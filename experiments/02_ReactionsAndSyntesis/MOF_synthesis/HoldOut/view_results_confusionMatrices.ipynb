{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from fastcore.xtras import load_pickle\n",
    "import pandas as pd \n",
    "import os \n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from scipy.stats import sem\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/jorenvanherck/Documents/gptchallengeV2/gptchem-gptj/plotutils/\")\n",
    "from plotutils import *\n",
    "\n",
    "plt.style.use(\"/home/jorenvanherck/Documents/gptchallengeV2/gptchem-gptj/plotutils/kevin.mplstyle\")\n",
    "\n",
    "FOLDER = 'out_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickles found in out_final: 10\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(FOLDER):\n",
    "    raise FileExistsError('Cannot find folder {}'.format(FOLDER))\n",
    "\n",
    "all_res = glob(f'{FOLDER}/*.pkl')\n",
    "print('Pickles found in {}: {}'.format(FOLDER, len(all_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'size': 20, 'target': 'completion_raw', 'accuracy': 0.8333333333333334, 'f1_macro': 0.8285714285714285, 'f1_micro': 0.8333333333333334, 'kappa': 0.6666666666666667, 'num_epochs': 50, 'lr': 0.0003, 'bins': 2, 'test_size': 6}, {'size': 20, 'target': 'completion_raw', 'accuracy': 1.0, 'f1_macro': 1.0, 'f1_micro': 1.0, 'kappa': 1.0, 'num_epochs': 50, 'lr': 0.0003, 'bins': 2, 'test_size': 6}, {'size': 20, 'target': 'completion_raw', 'accuracy': 1.0, 'f1_macro': 1.0, 'f1_micro': 1.0, 'kappa': 1.0, 'num_epochs': 50, 'lr': 0.0003, 'bins': 2, 'test_size': 6}, {'size': 20, 'target': 'completion_raw', 'accuracy': 0.8333333333333334, 'f1_macro': 0.8285714285714285, 'f1_micro': 0.8333333333333334, 'kappa': 0.6666666666666667, 'num_epochs': 50, 'lr': 0.0003, 'bins': 2, 'test_size': 6}, {'size': 20, 'target': 'completion_raw', 'accuracy': 0.8333333333333334, 'f1_macro': 0.8285714285714285, 'f1_micro': 0.8333333333333334, 'kappa': 0.6666666666666667, 'num_epochs': 50, 'lr': 0.0003, 'bins': 2, 'test_size': 6}, {'size': 20, 'target': 'completion_raw', 'accuracy': 1.0, 'f1_macro': 1.0, 'f1_micro': 1.0, 'kappa': 1.0, 'num_epochs': 50, 'lr': 0.0003, 'bins': 2, 'test_size': 6}, {'size': 20, 'target': 'completion_raw', 'accuracy': 0.8333333333333334, 'f1_macro': 0.8285714285714285, 'f1_micro': 0.8333333333333334, 'kappa': 0.6666666666666667, 'num_epochs': 50, 'lr': 0.0003, 'bins': 2, 'test_size': 6}, {'size': 20, 'target': 'completion_raw', 'accuracy': 1.0, 'f1_macro': 1.0, 'f1_micro': 1.0, 'kappa': 1.0, 'num_epochs': 50, 'lr': 0.0003, 'bins': 2, 'test_size': 6}, {'size': 20, 'target': 'completion_raw', 'accuracy': 0.8333333333333334, 'f1_macro': 0.8285714285714285, 'f1_micro': 0.8333333333333334, 'kappa': 0.6666666666666667, 'num_epochs': 50, 'lr': 0.0003, 'bins': 2, 'test_size': 6}, {'size': 20, 'target': 'completion_raw', 'accuracy': 0.8333333333333334, 'f1_macro': 0.8285714285714285, 'f1_micro': 0.8333333333333334, 'kappa': 0.6666666666666667, 'num_epochs': 50, 'lr': 0.0003, 'bins': 2, 'test_size': 6}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "compiled_res_list = []\n",
    "conf_mats = []\n",
    "\n",
    "for results in all_res:\n",
    "    res_full = load_pickle(results)\n",
    "    res = res_full['results']\n",
    "    summary = {\n",
    "        'size': res_full['train_size'],\n",
    "        #'representation': res_full['data_summary']['representation'],\n",
    "        'target': res_full['data_summary']['target'],\n",
    "        'accuracy': res['accuracy'],\n",
    "        'f1_macro': res['f1_macro'],\n",
    "        'f1_micro': res['f1_micro'],\n",
    "        'kappa': res['kappa'],\n",
    "        'num_epochs': res_full['config']['tune_settings']['num_train_epochs'],\n",
    "        'lr': res_full['config']['tune_settings']['learning_rate'],\n",
    "        'bins': len(set(res['all_y_true'])),\n",
    "        'test_size': len(res['all_y_true'])\n",
    "       \n",
    "    }\n",
    "    confusion_matrix = {\n",
    "        'all_y_true':res['all_y_true'],\n",
    "        'all_y_pred':res['all_y_pred']\n",
    "    }\n",
    "    conf_mats.append(confusion_matrix)\n",
    "    compiled_res_list.append(summary)\n",
    "print(compiled_res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "compiled_res = pd.DataFrame(compiled_res_list)\n",
    "grouped_res =compiled_res.groupby(['bins', 'num_epochs', 'target', 'size']).agg(['mean', 'sem'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">kappa</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lr</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bins</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>target</th>\n",
       "      <th>size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>50</th>\n",
       "      <th>completion_raw</th>\n",
       "      <th>20</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.027217</td>\n",
       "      <td>0.897143</td>\n",
       "      <td>0.027994</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.027217</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.054433</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    accuracy            f1_macro            \\\n",
       "                                        mean       sem      mean       sem   \n",
       "bins num_epochs target         size                                          \n",
       "2    50         completion_raw 20        0.9  0.027217  0.897143  0.027994   \n",
       "\n",
       "                                    f1_micro           kappa            \\\n",
       "                                        mean       sem  mean       sem   \n",
       "bins num_epochs target         size                                      \n",
       "2    50         completion_raw 20        0.9  0.027217   0.8  0.054433   \n",
       "\n",
       "                                         lr      test_size       \n",
       "                                       mean  sem      mean  sem  \n",
       "bins num_epochs target         size                              \n",
       "2    50         completion_raw 20    0.0003  0.0       6.0  0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_valid(trues, preds, valid_predictions = [0,1]):\n",
    "    correct_indices = [i for i, value in enumerate(preds) if value in valid_predictions]\n",
    "\n",
    "    trues_new = [trues[i] for i in correct_indices]\n",
    "    preds_new = [preds[i] for i in correct_indices]\n",
    "    if len(preds) != len(preds_new):\n",
    "        print(f'{len(preds) - len(preds_new)} removed')\n",
    "    return trues_new, preds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 330x250 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 330x250 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 330x250 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 330x250 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 330x250 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 330x250 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 330x250 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 330x250 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 330x250 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 330x250 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import os\n",
    "\n",
    "for csv in os.listdir('predictions_final'):\n",
    "    try:\n",
    "        file = os.path.join('predictions_final', csv)\n",
    "        df = pd.read_csv(file)\n",
    "        predicted = df.loc[df['partition'] == 'test_taddei']['prediction'].tolist()\n",
    "        actual = [0,0,1,0,0]\n",
    "        actual, predicted = get_valid(actual, predicted, [0,1])\n",
    "\n",
    "        confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "        #print(classification_report(actual, predicted))\n",
    "\n",
    "        cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['1','0'])\n",
    "        cm_display.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "\n",
    "        plt.savefig('Unseen_test_data.pdf', bbox_inches = 'tight')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predirra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
