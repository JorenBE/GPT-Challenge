{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional machine learning\n",
    "Feature(s): 'SMILES' column\n",
    "\n",
    "- 'SMILES' column\n",
    "\n",
    "Target: deltaG4_bin\n",
    "\n",
    "- Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import clone\n",
    "from loguru import logger\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"WARNING\")\n",
    "# Append the parent directory of your package to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..', '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique smiles: 1423\n",
      "Count of all of the smiles: 1423\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "path_to_dataset = 'NiCatalysis.csv'\n",
    "csv_filename = 'NiCatalysis.csv'\n",
    "\n",
    "# Open the file, Correct the encoding and sep if necessary\n",
    "if path_to_dataset.endswith('.zip'):\n",
    "    with zipfile.ZipFile(path_to_dataset, 'r') as z:\n",
    "        # Open the CSV file within the ZIP file\n",
    "        with z.open(csv_filename) as f:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(f, sep=',', on_bad_lines='warn', index_col = 0)\n",
    "else:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(path_to_dataset, sep=',', on_bad_lines='warn', index_col = 0)\n",
    "\n",
    "df = df.rename(columns={'Smiles': 'SMILES'})\n",
    "\n",
    "print('Count of unique smiles:', df.SMILES.unique().shape[0])\n",
    "print('Count of all of the smiles:', df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLPipeline import MLmodel, BinTheTarget\n",
    "\n",
    "Target = ['deltaG4_bin']\n",
    "Features = ['SMILES']\n",
    "Feature_types = ['SMILES']\n",
    "input = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>\\DeltaG4</th>\n",
       "      <th>type</th>\n",
       "      <th>deltaG4_bin</th>\n",
       "      <th>deltaG4_realbin-27_-39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Carb_0_0_10</td>\n",
       "      <td>*[Ni@](C9=N([H])C(C(C)C)=C(C(C)C)N([H])9)(c1cc...</td>\n",
       "      <td>-19.000359</td>\n",
       "      <td>Carb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carb_0_0_1</td>\n",
       "      <td>*[Ni@](C9=N([H])C(C)C(C)N([H])9)(c1ccc2ccccc2c...</td>\n",
       "      <td>-8.308853</td>\n",
       "      <td>Carb</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Carb_0_0_25</td>\n",
       "      <td>*[Ni@](C9=N([H])C1C2=CC=CC(=C23)C=CC=C3C=1N([H...</td>\n",
       "      <td>-9.688746</td>\n",
       "      <td>Carb</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Carb_0_0_7</td>\n",
       "      <td>*[Ni@](C9=N([H])C(C(F)(F)F)C(C(F)(F)F)N([H])9)...</td>\n",
       "      <td>-10.292410</td>\n",
       "      <td>Carb</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Carb_0_11_0</td>\n",
       "      <td>*[Ni@](C9=N([H])CCN(C1CC1)9)(c1ccc2ccccc2c1)([...</td>\n",
       "      <td>-5.979538</td>\n",
       "      <td>Carb</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0         Name  \\\n",
       "0             0           0  Carb_0_0_10   \n",
       "1             1           1   Carb_0_0_1   \n",
       "2             2           2  Carb_0_0_25   \n",
       "3             3           3   Carb_0_0_7   \n",
       "4             4           4  Carb_0_11_0   \n",
       "\n",
       "                                              SMILES   \\DeltaG4  type  \\\n",
       "0  *[Ni@](C9=N([H])C(C(C)C)=C(C(C)C)N([H])9)(c1cc... -19.000359  Carb   \n",
       "1  *[Ni@](C9=N([H])C(C)C(C)N([H])9)(c1ccc2ccccc2c...  -8.308853  Carb   \n",
       "2  *[Ni@](C9=N([H])C1C2=CC=CC(=C23)C=CC=C3C=1N([H...  -9.688746  Carb   \n",
       "3  *[Ni@](C9=N([H])C(C(F)(F)F)C(C(F)(F)F)N([H])9)... -10.292410  Carb   \n",
       "4  *[Ni@](C9=N([H])CCN(C1CC1)9)(c1ccc2ccccc2c1)([...  -5.979538  Carb   \n",
       "\n",
       "   deltaG4_bin  deltaG4_realbin-27_-39  \n",
       "0            0                       0  \n",
       "1            1                       0  \n",
       "2            1                       0  \n",
       "3            1                       0  \n",
       "4            1                       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveRandomForestClassifier(trial, model_instance):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to minimize.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters to tune\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [None, 10, 20, 30, 40]),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 6),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "\n",
    "    # Clone the model to ensure a fresh instance each trial\n",
    "    model_clone = clone(model_instance.model)\n",
    "    model_clone.set_params(**params)\n",
    "    \n",
    "    # Define the score metric\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model_clone, model_instance.X_train, model_instance.y_train, cv=model_instance.cv, scoring=scoring)\n",
    "\n",
    "    # Return the average score across all folds\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "def objectiveXGBClassifier(trial, model_instance):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to minimize for XGBClassifier.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters to tune\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),  # L1 regularization\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),  # L2 regularization\n",
    "    }\n",
    "\n",
    "    # Clone the model to ensure a fresh instance each trial\n",
    "    model_clone = clone(model_instance.model)\n",
    "    model_clone.set_params(**params)\n",
    "    \n",
    "    # Define the score metric\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model_clone, model_instance.X_train, model_instance.y_train, cv=model_instance.cv, scoring=scoring)\n",
    "\n",
    "    # Return the average score across all folds\n",
    "    return scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['deltaG4_bin'] / Train size:25 / Seed:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[11:03:42] Explicit valence for atom # 3 N, 4, is greater than permitted\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (25,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGBClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     15\u001b[0m     objective \u001b[38;5;241m=\u001b[39m objectiveXGBClassifier\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMLmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43mrandomSeed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43mtrain_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43mtest_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43mhyperparameter_tuning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m\u001b[49m\u001b[43moptimization_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptuna\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43moptimization_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28meval\u001b[39m, summary \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m<string>:18\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, modelType, df, target, features, feature_types, target_type, test_count, train_count, randomSeed, hyperparameter_tuning, param_grid, cv, optimization_method, optimization_trials, objective)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Joren_ML/GPT-Challenge/MLPipeline.py:129\u001b[0m, in \u001b[0;36mMLmodel.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray(x)\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test])\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Not optimal\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (25,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "MODEL_NAMES = ['RandomForestClassifier', 'XGBClassifier']\n",
    "TARGETS = [[i] for i in Target ]\n",
    "TRAIN_SIZES = [25, 50, 100, 200]\n",
    "\n",
    "result = []\n",
    "for seed in [1, 2, 3]:\n",
    "    for model_name in MODEL_NAMES:\n",
    "        for target in TARGETS:\n",
    "            for train_size in TRAIN_SIZES:\n",
    "                print(f'RUN: Model:{model_name} / Target:{target} / Train size:{train_size} / Seed:{seed}')\n",
    "                \n",
    "                if model_name == 'RandomForestClassifier':\n",
    "                    objective = objectiveRandomForestClassifier\n",
    "                elif model_name == 'XGBClassifier':\n",
    "                    objective = objectiveXGBClassifier\n",
    "\n",
    "                model = MLmodel(modelType=model_name, \n",
    "                df=input,\n",
    "                randomSeed=seed,\n",
    "                train_count = train_size,\n",
    "                test_count = 50, \n",
    "                target=target, \n",
    "                features=Features, \n",
    "                hyperparameter_tuning=True,\n",
    "                feature_types=Feature_types,\n",
    "                optimization_method='optuna', \n",
    "                optimization_trials=10,\n",
    "                objective=lambda trial: objective(trial, model)\n",
    "                )\n",
    "\n",
    "                model.train()\n",
    "                eval, summary = model.evaluate()\n",
    "                result.append({**summary, **eval, 'seed':seed})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)\n",
    "display(df)\n",
    "df.to_csv('FreeEnergy_cleavageReact_traditional_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "METRICS = ['accuracy','f1_micro','f1_macro', 'kappa']\n",
    "fig, ax = plt.subplots(len(METRICS), 1, sharex=True, layout = 'constrained')\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, metric in enumerate(METRICS):\n",
    "    ax[i].plot(df['train_size'], df[metric], marker = 'o')\n",
    "    ax[i].set_title(metric)\n",
    "    ax[i].set_ylim(0,1)\n",
    "\n",
    "fig.suptitle('Random Forrest & XGB - FreeEnergy_cleavageReact')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
