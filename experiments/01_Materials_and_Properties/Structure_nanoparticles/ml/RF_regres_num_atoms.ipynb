{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - pair distribution function (PDF) - number of atoms - regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from debyecalculator import DebyeCalculator\n",
    "from ase.io import read\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import tiktoken\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, r2_score, mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import pycm\n",
    "from ast import literal_eval\n",
    "import sys\n",
    "sys.path.append(\"/mnt/c/Users/44907688G/Documents/home_vicky/LLMs_models/gptchem-gptj/plotutils/\")\n",
    "from plotutils import *\n",
    "plt.style.use(\"/mnt/c/Users/44907688G/Documents/home_vicky/LLMs_models/gptchem-gptj/plotutils/kevin.mplstyle\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xyz_files():\n",
    "    # Initialise DebyeCalculator object\n",
    "    calc = DebyeCalculator()\n",
    "    print(calc)\n",
    "    \n",
    "    # Load XYZ files\n",
    "    XYZ_files = sorted(glob.glob(\"../xyz_files/*.xyz\"))\n",
    "    random.shuffle(XYZ_files)\n",
    "\n",
    "    # Calculate Pair Distribution Function for all XYZ files\n",
    "    scattering_files = []\n",
    "    structure_types = []\n",
    "    num_atoms = []\n",
    "\n",
    "    for iter, xyz_file in enumerate(XYZ_files):\n",
    "        # Extract structure type\n",
    "        structure_type = os.path.basename(xyz_file).split('_')[0]\n",
    "\n",
    "        # Calculate the scattering pattern\n",
    "        scatt_x, scatt_Int = calc.gr(structure_source=xyz_file)\n",
    "\n",
    "        # Normalise the scattering files\n",
    "        scatt_Int /= max(scatt_Int)\n",
    "        scattering_files.append(scatt_Int)\n",
    "\n",
    "        # Increment the count for this structure type\n",
    "        structure_types.append(structure_type)\n",
    "\n",
    "        atoms = read(xyz_file)\n",
    "        num_atoms.append(len(atoms))\n",
    "\n",
    "    return scattering_files, structure_types, num_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12297/1612413307.py:3: UserWarning: Warning: Your system might have a CUDA-enabled GPU, but CUDA is not available. Computations will run on the CPU instead. For optimal performance, please install Pytorch with CUDA support. If you do not have a CUDA-enabled CPU, you can surpress this warning by specifying the 'device' argument as 'cpu'\n",
      "  calc = DebyeCalculator()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebyeCalculator{'qmin': 1.0, 'qmax': 30.0, 'qdamp': 0.04, 'qstep': 0.05, 'rmin': 0.0, 'rmax': 20.0, 'rstep': 0.01, 'rthres': 0.0, 'biso': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# Simulate scattering data\n",
    "scattering_files, structure_types, num_atoms = process_xyz_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scattering_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.24081259e-03, -2.43981788e-03, -3.55886901e-03,\n",
       "       -4.56686504e-03, -5.44242794e-03, -6.17583841e-03, -6.76981779e-03,\n",
       "       -7.23938225e-03, -7.61045050e-03, -7.91762862e-03, -8.20107665e-03,\n",
       "       -8.50310456e-03, -8.86432454e-03, -9.32015758e-03, -9.89775546e-03,\n",
       "       -1.06134415e-02, -1.14714708e-02, -1.24634868e-02, -1.35693504e-02,\n",
       "       -1.47587219e-02, -1.59940217e-02, -1.72333848e-02, -1.84345916e-02,\n",
       "       -1.95586290e-02, -2.05732044e-02, -2.14555021e-02, -2.21943278e-02,\n",
       "       -2.27909349e-02, -2.32591350e-02, -2.36239322e-02, -2.39193980e-02,\n",
       "       -2.41856966e-02, -2.44655330e-02, -2.48004626e-02, -2.52271071e-02,\n",
       "       -2.57741194e-02, -2.64594071e-02, -2.72887163e-02, -2.82550789e-02,\n",
       "       -2.93392893e-02, -3.05116437e-02, -3.17345411e-02, -3.29658240e-02,\n",
       "       -3.41622792e-02, -3.52836587e-02, -3.62959877e-02, -3.71749178e-02,\n",
       "       -3.79074812e-02, -3.84935588e-02, -3.89457569e-02, -3.92884202e-02,\n",
       "       -3.95554863e-02, -3.97875607e-02, -4.00282070e-02, -4.03202996e-02,\n",
       "       -4.07022499e-02, -4.12044451e-02, -4.18465957e-02, -4.26361896e-02,\n",
       "       -4.35675271e-02, -4.46221568e-02, -4.57707383e-02, -4.69754003e-02,\n",
       "       -4.81928736e-02, -4.93786745e-02, -5.04906923e-02, -5.14931269e-02,\n",
       "       -5.23593836e-02, -5.30747734e-02, -5.36375418e-02, -5.40593043e-02,\n",
       "       -5.43640181e-02, -5.45857698e-02, -5.47659956e-02, -5.49499206e-02,\n",
       "       -5.51821254e-02, -5.55032901e-02, -5.59460223e-02, -5.65323383e-02,\n",
       "       -5.72714172e-02, -5.81588969e-02, -5.91770783e-02, -6.02965169e-02,\n",
       "       -6.14784360e-02, -6.26783147e-02, -6.38495684e-02, -6.49476647e-02,\n",
       "       -6.59342259e-02, -6.67802244e-02, -6.74687549e-02, -6.79964572e-02,\n",
       "       -6.83739781e-02, -6.86250180e-02, -6.87843561e-02, -6.88948333e-02,\n",
       "       -6.90037310e-02, -6.91583306e-02, -6.94020987e-02, -6.97705969e-02,\n",
       "       -7.02883825e-02, -7.09666684e-02, -7.18025640e-02, -7.27788582e-02,\n",
       "       -7.38656372e-02, -7.50229061e-02, -7.62039125e-02, -7.73592591e-02,\n",
       "       -7.84413517e-02, -7.94084743e-02, -8.02284926e-02, -8.08819532e-02,\n",
       "       -8.13635513e-02, -8.16830397e-02, -8.18642676e-02, -8.19430798e-02,\n",
       "       -8.19645822e-02, -8.19788352e-02, -8.20367336e-02, -8.21854770e-02,\n",
       "       -8.24643001e-02, -8.29008371e-02, -8.35089758e-02, -8.42872784e-02,\n",
       "       -8.52187723e-02, -8.62727687e-02, -8.74072090e-02, -8.85722116e-02,\n",
       "       -8.97147134e-02, -9.07827765e-02, -9.17304903e-02, -9.25217271e-02,\n",
       "       -9.31337327e-02, -9.35592130e-02, -9.38067660e-02, -9.39007327e-02,\n",
       "       -9.38789546e-02, -9.37894955e-02, -9.36865881e-02, -9.36258808e-02,\n",
       "       -9.36595351e-02, -9.38315764e-02, -9.41738486e-02, -9.47033018e-02,\n",
       "       -9.54200551e-02, -9.63075086e-02, -9.73333120e-02, -9.84524116e-02,\n",
       "       -9.96107683e-02, -1.00749806e-01, -1.01811975e-01, -1.02745444e-01,\n",
       "       -1.03508934e-01, -1.04075611e-01, -1.04435302e-01, -1.04595780e-01,\n",
       "       -1.04582347e-01, -1.04435667e-01, -1.04208253e-01, -1.03960104e-01,\n",
       "       -1.03753559e-01, -1.03647873e-01, -1.03693344e-01, -1.03927419e-01,\n",
       "       -1.04371153e-01, -1.05026655e-01, -1.05877213e-01, -1.06888101e-01,\n",
       "       -1.08009689e-01, -1.09181575e-01, -1.10337690e-01, -1.11412108e-01,\n",
       "       -1.12344913e-01, -1.13087811e-01, -1.13607973e-01, -1.13891743e-01,\n",
       "       -1.13945991e-01, -1.13797531e-01, -1.13491528e-01, -1.13087215e-01,\n",
       "       -1.12653494e-01, -1.12262264e-01, -1.11982822e-01, -1.11875102e-01,\n",
       "       -1.11984521e-01, -1.12337641e-01, -1.12939358e-01, -1.13772236e-01,\n",
       "       -1.14797801e-01, -1.15959197e-01, -1.17186159e-01, -1.18400991e-01,\n",
       "       -1.19525231e-01, -1.20486595e-01, -1.21225700e-01, -1.21701375e-01,\n",
       "       -1.21894747e-01, -1.21811479e-01, -1.21481538e-01, -1.20957285e-01,\n",
       "       -1.20309383e-01, -1.19620435e-01, -1.18978389e-01, -1.18468747e-01,\n",
       "       -1.18166678e-01, -1.18130304e-01, -1.18395038e-01, -1.18969910e-01,\n",
       "       -1.19835876e-01, -1.20947212e-01, -1.22234344e-01, -1.23609908e-01,\n",
       "       -1.24975652e-01, -1.26231149e-01, -1.27282426e-01, -1.28050968e-01,\n",
       "       -1.28480569e-01, -1.28543690e-01, -1.28244370e-01, -1.27619013e-01,\n",
       "       -1.26734108e-01, -1.25681296e-01, -1.24569185e-01, -1.23514459e-01,\n",
       "       -1.22630849e-01, -1.22017518e-01, -1.21748522e-01, -1.21863000e-01,\n",
       "       -1.22357711e-01, -1.23182356e-01, -1.24237746e-01, -1.25376970e-01,\n",
       "       -1.26410887e-01, -1.27115145e-01, -1.27239615e-01, -1.26520097e-01,\n",
       "       -1.24690384e-01, -1.21492140e-01, -1.16686612e-01, -1.10061593e-01,\n",
       "       -1.01437114e-01, -9.06679109e-02, -7.76424929e-02, -6.22795448e-02,\n",
       "       -4.45220284e-02, -2.43305378e-02, -1.67425314e-03,  2.34756581e-02,\n",
       "        5.11520430e-02,  8.13953653e-02,  1.14253238e-01,  1.49776816e-01,\n",
       "        1.88011691e-01,  2.28986531e-01,  2.72697270e-01,  3.19088519e-01,\n",
       "        3.68034363e-01,  4.19318944e-01,  4.72618908e-01,  5.27489901e-01,\n",
       "        5.83356798e-01,  6.39512658e-01,  6.95123255e-01,  7.49239743e-01,\n",
       "        8.00822437e-01,  8.48763645e-01,  8.91932547e-01,  9.29210246e-01,\n",
       "        9.59535837e-01,  9.81951296e-01,  9.95646894e-01,  1.00000000e+00,\n",
       "        9.94609892e-01,  9.79322970e-01,  9.54249382e-01,  9.19767141e-01,\n",
       "        8.76514137e-01,  8.25371504e-01,  7.67431796e-01,  7.03961909e-01,\n",
       "        6.36354804e-01,  5.66078603e-01,  4.94622082e-01,  4.23439175e-01,\n",
       "        3.53898585e-01,  2.87236571e-01,  2.24518389e-01,  1.66608498e-01,\n",
       "        1.14149898e-01,  6.75610453e-02,  2.70300973e-02, -7.46678282e-03,\n",
       "       -3.61461975e-02, -5.93875051e-02, -7.76997060e-02, -9.16840583e-02,\n",
       "       -1.01995468e-01, -1.09306335e-01, -1.14272207e-01, -1.17503487e-01,\n",
       "       -1.19541764e-01, -1.20843709e-01, -1.21772148e-01, -1.22592770e-01,\n",
       "       -1.23478658e-01, -1.24518499e-01, -1.25730276e-01, -1.27076641e-01,\n",
       "       -1.28482103e-01, -1.29850566e-01, -1.31080806e-01, -1.32080585e-01,\n",
       "       -1.32776886e-01, -1.33123830e-01, -1.33106038e-01, -1.32738978e-01,\n",
       "       -1.32066220e-01, -1.31154224e-01, -1.30085588e-01, -1.28950164e-01,\n",
       "       -1.27837986e-01, -1.26831248e-01, -1.25997290e-01, -1.25384986e-01,\n",
       "       -1.25020549e-01, -1.24907702e-01, -1.25028372e-01, -1.25345528e-01,\n",
       "       -1.25807524e-01, -1.26353353e-01, -1.26918361e-01, -1.27439275e-01,\n",
       "       -1.27860054e-01, -1.28135338e-01, -1.28234401e-01, -1.28141522e-01,\n",
       "       -1.27857804e-01, -1.27398938e-01, -1.26793966e-01, -1.26081303e-01,\n",
       "       -1.25306278e-01, -1.24516211e-01, -1.23757429e-01, -1.23070620e-01,\n",
       "       -1.22489311e-01, -1.22036628e-01, -1.21724583e-01, -1.21553741e-01,\n",
       "       -1.21513776e-01, -1.21584624e-01, -1.21738642e-01, -1.21942893e-01,\n",
       "       -1.22162163e-01, -1.22360930e-01, -1.22506566e-01, -1.22571252e-01,\n",
       "       -1.22533515e-01, -1.22380078e-01, -1.22105613e-01, -1.21713839e-01,\n",
       "       -1.21215858e-01, -1.20630048e-01, -1.19980387e-01, -1.19294465e-01,\n",
       "       -1.18602142e-01, -1.17932908e-01, -1.17314681e-01, -1.16771221e-01,\n",
       "       -1.16321281e-01, -1.15976952e-01, -1.15742862e-01, -1.15616113e-01,\n",
       "       -1.15585864e-01, -1.15634382e-01, -1.15737215e-01, -1.15866177e-01,\n",
       "       -1.15989409e-01, -1.16074659e-01, -1.16091043e-01, -1.16011508e-01,\n",
       "       -1.15814924e-01, -1.15487598e-01, -1.15025260e-01, -1.14433378e-01,\n",
       "       -1.13727689e-01, -1.12933300e-01, -1.12083822e-01, -1.11217991e-01,\n",
       "       -1.10378720e-01, -1.09608710e-01, -1.08947307e-01, -1.08427033e-01,\n",
       "       -1.08070537e-01, -1.07887894e-01, -1.07875057e-01, -1.08012997e-01,\n",
       "       -1.08268403e-01, -1.08595483e-01, -1.08938880e-01, -1.09237820e-01,\n",
       "       -1.09431289e-01, -1.09462872e-01, -1.09286346e-01, -1.08870216e-01,\n",
       "       -1.08201519e-01, -1.07287593e-01, -1.06156781e-01, -1.04855560e-01,\n",
       "       -1.03445224e-01, -1.01993084e-01, -1.00566044e-01, -9.92180184e-02,\n",
       "       -9.79797170e-02, -9.68466327e-02, -9.57681015e-02, -9.46386009e-02,\n",
       "       -9.32912976e-02, -9.14949402e-02, -8.89564157e-02, -8.53257924e-02,\n",
       "       -8.02092254e-02, -7.31834546e-02, -6.38184920e-02, -5.16988039e-02,\n",
       "       -3.64536718e-02, -1.77797098e-02,  4.52678697e-03,  3.05519477e-02,\n",
       "        6.02355562e-02,  9.33667645e-02,  1.29564539e-01,  1.68289974e-01,\n",
       "        2.08843112e-01,  2.50387728e-01,  2.91972041e-01,  3.32569569e-01,\n",
       "        3.71104032e-01,  4.06507283e-01,  4.37749565e-01,  4.63896632e-01,\n",
       "        4.84140664e-01,  4.97845978e-01,  5.04572511e-01,  5.04100621e-01,\n",
       "        4.96441334e-01,  4.81836140e-01,  4.60749477e-01,  4.33843672e-01,\n",
       "        4.01957005e-01,  3.66056621e-01,  3.27207208e-01,  2.86512375e-01,\n",
       "        2.45081887e-01,  2.03970701e-01,  1.64154649e-01,  1.26477972e-01,\n",
       "        9.16424543e-02,  6.01722486e-02,  3.24205756e-02,  8.55571125e-03,\n",
       "       -1.14177056e-02, -2.76513454e-02, -4.04214934e-02, -5.01064658e-02,\n",
       "       -5.71505576e-02, -6.20356165e-02, -6.52473792e-02, -6.72493353e-02,\n",
       "       -6.84580877e-02, -6.92265183e-02, -6.98308572e-02, -7.04668313e-02,\n",
       "       -7.12497830e-02, -7.22213611e-02, -7.33604878e-02, -7.45985135e-02,\n",
       "       -7.58347660e-02, -7.69542381e-02, -7.78433159e-02, -7.84041807e-02,\n",
       "       -7.85658360e-02, -7.82920122e-02, -7.75841177e-02, -7.64807686e-02,\n",
       "       -7.50548393e-02, -7.34038800e-02, -7.16432258e-02, -6.98918030e-02,\n",
       "       -6.82637319e-02, -6.68554455e-02, -6.57372475e-02, -6.49458095e-02,\n",
       "       -6.44798651e-02, -6.42996728e-02, -6.43276498e-02, -6.44542873e-02,\n",
       "       -6.45441860e-02, -6.44467697e-02, -6.40051514e-02, -6.30676523e-02,\n",
       "       -6.14986904e-02, -5.91868982e-02, -5.60545176e-02, -5.20613007e-02,\n",
       "       -4.72091883e-02, -4.15415391e-02, -3.51426676e-02, -2.81321779e-02,\n",
       "       -2.06609294e-02, -1.29015287e-02, -5.04245516e-03,  2.72299210e-03,\n",
       "        1.02023892e-02,  1.72145814e-02,  2.35933661e-02,  2.91958489e-02,\n",
       "        3.39039490e-02,  3.76287065e-02,  4.03098464e-02,  4.19167653e-02,\n",
       "        4.24467325e-02,  4.19229344e-02,  4.03920971e-02,  3.79212163e-02,\n",
       "        3.45948339e-02,  3.05116028e-02,  2.57819630e-02,  2.05239784e-02,\n",
       "        1.48626408e-02,  8.92553199e-03,  2.84140045e-03, -3.26386979e-03,\n",
       "       -9.26731247e-03, -1.50547829e-02, -2.05204431e-02, -2.55720820e-02,\n",
       "       -3.01313624e-02, -3.41380052e-02, -3.75507064e-02, -4.03482914e-02,\n",
       "       -4.25302163e-02, -4.41167057e-02, -4.51469570e-02, -4.56771702e-02,\n",
       "       -4.57779057e-02, -4.55295779e-02, -4.50184532e-02, -4.43322659e-02,\n",
       "       -4.35553417e-02, -4.27644812e-02, -4.20244969e-02, -4.13859896e-02,\n",
       "       -4.08833139e-02, -4.05326113e-02, -4.03335877e-02, -4.02703732e-02,\n",
       "       -4.03138511e-02, -4.04255651e-02, -4.05610092e-02, -4.06745151e-02,\n",
       "       -4.07227091e-02, -4.06686328e-02, -4.04852331e-02, -4.01566550e-02,\n",
       "       -3.96794416e-02, -3.90638597e-02, -3.83312069e-02, -3.75128314e-02,\n",
       "       -3.66468541e-02, -3.57748270e-02, -3.49381790e-02, -3.41745876e-02,\n",
       "       -3.35152596e-02, -3.29814926e-02, -3.25839333e-02, -3.23213562e-02,\n",
       "       -3.21806930e-02, -3.21392864e-02, -3.21655758e-02, -3.22233066e-02,\n",
       "       -3.22741941e-02, -3.22805494e-02, -3.22100446e-02, -3.20368856e-02,\n",
       "       -3.17450836e-02, -3.13293524e-02, -3.07948105e-02, -3.01576145e-02,\n",
       "       -2.94422321e-02, -2.86800675e-02, -2.79061645e-02, -2.71565951e-02,\n",
       "       -2.64639072e-02, -2.58572940e-02, -2.53566597e-02, -2.49730870e-02,\n",
       "       -2.47073676e-02, -2.45506130e-02, -2.44838502e-02, -2.44811252e-02,\n",
       "       -2.45113242e-02, -2.45409068e-02, -2.45365854e-02, -2.44690441e-02,\n",
       "       -2.43144967e-02, -2.40575150e-02, -2.36918107e-02, -2.32204255e-02,\n",
       "       -2.26567797e-02, -2.20210496e-02, -2.13409457e-02, -2.06468161e-02,\n",
       "       -1.99707914e-02, -1.93428081e-02, -1.87888909e-02, -1.83280129e-02,\n",
       "       -1.79710984e-02, -1.77200101e-02, -1.75679289e-02, -1.74980909e-02,\n",
       "       -1.74890347e-02, -1.75123457e-02, -1.75382309e-02, -1.75368004e-02,\n",
       "       -1.74812526e-02, -1.73495244e-02, -1.71269719e-02, -1.68070421e-02,\n",
       "       -1.63918640e-02, -1.58924349e-02, -1.53265363e-02, -1.47186145e-02,\n",
       "       -1.40964575e-02, -1.34881688e-02, -1.29219079e-02, -1.24216285e-02,\n",
       "       -1.20044462e-02, -1.16813192e-02, -1.14547322e-02, -1.13185225e-02,\n",
       "       -1.12588629e-02, -1.12558166e-02, -1.12844771e-02, -1.13175577e-02,\n",
       "       -1.13278115e-02, -1.12905828e-02, -1.11853415e-02, -1.09979911e-02,\n",
       "       -1.07226586e-02, -1.03602437e-02, -9.92019475e-03, -9.41909850e-03,\n",
       "       -8.87799729e-03, -8.32258165e-03, -7.77878752e-03, -7.27242464e-03,\n",
       "       -6.82504149e-03, -6.45357044e-03, -6.16819086e-03, -5.97117376e-03,\n",
       "       -5.85787604e-03, -5.81597537e-03, -5.82679734e-03, -5.86894620e-03,\n",
       "       -5.91615075e-03, -5.94383338e-03, -5.92909707e-03, -5.85269881e-03,\n",
       "       -5.70190558e-03, -5.46988286e-03, -5.15802857e-03, -4.77443123e-03,\n",
       "       -4.33377596e-03, -3.85568151e-03, -3.36320116e-03, -2.88091158e-03,\n",
       "       -2.43221410e-03, -2.03743530e-03, -1.71197311e-03, -1.46603107e-03,\n",
       "       -1.30220712e-03, -1.21600262e-03, -1.19656033e-03, -1.22706231e-03,\n",
       "       -1.28679897e-03, -1.35284069e-03, -1.40178541e-03, -1.41224544e-03,\n",
       "       -1.36624579e-03, -1.25218637e-03, -1.06281915e-03, -7.99366098e-04,\n",
       "       -4.69260267e-04, -8.57363266e-05,  3.33085394e-04,  7.65886973e-04,\n",
       "        1.18980824e-03,  1.58350193e-03,  1.92749756e-03,  2.20688642e-03,\n",
       "        2.41268799e-03,  2.54217372e-03,  2.59903981e-03,  2.59338575e-03,\n",
       "        2.54058745e-03,  2.45940429e-03,  2.37222132e-03,  2.29994440e-03,\n",
       "        2.26307474e-03,  2.27785902e-03,  2.35653319e-03,  2.50458950e-03,\n",
       "        2.72193924e-03,  3.00184079e-03,  3.33177624e-03,  3.69518227e-03,\n",
       "        4.07196581e-03,  4.44132043e-03,  4.78237402e-03,  5.07793529e-03,\n",
       "        5.31322462e-03,  5.47985686e-03,  5.57490811e-03,  5.60196768e-03,\n",
       "        5.57033345e-03,  5.49395522e-03,  5.39090112e-03,  5.28115034e-03,\n",
       "        5.18511701e-03,  5.12162177e-03,  5.10609895e-03,  5.15041267e-03,\n",
       "        5.25951153e-03,  5.43360040e-03,  5.66638447e-03,  5.94670558e-03,\n",
       "        6.25833729e-03,  6.58325898e-03,  6.90148631e-03,  7.19377026e-03,\n",
       "        7.44329672e-03,  7.63671333e-03,  7.76566984e-03,  7.82776438e-03,\n",
       "        7.82540254e-03,  7.76809454e-03,  7.66813522e-03,  7.54281925e-03,\n",
       "        7.41084199e-03,  7.29148090e-03,  7.20231887e-03,  7.15830829e-03,\n",
       "        7.17005646e-03,  7.24304235e-03,  7.37702753e-03,  7.56653165e-03,\n",
       "        7.80093716e-03,  8.06580111e-03,  8.34284257e-03,  8.61413963e-03,\n",
       "        8.86138808e-03,  9.06848349e-03,  9.22319945e-03,  9.31733008e-03,\n",
       "        9.34817083e-03,  9.31843370e-03,  9.23634693e-03,  9.11426917e-03,\n",
       "        8.96803476e-03,  8.81527085e-03,  8.67405254e-03,  8.56089219e-03,\n",
       "        8.49050935e-03,  8.47282261e-03,  8.51289928e-03,  8.61065648e-03,\n",
       "        8.76117684e-03,  8.95416550e-03,  9.17611644e-03,  9.41017736e-03,\n",
       "        9.63910110e-03,  9.84548032e-03,  1.00144884e-02,  1.01338150e-02,\n",
       "        1.01960488e-02,  1.01986034e-02,  1.01439152e-02,  1.00396303e-02,\n",
       "        9.89741646e-03,  9.73215420e-03,  9.56043601e-03,  9.39967949e-03,\n",
       "        9.26577300e-03,  9.17199999e-03,  9.12780967e-03,  9.13875271e-03,\n",
       "        9.20452178e-03,  9.32046585e-03,  9.47694946e-03,  9.66099370e-03,\n",
       "        9.85706970e-03,  1.00484081e-02,  1.02187432e-02,  1.03537161e-02,\n",
       "        1.04419570e-02,  1.04760174e-02,  1.04537485e-02,  1.03771370e-02,\n",
       "        1.02533894e-02,  1.00934021e-02,  9.91185941e-03,  9.72432736e-03,\n",
       "        9.54675674e-03,  9.39492043e-03,  9.28097405e-03,  9.21441335e-03,\n",
       "        9.20020882e-03,  9.23820212e-03,  9.32418834e-03,  9.44884401e-03,\n",
       "        9.60003864e-03,  9.76297446e-03,  9.92167275e-03,  1.00605320e-02,\n",
       "        1.01660602e-02,  1.02274176e-02,  1.02375327e-02,  1.01940297e-02,\n",
       "        1.00990701e-02,  9.95929819e-03,  9.78515483e-03,  9.59046092e-03,\n",
       "        9.38993506e-03,  9.19923652e-03,  9.03271511e-03,  8.90254974e-03,\n",
       "        8.81771930e-03,  8.78272671e-03,  8.79763626e-03,  8.85829981e-03,\n",
       "        8.95647984e-03,  9.08005796e-03,  9.21483338e-03,  9.34529770e-03,\n",
       "        9.45826061e-03,  9.53909010e-03,  9.57794860e-03,  9.56830103e-03,\n",
       "        9.50750802e-03,  9.39785969e-03,  9.24552791e-03,  9.06066690e-03,\n",
       "        8.85603577e-03,  8.64589028e-03,  8.44552461e-03,  8.26826971e-03,\n",
       "        8.12568236e-03,  8.02640896e-03,  7.97487982e-03,  7.97174219e-03,\n",
       "        8.01206473e-03,  8.08819663e-03,  8.18887632e-03,  8.30098521e-03,\n",
       "        8.40930082e-03,  8.50034505e-03,  8.56128242e-03,  8.58222693e-03,\n",
       "        8.55719205e-03,  8.48323386e-03,  8.36319569e-03,  8.20191484e-03,\n",
       "        8.01000651e-03,  7.79933436e-03,  7.58372666e-03,  7.37712905e-03,\n",
       "        7.19282776e-03,  7.04204803e-03,  6.93296408e-03,  6.86949072e-03,\n",
       "        6.85211644e-03,  6.87724259e-03,  6.93616876e-03,  7.01945787e-03,\n",
       "        7.11324438e-03,  7.20381550e-03,  7.27792131e-03,  7.32356589e-03,\n",
       "        7.33135222e-03,  7.29477825e-03,  7.21205398e-03,  7.08485162e-03,\n",
       "        6.91885129e-03,  6.72327634e-03,  6.50973478e-03,  6.29172195e-03,\n",
       "        6.08241465e-03,  5.89511823e-03,  5.73959807e-03,  5.62446332e-03,\n",
       "        5.55333402e-03,  5.52638248e-03,  5.54034021e-03,  5.58719272e-03,\n",
       "        5.65685844e-03,  5.73709141e-03,  5.81471762e-03,  5.87666966e-03,\n",
       "        5.91132697e-03,  5.90997888e-03,  5.86621929e-03,  5.77831361e-03,\n",
       "        5.64749213e-03,  5.48040541e-03,  5.28455013e-03,  5.07202046e-03,\n",
       "        4.85535245e-03,  4.64733643e-03,  4.45985049e-03,  4.30379109e-03,\n",
       "        4.18630708e-03,  4.11129836e-03,  4.07894468e-03,  4.08571819e-03,\n",
       "        4.12456412e-03,  4.18564025e-03,  4.25674208e-03,  4.32570232e-03,\n",
       "        4.37949225e-03,  4.40753950e-03,  4.40069474e-03,  4.35357867e-03,\n",
       "        4.26402083e-03,  4.13374696e-03,  3.96841252e-03,  3.77602200e-03,\n",
       "        3.56749864e-03,  3.35511612e-03,  3.15107522e-03,  2.96776043e-03,\n",
       "        2.81411153e-03,  2.69780355e-03,  2.62268679e-03,  2.58851261e-03,\n",
       "        2.59232102e-03,  2.62695760e-03,  2.68287561e-03,  2.74886144e-03,\n",
       "        2.81266822e-03,  2.86242878e-03,  2.88707623e-03,  2.87836371e-03,\n",
       "        2.83131236e-03,  2.74379295e-03,  2.61645112e-03,  2.45619775e-03,\n",
       "        2.26970389e-03,  2.06799246e-03,  1.86292327e-03,  1.66594982e-03,\n",
       "        1.48901273e-03,  1.34092756e-03,  1.22890773e-03,  1.15649181e-03,\n",
       "        1.12411962e-03,  1.12812046e-03,  1.16194750e-03,  1.21674570e-03,\n",
       "        1.28085143e-03,  1.34309521e-03,  1.39185728e-03,  1.41660566e-03,\n",
       "        1.40946242e-03,  1.36506162e-03,  1.28198799e-03,  1.16118055e-03,\n",
       "        1.00785645e-03,  8.30108824e-04,  6.37691061e-04,  4.41919256e-04,\n",
       "        2.54813378e-04,  8.65015245e-05, -5.33981947e-05, -1.58499606e-04,\n",
       "       -2.25362717e-04, -2.53517937e-04, -2.46402691e-04, -2.10591126e-04,\n",
       "       -1.54639565e-04, -8.92751486e-05, -2.55326140e-05,  2.47886437e-05,\n",
       "        5.21381407e-05,  4.88838268e-05,  1.00533462e-05, -6.65884218e-05,\n",
       "       -1.78993141e-04, -3.22582840e-04, -4.89651167e-04, -6.70906797e-04,\n",
       "       -8.54867627e-04, -1.03079178e-03, -1.18806097e-03, -1.31799118e-03,\n",
       "       -1.41398574e-03, -1.47296069e-03, -1.49459776e-03, -1.48241920e-03,\n",
       "       -1.44188164e-03, -1.38212938e-03, -1.31329359e-03, -1.24620122e-03,\n",
       "       -1.19194854e-03, -1.15930277e-03, -1.15648890e-03, -1.18831417e-03,\n",
       "       -1.25644077e-03, -1.35871419e-03, -1.49122439e-03, -1.64631463e-03,\n",
       "       -1.81455840e-03, -1.98579719e-03, -2.14898959e-03, -2.29372573e-03,\n",
       "       -2.41222582e-03, -2.49749352e-03, -2.54701613e-03, -2.56036548e-03,\n",
       "       -2.54103006e-03, -2.49431003e-03, -2.42907321e-03, -2.35488103e-03,\n",
       "       -2.28260830e-03, -2.22227536e-03, -2.18362547e-03, -2.17362843e-03,\n",
       "       -2.19650241e-03, -2.25437712e-03, -2.34599411e-03, -2.46609631e-03,\n",
       "       -2.60802079e-03, -2.76253070e-03, -2.91993003e-03, -3.06925760e-03,\n",
       "       -3.20037617e-03, -3.30605358e-03, -3.37984180e-03, -3.41892499e-03,\n",
       "       -3.42308148e-03, -3.39508196e-03, -3.34124430e-03, -3.26912059e-03,\n",
       "       -3.18860705e-03, -3.10973544e-03, -3.04275798e-03, -2.99651898e-03,\n",
       "       -2.97777308e-03, -2.99116550e-03, -3.03875771e-03, -3.11823003e-03,\n",
       "       -3.22563667e-03, -3.35385371e-03, -3.49450135e-03, -3.63722933e-03,\n",
       "       -3.77207412e-03, -3.88973602e-03, -3.98228830e-03, -4.04405640e-03,\n",
       "       -4.07192577e-03, -4.06616321e-03, -4.02909564e-03, -3.96703556e-03,\n",
       "       -3.88751831e-03, -3.79986363e-03, -3.71390698e-03, -3.63941281e-03,\n",
       "       -3.58506851e-03, -3.55767016e-03, -3.56133445e-03, -3.59769096e-03,\n",
       "       -3.66538297e-03, -3.75965168e-03, -3.87442368e-03, -4.00065491e-03,\n",
       "       -4.12915694e-03, -4.24977858e-03, -4.35397401e-03, -4.43315785e-03,\n",
       "       -4.48283553e-03, -4.49954765e-03, -4.48349956e-03, -4.43739071e-03,\n",
       "       -4.36721835e-03, -4.27971035e-03, -4.18499159e-03, -4.09175502e-03,\n",
       "       -4.00974182e-03, -3.94721841e-03, -3.91075201e-03, -3.90482950e-03,\n",
       "       -3.93058546e-03, -3.98640241e-03, -4.06793458e-03, -4.16922709e-03,\n",
       "       -4.28204425e-03, -4.39627934e-03, -4.50315885e-03, -4.59355861e-03,\n",
       "       -4.66049416e-03, -4.69812099e-03, -4.70364559e-03, -4.67826426e-03,\n",
       "       -4.62325290e-03, -4.54486348e-03, -4.45020339e-03, -4.34822636e-03,\n",
       "       -4.24786797e-03, -4.15872410e-03, -4.08869190e-03, -4.04420495e-03,\n",
       "       -4.02877200e-03, -4.04453510e-03, -4.08917246e-03, -4.15919721e-03,\n",
       "       -4.24803933e-03, -4.34756093e-03, -4.44919569e-03, -4.54315869e-03,\n",
       "       -4.62125428e-03, -4.67599183e-03, -4.70297458e-03, -4.69869608e-03,\n",
       "       -4.66363179e-03, -4.60061524e-03, -4.51518828e-03, -4.41371836e-03,\n",
       "       -4.30511963e-03, -4.19862848e-03, -4.10321122e-03, -4.02627699e-03,\n",
       "       -3.97393992e-03, -3.95040028e-03, -3.95684596e-03, -3.99170909e-03,\n",
       "       -4.05084249e-03, -4.12847148e-03, -4.21598181e-03, -4.30561602e-03,\n",
       "       -4.38805623e-03, -4.45465883e-03, -4.49852971e-03, -4.51552868e-03,\n",
       "       -4.50224336e-03, -4.45891777e-03, -4.38904017e-03, -4.29651514e-03,\n",
       "       -4.18951362e-03, -4.07545315e-03, -3.96352913e-03, -3.86244268e-03,\n",
       "       -3.77960992e-03, -3.72097199e-03, -3.69021227e-03, -3.68848233e-03,\n",
       "       -3.71447508e-03, -3.76426568e-03, -3.83163989e-03, -3.90916597e-03,\n",
       "       -3.98824085e-03, -4.06030426e-03, -4.11686068e-03, -4.15176619e-03,\n",
       "       -4.15992504e-03, -4.13920311e-03, -4.08938061e-03, -4.01315745e-03,\n",
       "       -3.91588220e-03, -3.80423455e-03, -3.68607510e-03, -3.57023557e-03,\n",
       "       -3.46496492e-03, -3.37766367e-03, -3.31392582e-03, -3.27747338e-03,\n",
       "       -3.26901465e-03, -3.28792608e-03, -3.32929054e-03, -3.38862790e-03,\n",
       "       -3.45736556e-03, -3.52727971e-03, -3.59053980e-03, -3.63867753e-03,\n",
       "       -3.66581883e-03, -3.66719300e-03, -3.63972900e-03, -3.58472834e-03,\n",
       "       -3.50417173e-03, -3.40300030e-03, -3.28795286e-03, -3.16736032e-03,\n",
       "       -3.04866815e-03, -2.94076372e-03, -2.85009760e-03, -2.78287404e-03,\n",
       "       -2.74206139e-03, -2.72907177e-03, -2.74216221e-03, -2.77759763e-03,\n",
       "       -2.82986392e-03, -2.89155263e-03, -2.95464485e-03, -3.01056379e-03,\n",
       "       -3.05206887e-03, -3.07328464e-03, -3.06904665e-03, -3.03777470e-03,\n",
       "       -2.97850347e-03, -2.89488933e-03, -2.79197446e-03, -2.67521827e-03,\n",
       "       -2.55276007e-03, -2.43331539e-03, -2.32387544e-03, -2.23189429e-03,\n",
       "       -2.16251542e-03, -2.11916491e-03, -2.10240879e-03, -2.11155554e-03,\n",
       "       -2.14268640e-03, -2.18957965e-03, -2.24600406e-03, -2.30358914e-03,\n",
       "       -2.35429569e-03, -2.39087711e-03, -2.40721530e-03, -2.39935727e-03,\n",
       "       -2.36453116e-03, -2.30362546e-03, -2.21884460e-03, -2.11471645e-03,\n",
       "       -1.99780869e-03, -1.87584327e-03, -1.75637007e-03, -1.64723850e-03,\n",
       "       -1.55497272e-03, -1.48529105e-03, -1.44059490e-03, -1.42257370e-03,\n",
       "       -1.42937619e-03, -1.45770202e-03, -1.50156126e-03, -1.55390496e-03,\n",
       "       -1.60796172e-03, -1.65532285e-03, -1.68841542e-03, -1.70281564e-03,\n",
       "       -1.69231836e-03, -1.65632414e-03, -1.59469491e-03, -1.50999345e-03,\n",
       "       -1.40686170e-03, -1.29141274e-03, -1.17116142e-03, -1.05341210e-03,\n",
       "       -9.45973152e-04, -8.55266815e-04, -7.86556455e-04, -7.42648903e-04,\n",
       "       -7.24460580e-04, -7.30509637e-04, -7.56951398e-04, -7.98965048e-04,\n",
       "       -8.49718868e-04, -9.01517749e-04, -9.46427870e-04, -9.78306867e-04,\n",
       "       -9.90657136e-04, -9.79901291e-04, -9.43933788e-04, -8.82854278e-04,\n",
       "       -7.99861562e-04, -6.98797288e-04, -5.86160750e-04, -4.68533020e-04,\n",
       "       -3.54399905e-04, -2.49682955e-04, -1.62276017e-04, -9.61047190e-05,\n",
       "       -5.38434033e-05, -3.71347051e-05, -4.38953539e-05, -7.10718377e-05,\n",
       "       -1.12668007e-04, -1.62949116e-04, -2.14163854e-04, -2.58773856e-04,\n",
       "       -2.90252035e-04, -3.03299923e-04, -2.93638499e-04, -2.58784246e-04,\n",
       "       -2.00414506e-04, -1.20524317e-04, -2.26554748e-05,  8.57558334e-05,\n",
       "        1.98909300e-04,  3.09110677e-04,  4.08846681e-04,  4.92630003e-04,\n",
       "        5.55209932e-04,  5.93963428e-04,  6.08146656e-04,  5.99179417e-04,\n",
       "        5.70943928e-04,  5.27704484e-04,  4.76721616e-04,  4.25036298e-04,\n",
       "        3.79367557e-04,  3.46730463e-04,  3.32338706e-04,  3.40459344e-04,\n",
       "        3.72164155e-04,  4.27543360e-04,  5.03651041e-04,  5.96824626e-04,\n",
       "        7.00602017e-04,  8.08254350e-04,  9.13365162e-04,  1.00776285e-03,\n",
       "        1.08658965e-03,  1.14435959e-03,  1.17912062e-03,  1.18982128e-03,\n",
       "        1.17783085e-03,  1.14682072e-03,  1.10169279e-03,  1.04878657e-03,\n",
       "        9.95161245e-04,  9.47823573e-04,  9.13351658e-04,  8.96420039e-04,\n",
       "        9.01324849e-04,  9.29070229e-04,  9.79993842e-04,  1.05158449e-03,\n",
       "        1.13907235e-03,  1.23703433e-03,  1.33842381e-03,  1.43723062e-03,\n",
       "        1.52578647e-03,  1.59820146e-03,  1.65076554e-03,  1.68024295e-03,\n",
       "        1.68663159e-03,  1.67066976e-03,  1.63565867e-03,  1.58777216e-03,\n",
       "        1.53228187e-03,  1.47589704e-03,  1.42557442e-03,  1.38784479e-03,\n",
       "        1.36808888e-03,  1.36924104e-03,  1.39271747e-03,  1.43888302e-03,\n",
       "        1.50451635e-03,  1.58592290e-03,  1.67759974e-03,  1.77236367e-03,\n",
       "        1.86396122e-03,  1.94592623e-03,  2.01221695e-03,  2.05895794e-03,\n",
       "        2.08259467e-03,  2.08346220e-03,  2.06305785e-03,  2.02446338e-03,\n",
       "        1.97237334e-03,  1.91370677e-03,  1.85387291e-03,  1.80058694e-03,\n",
       "        1.75951701e-03,  1.73559599e-03,  1.73234195e-03,  1.75122090e-03,\n",
       "        1.79187616e-03,  1.85156683e-03,  1.92667579e-03,  2.01126025e-03,\n",
       "        2.09911377e-03,  2.18402292e-03,  2.25855014e-03,  2.31794477e-03,\n",
       "        2.35780491e-03,  2.37604859e-03,  2.37179617e-03,  2.34651193e-03,\n",
       "        2.30320147e-03,  2.24718498e-03,  2.18412955e-03,  2.12153839e-03,\n",
       "        2.06451770e-03,  2.01971387e-03,  1.99185242e-03,  1.98384328e-03,\n",
       "        1.99748785e-03,  2.03261292e-03,  2.08641449e-03,  2.15489091e-03,\n",
       "        2.23247055e-03,  2.31362786e-03,  2.39109341e-03,  2.45860568e-03,\n",
       "        2.51126569e-03,  2.54480680e-03,  2.55694380e-03,  2.54657865e-03,\n",
       "        2.51654186e-03,  2.46967911e-03,  2.40935083e-03,  2.34275474e-03,\n",
       "        2.27585481e-03,  2.21515656e-03,  2.16651079e-03,  2.13443767e-03,\n",
       "        2.12202454e-03,  2.13067210e-03,  2.16016034e-03,  2.20763660e-03,\n",
       "        2.26974930e-03,  2.34084716e-03,  2.41463259e-03,  2.48490227e-03,\n",
       "        2.54557352e-03,  2.59131915e-03,  2.61838944e-03,  2.62454082e-03,\n",
       "        2.60951929e-03,  2.57400027e-03,  2.52199289e-03,  2.45820126e-03,\n",
       "        2.38800747e-03,  2.31756107e-03,  2.25321669e-03,  2.20082072e-03,\n",
       "        2.16487562e-03,  2.14781146e-03,  2.15204363e-03,  2.17622123e-03,\n",
       "        2.21824367e-03,  2.27435399e-03,  2.33870652e-03,  2.40578828e-03,\n",
       "        2.46941531e-03,  2.52378546e-03,  2.56333081e-03,  2.58446345e-03,\n",
       "        2.58508348e-03,  2.56490079e-03,  2.52492749e-03,  2.46911193e-03,\n",
       "        2.40149582e-03,  2.32776930e-03,  2.25405116e-03,  2.18684948e-03,\n",
       "        2.13082344e-03,  2.09128740e-03,  2.07092613e-03,  2.07018014e-03,\n",
       "        2.08960706e-03,  2.12631910e-03,  2.17661844e-03,  2.23494857e-03,\n",
       "        2.29600538e-03,  2.35356879e-03,  2.40157242e-03,  2.43544276e-03,\n",
       "        2.45100050e-03,  2.44674226e-03,  2.42180168e-03,  2.37867981e-03,\n",
       "        2.31892755e-03,  2.24825321e-03,  2.17164401e-03,  2.09502969e-03,\n",
       "        2.02519703e-03,  1.96678308e-03,  1.92432769e-03,  1.90022669e-03,\n",
       "        1.89600361e-03,  1.91106112e-03,  1.94319920e-03,  1.98848592e-03,\n",
       "        2.04169215e-03,  2.09737592e-03,  2.14922545e-03,  2.19206698e-03,\n",
       "        2.22079433e-03,  2.23181630e-03,  2.22299853e-03,  2.19425326e-03,\n",
       "        2.14739027e-03,  2.08497536e-03,  2.01175618e-03,  1.93309493e-03,\n",
       "        1.85466302e-03,  1.78248214e-03,  1.72167784e-03,  1.67656504e-03,\n",
       "        1.64994074e-03,  1.64269016e-03,  1.65444368e-03,  1.68267742e-03,\n",
       "        1.72360858e-03,  1.77258346e-03,  1.82345940e-03,  1.87067944e-03,\n",
       "        1.90902082e-03,  1.93330029e-03,  1.94017251e-03,  1.92825869e-03,\n",
       "        1.89660804e-03,  1.84680789e-03,  1.78196444e-03,  1.70758599e-03,\n",
       "        1.62728271e-03,  1.54773390e-03,  1.47443532e-03,  1.41236442e-03,\n",
       "        1.36567105e-03,  1.33704324e-03,  1.32775214e-03,  1.33675954e-03,\n",
       "        1.36175100e-03,  1.39967469e-03,  1.44474627e-03,  1.49179180e-03,\n",
       "        1.53583463e-03,  1.57016120e-03,  1.59099663e-03,  1.59502053e-03,\n",
       "        1.58003869e-03,  1.54606323e-03,  1.49493397e-03,  1.42884860e-03,\n",
       "        1.35298993e-03,  1.27228443e-03,  1.19225134e-03,  1.11834286e-03,\n",
       "        1.05561165e-03,  1.00841175e-03,  9.78658907e-04,  9.67818778e-04,\n",
       "        9.75284260e-04,  9.98350792e-04,  1.03349041e-03,  1.07598992e-03,\n",
       "        1.12055033e-03,  1.16096414e-03,  1.19291176e-03,  1.21148839e-03,\n",
       "        1.21322344e-03,  1.19630352e-03,  1.16147811e-03,  1.10923487e-03,\n",
       "        1.04299199e-03,  9.66976164e-04,  8.86477355e-04,  8.06699623e-04,\n",
       "        7.33015535e-04,  6.70878566e-04,  6.23811735e-04,  5.93707839e-04,\n",
       "        5.82493609e-04,  5.88950119e-04,  6.10971299e-04,  6.44352112e-04,\n",
       "        6.85107778e-04,  7.27559847e-04,  7.65906589e-04,  7.96330860e-04,\n",
       "        8.13171908e-04,  8.13667430e-04,  7.96011300e-04,  7.60293624e-04,\n",
       "        7.08407839e-04,  6.42477185e-04,  5.67109440e-04,  4.87775251e-04,\n",
       "        4.09276981e-04,  3.37291625e-04,  2.76025996e-04,  2.29545985e-04,\n",
       "        2.00727329e-04,  1.89357932e-04,  1.95578716e-04,  2.17333727e-04,\n",
       "        2.49705539e-04,  2.90034252e-04,  3.31277522e-04,  3.68917041e-04,\n",
       "        3.98005504e-04,  4.14185459e-04,  4.13999805e-04,  3.96612624e-04,\n",
       "        3.61094979e-04,  3.10009142e-04,  2.45002651e-04,  1.71405933e-04,\n",
       "        9.37843797e-05,  1.69555587e-05, -5.34566971e-05, -1.12605725e-04,\n",
       "       -1.57066184e-04, -1.85095385e-04, -1.95041212e-04, -1.87616562e-04,\n",
       "       -1.65538033e-04, -1.33048336e-04, -9.30505921e-05, -5.18157540e-05,\n",
       "       -1.43522848e-05,  1.45530494e-05,  3.07103219e-05,  3.09146963e-05,\n",
       "        1.43791140e-05, -1.99043388e-05, -6.99414595e-05, -1.32402900e-04,\n",
       "       -2.03808013e-04, -2.79112806e-04, -3.52934730e-04, -4.20878670e-04,\n",
       "       -4.77802852e-04, -5.19708265e-04, -5.44994953e-04, -5.53468359e-04,\n",
       "       -5.44814218e-04, -5.21840993e-04, -4.87843587e-04, -4.47827886e-04,\n",
       "       -4.06071456e-04, -3.67906818e-04, -3.38542130e-04, -3.21741536e-04,\n",
       "       -3.20225576e-04, -3.35824589e-04, -3.68061126e-04, -4.16283234e-04,\n",
       "       -4.76070505e-04, -5.44639246e-04, -6.16699923e-04, -6.87173218e-04,\n",
       "       -7.51742919e-04, -8.05387390e-04, -8.44745431e-04, -8.67538911e-04,\n",
       "       -8.73297220e-04, -8.62787827e-04, -8.37925647e-04, -8.02498485e-04,\n",
       "       -7.61246250e-04, -7.18985451e-04, -6.79555931e-04, -6.48815650e-04,\n",
       "       -6.30899798e-04, -6.27553207e-04, -6.41302380e-04, -6.71075657e-04,\n",
       "       -7.16427283e-04, -7.73311069e-04, -8.38420237e-04, -9.07012320e-04,\n",
       "       -9.74401017e-04, -1.03497470e-03, -1.08472444e-03, -1.12074416e-03,\n",
       "       -1.14037981e-03, -1.14357763e-03, -1.13008602e-03, -1.10341050e-03,\n",
       "       -1.06600509e-03, -1.02288451e-03, -9.78909200e-04, -9.37977107e-04,\n",
       "       -9.06132860e-04, -8.86146561e-04, -8.81172018e-04, -8.92151147e-04,\n",
       "       -9.19404498e-04, -9.61348298e-04, -1.01525604e-03, -1.07673695e-03,\n",
       "       -1.14126375e-03, -1.20422314e-03, -1.26076839e-03, -1.30674907e-03,\n",
       "       -1.33881392e-03, -1.35515269e-03, -1.35464908e-03, -1.33900926e-03,\n",
       "       -1.30933174e-03, -1.26992690e-03, -1.22480455e-03, -1.17830141e-03,\n",
       "       -1.13620039e-03, -1.10190629e-03, -1.08022161e-03, -1.07271189e-03,\n",
       "       -1.08103163e-03, -1.10564171e-03, -1.14424212e-03, -1.19418697e-03,\n",
       "       -1.25181209e-03, -1.31245260e-03, -1.37110834e-03, -1.42366881e-03,\n",
       "       -1.46531791e-03, -1.49358623e-03, -1.50631845e-03, -1.50252692e-03,\n",
       "       -1.48378476e-03, -1.45148765e-03, -1.40944775e-03, -1.36185542e-03,\n",
       "       -1.31386181e-03, -1.26959872e-03, -1.23352301e-03, -1.20913517e-03,\n",
       "       -1.19947549e-03, -1.20502186e-03, -1.22674508e-03, -1.26147678e-03,\n",
       "       -1.30769110e-03, -1.36143330e-03, -1.41737028e-03, -1.47186464e-03,\n",
       "       -1.52048864e-03, -1.55794306e-03, -1.58201111e-03, -1.59103400e-03,\n",
       "       -1.58372649e-03, -1.56199711e-03, -1.52749266e-03, -1.48243667e-03,\n",
       "       -1.43299310e-03, -1.38286932e-03, -1.33643602e-03, -1.29848288e-03,\n",
       "       -1.27160084e-03, -1.25928130e-03, -1.26234151e-03, -1.28067832e-03,\n",
       "       -1.31219660e-03, -1.35508180e-03, -1.40469882e-03, -1.45684986e-03,\n",
       "       -1.50749949e-03, -1.55109598e-03, -1.58457283e-03, -1.60531129e-03,\n",
       "       -1.61081506e-03, -1.59980392e-03, -1.57486834e-03, -1.53750647e-03,\n",
       "       -1.49097003e-03, -1.43877720e-03, -1.38669461e-03, -1.33823906e-03,\n",
       "       -1.29790127e-03, -1.26960315e-03, -1.25520758e-03, -1.25512516e-03,\n",
       "       -1.27078767e-03, -1.29920465e-03, -1.33819703e-03, -1.38414826e-03,\n",
       "       -1.43263058e-03, -1.47892768e-03, -1.51913252e-03, -1.54885068e-03,\n",
       "       -1.56548340e-03, -1.56748050e-03, -1.55387970e-03, -1.52598729e-03,\n",
       "       -1.48603937e-03, -1.43732154e-03, -1.38378236e-03, -1.32941315e-03,\n",
       "       -1.27940427e-03, -1.23708544e-03, -1.20628008e-03, -1.18999381e-03,\n",
       "       -1.18790637e-03, -1.20041089e-03, -1.22602284e-03, -1.26225338e-03,\n",
       "       -1.30431820e-03, -1.34899700e-03, -1.39193179e-03, -1.42794161e-03,\n",
       "       -1.45437790e-03, -1.46767276e-03, -1.46647729e-03, -1.45029626e-03,\n",
       "       -1.42001570e-03, -1.37801503e-03, -1.32757192e-03, -1.27220212e-03,\n",
       "       -1.21635862e-03, -1.16518827e-03, -1.12138456e-03, -1.08979177e-03,\n",
       "       -1.07108359e-03, -1.06728077e-03, -1.07771042e-03, -1.10080268e-03,\n",
       "       -1.13367673e-03, -1.17368402e-03, -1.21505128e-03, -1.25482748e-03,\n",
       "       -1.28778722e-03, -1.31101022e-03, -1.32140412e-03, -1.31762656e-03,\n",
       "       -1.29913841e-03, -1.26695493e-03, -1.22350955e-03, -1.17086899e-03,\n",
       "       -1.11453119e-03, -1.05755718e-03, -1.00539310e-03, -9.60804755e-04,\n",
       "       -9.27402172e-04, -9.07602429e-04, -9.01833759e-04, -9.10615316e-04,\n",
       "       -9.31341259e-04, -9.61868907e-04, -9.98849981e-04, -1.03805738e-03,\n",
       "       -1.07457826e-03, -1.10486848e-03, -1.12541264e-03, -1.13346777e-03,\n",
       "       -1.12733117e-03, -1.10668561e-03, -1.07278826e-03, -1.02785171e-03,\n",
       "       -9.74678260e-04, -9.17620782e-04, -8.60057131e-04, -8.07069940e-04,\n",
       "       -7.61924079e-04, -7.28100771e-04, -7.07302126e-04, -7.01102952e-04,\n",
       "       -7.07591709e-04, -7.27072242e-04, -7.55798654e-04, -7.90447521e-04,\n",
       "       -8.27396521e-04, -8.61710694e-04, -8.89685354e-04, -9.08269372e-04,\n",
       "       -9.14460630e-04, -9.06823028e-04, -8.85162852e-04, -8.50305718e-04,\n",
       "       -8.04464449e-04, -7.51188491e-04, -6.93689741e-04, -6.36545999e-04,\n",
       "       -5.83215035e-04, -5.37951943e-04, -5.04134921e-04, -4.82994830e-04,\n",
       "       -4.75931127e-04, -4.82315314e-04, -5.00586524e-04, -5.28134988e-04,\n",
       "       -5.61385008e-04, -5.96419268e-04, -6.29089132e-04, -6.55930606e-04,\n",
       "       -6.72783703e-04, -6.77355507e-04, -6.68685418e-04, -6.46230124e-04,\n",
       "       -6.10807969e-04, -5.64474612e-04, -5.11273334e-04, -4.53873101e-04,\n",
       "       -3.97125958e-04, -3.44277243e-04, -2.99542211e-04, -2.65677663e-04,\n",
       "       -2.44873198e-04, -2.37604138e-04, -2.43245668e-04, -2.61204696e-04,\n",
       "       -2.87731586e-04, -3.19851591e-04, -3.53765528e-04, -3.85235122e-04,\n",
       "       -4.10869281e-04, -4.26479441e-04, -4.30394197e-04, -4.21115634e-04,\n",
       "       -3.97947588e-04, -3.62935185e-04, -3.17133177e-04, -2.64234695e-04,\n",
       "       -2.07750636e-04, -1.51861313e-04, -9.99414260e-05, -5.59956607e-05,\n",
       "       -2.29368034e-05, -2.90138928e-06,  3.78335812e-06, -2.37465429e-06,\n",
       "       -1.96592937e-05, -4.65019584e-05, -7.82900825e-05, -1.11856687e-04,\n",
       "       -1.42303281e-04, -1.67249091e-04, -1.82593270e-04, -1.86331294e-04,\n",
       "       -1.77109439e-04, -1.54539171e-04, -1.18926589e-04, -7.45900470e-05,\n",
       "       -2.29309862e-05,  3.29803479e-05,  8.73907848e-05,  1.37621086e-04,\n",
       "        1.80465970e-04,  2.12037892e-04,  2.31149592e-04,  2.36539694e-04,\n",
       "        2.29974175e-04,  2.12053783e-04,  1.85158977e-04,  1.53381741e-04,\n",
       "        1.20050034e-04,  8.89618459e-05,  6.46605695e-05,  4.88660480e-05,\n",
       "        4.51789201e-05,  5.40818619e-05,  7.60244511e-05,  1.09753200e-04,\n",
       "        1.53121291e-04,  2.03783216e-04,  2.57154024e-04,  3.10520001e-04,\n",
       "        3.59309866e-04,  3.99688754e-04,  4.29724751e-04,  4.47331986e-04,\n",
       "        4.51984029e-04,  4.44084581e-04,  4.25137056e-04,  3.98200849e-04,\n",
       "        3.65901971e-04,  3.32228810e-04,  3.00856133e-04,  2.76355946e-04,\n",
       "        2.60084315e-04,  2.55934981e-04,  2.64420902e-04,  2.84966663e-04,\n",
       "        3.17556580e-04,  3.59911646e-04,  4.08428226e-04,  4.59834730e-04,\n",
       "        5.10722806e-04,  5.57282532e-04,  5.95298188e-04,  6.23396889e-04,\n",
       "        6.39230886e-04,  6.42127707e-04,  6.32803189e-04,  6.12256583e-04,\n",
       "        5.83929592e-04,  5.51466539e-04,  5.16770291e-04,  4.85219003e-04,\n",
       "        4.59245231e-04,  4.42831777e-04,  4.37378767e-04,  4.44146746e-04,\n",
       "        4.63563163e-04,  4.95101616e-04,  5.34859020e-04,  5.81204251e-04,\n",
       "        6.30294904e-04,  6.78847544e-04,  7.22408935e-04,  7.58833950e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scattering_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19524"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "num_tokens = len(encoding.encode(str(scattering_files[0])))\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scattering_files[0].round(3)[::15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "num_tokens = len(encoding.encode(str(scattering_files[0].round(3)[::15])))\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distribution of num of atoms values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([285., 247., 228., 171., 171., 209., 133., 152., 171., 190.]),\n",
       " array([  6. ,  15.4,  24.8,  34.2,  43.6,  53. ,  62.4,  71.8,  81.2,\n",
       "         90.6, 100. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3.5, 2.5))\n",
    "plt.hist(num_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering_patterns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(scattering_files)):\n",
    "    pattern = scattering_files[i].round(3)[::15]\n",
    "    scattering_patterns.append(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scattering_patterns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare regression dataset for number of atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering_patterns = np.array(scattering_patterns)\n",
    "num_atoms = np.array(num_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD_num = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_atoms_binned = np.array([1 if value > THRESHOLD_num else 0 for value in num_atoms])\n",
    "num_atoms_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([1311,  646]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(num_atoms_binned, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TEST_DATA = 2000\n",
    "train_size = 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
       "         11,   12,   13,   14,   15,   16,   17,   18,   19,   20,   21,\n",
       "         22,   23,   24,   25,   26,   27,   28,   29,   30,   31,   32,\n",
       "         33,   34,   35,   36,   37,   38,   39,   40,   41,   42,   43,\n",
       "         44,   45,   46,   47,   48,   49,   50,   51,   52,   53,   54,\n",
       "         55,   56,   57,   58,   59,   60,   61,   62,   63,   64,   65,\n",
       "         66,   67,   68,   69,   70,   71,   72,   73,   74,   75,   76,\n",
       "         77,   78,   79,   80,   81,   82,   83,   84,   85,   86,   87,\n",
       "         88,   89,   90,   91,   92,   93,   94,   95,   96,   97,   98,\n",
       "         99,  100,  101,  102,  103,  104,  105,  106,  107,  108,  109,\n",
       "        110,  111,  112,  113,  114,  115,  116,  117,  118,  119,  120,\n",
       "        121,  122,  123,  124,  125,  126,  127,  128,  129,  130,  131,\n",
       "        132,  133,  134,  135,  136,  137,  138,  139,  140,  141,  142,\n",
       "        143,  144,  145,  146,  147,  148,  149,  150,  151,  152,  153,\n",
       "        154,  155,  156,  157,  158,  159,  160,  161,  162,  163,  164,\n",
       "        165,  166,  167,  168,  169,  170,  171,  172,  173,  174,  175,\n",
       "        176,  177,  178,  179,  180,  181,  182,  183,  184,  185,  186,\n",
       "        187,  188,  189,  190,  191,  192,  193,  194,  195,  196,  197,\n",
       "        198,  199,  200,  201,  202,  203,  204,  205,  206,  207,  208,\n",
       "        209,  210,  211,  212,  213,  214,  215,  216,  217,  218,  219,\n",
       "        220,  221,  222,  223,  224,  225,  226,  227,  228,  229,  230,\n",
       "        231,  232,  233,  234,  235,  236,  237,  238,  239,  240,  241,\n",
       "        242,  243,  244,  245,  246,  247,  248,  249,  250,  251,  252,\n",
       "        253,  254,  255,  256,  257,  258,  259,  260,  261,  262,  263,\n",
       "        264,  265,  266,  267,  268,  269,  270,  271,  272,  273,  274,\n",
       "        275,  276,  277,  278,  279,  280,  281,  282,  283,  284,  285,\n",
       "        286,  287,  288,  289,  290,  291,  292,  293,  294,  295,  296,\n",
       "        297,  298,  299,  300,  301,  302,  303,  304,  305,  306,  307,\n",
       "        308,  309,  310,  311,  312,  313,  314,  315,  316,  317,  318,\n",
       "        319,  320,  321,  322,  323,  324,  325,  326,  327,  328,  329,\n",
       "        330,  331,  332,  333,  334,  335,  336,  337,  338,  339,  340,\n",
       "        341,  342,  343,  344,  345,  346,  347,  348,  349,  350,  351,\n",
       "        352,  353,  354,  355,  356,  357,  358,  359,  360,  361,  362,\n",
       "        363,  364,  365,  366,  367,  368,  369,  370,  371,  372,  373,\n",
       "        374,  375,  376,  377,  378,  379,  380,  381,  382,  383,  384,\n",
       "        385,  386,  387,  388,  389,  390,  391,  392,  393,  394,  395,\n",
       "        396,  397,  398,  399,  400,  401,  402,  403,  404,  405,  406,\n",
       "        407,  408,  409,  410,  411,  412,  413,  414,  415,  416,  417,\n",
       "        418,  419,  420,  421,  422,  423,  424,  425,  426,  427,  428,\n",
       "        429,  430,  431,  432,  433,  434,  435,  436,  437,  438,  439,\n",
       "        440,  441,  442,  443,  444,  445,  446,  447,  448,  449,  450,\n",
       "        451,  452,  453,  454,  455,  456,  457,  458,  459,  460,  461,\n",
       "        462,  463,  464,  465,  466,  467,  468,  469,  470,  471,  472,\n",
       "        473,  474,  475,  476,  477,  478,  479,  480,  481,  482,  483,\n",
       "        484,  485,  486,  487,  488,  489,  490,  491,  492,  493,  494,\n",
       "        495,  496,  497,  498,  499,  500,  501,  502,  503,  504,  505,\n",
       "        506,  507,  508,  509,  510,  511,  512,  513,  514,  515,  516,\n",
       "        517,  518,  519,  520,  521,  522,  523,  524,  525,  526,  527,\n",
       "        528,  529,  530,  531,  532,  533,  534,  535,  536,  537,  538,\n",
       "        539,  540,  541,  542,  543,  544,  545,  546,  547,  548,  549,\n",
       "        550,  551,  552,  553,  554,  555,  556,  557,  558,  559,  560,\n",
       "        561,  562,  563,  564,  565,  566,  567,  568,  569,  570,  571,\n",
       "        572,  573,  574,  575,  576,  577,  578,  579,  580,  581,  582,\n",
       "        583,  584,  585,  586,  587,  588,  589,  590,  591,  592,  593,\n",
       "        594,  595,  596,  597,  598,  599,  600,  601,  602,  603,  604,\n",
       "        605,  606,  607,  608,  609,  610,  611,  612,  613,  614,  615,\n",
       "        616,  617,  618,  619,  620,  621,  622,  623,  624,  625,  626,\n",
       "        627,  628,  629,  630,  631,  632,  633,  634,  635,  636,  637,\n",
       "        638,  639,  640,  641,  642,  643,  644,  645,  646,  647,  648,\n",
       "        649,  650,  651,  652,  653,  654,  655,  656,  657,  658,  659,\n",
       "        660,  661,  662,  663,  664,  665,  666,  667,  668,  669,  670,\n",
       "        671,  672,  673,  674,  675,  676,  677,  678,  679,  680,  681,\n",
       "        682,  683,  684,  685,  686,  687,  688,  689,  690,  691,  692,\n",
       "        693,  694,  695,  696,  697,  698,  699,  700,  701,  702,  703,\n",
       "        704,  705,  706,  707,  708,  709,  710,  711,  712,  713,  714,\n",
       "        715,  716,  717,  718,  719,  720,  721,  722,  723,  724,  725,\n",
       "        726,  727,  728,  729,  730,  731,  732,  733,  734,  735,  736,\n",
       "        737,  738,  739,  740,  741,  742,  743,  744,  745,  746,  747,\n",
       "        748,  749,  750,  751,  752,  753,  754,  755,  756,  757,  758,\n",
       "        759,  760,  761,  762,  763,  764,  765,  766,  767,  768,  769,\n",
       "        770,  771,  772,  773,  774,  775,  776,  777,  778,  779,  780,\n",
       "        781,  782,  783,  784,  785,  786,  787,  788,  789,  790,  791,\n",
       "        792,  793,  794,  795,  796,  797,  798,  799,  800,  801,  802,\n",
       "        803,  804,  805,  806,  807,  808,  809,  810,  811,  812,  813,\n",
       "        814,  815,  816,  817,  818,  819,  820,  821,  822,  823,  824,\n",
       "        825,  826,  827,  828,  829,  830,  831,  832,  833,  834,  835,\n",
       "        836,  837,  838,  839,  840,  841,  842,  843,  844,  845,  846,\n",
       "        847,  848,  849,  850,  851,  852,  853,  854,  855,  856,  857,\n",
       "        858,  859,  860,  861,  862,  863,  864,  865,  866,  867,  868,\n",
       "        869,  870,  871,  872,  873,  874,  875,  876,  877,  878,  879,\n",
       "        880,  881,  882,  883,  884,  885,  886,  887,  888,  889,  890,\n",
       "        891,  892,  893,  894,  895,  896,  897,  898,  899,  900,  901,\n",
       "        902,  903,  904,  905,  906,  907,  908,  909,  910,  911,  912,\n",
       "        913,  914,  915,  916,  917,  918,  919,  920,  921,  922,  923,\n",
       "        924,  925,  926,  927,  928,  929,  930,  931,  932,  933,  934,\n",
       "        935,  936,  937,  938,  939,  940,  941,  942,  943,  944,  945,\n",
       "        946,  947,  948,  949,  950,  951,  952,  953,  954,  955,  956,\n",
       "        957,  958,  959,  960,  961,  962,  963,  964,  965,  966,  967,\n",
       "        968,  969,  970,  971,  972,  973,  974,  975,  976,  977,  978,\n",
       "        979,  980,  981,  982,  983,  984,  985,  986,  987,  988,  989,\n",
       "        990,  991,  992,  993,  994,  995,  996,  997,  998,  999, 1000,\n",
       "       1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011,\n",
       "       1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022,\n",
       "       1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033,\n",
       "       1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044,\n",
       "       1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055,\n",
       "       1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066,\n",
       "       1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077,\n",
       "       1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088,\n",
       "       1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099,\n",
       "       1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110,\n",
       "       1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121,\n",
       "       1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132,\n",
       "       1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143,\n",
       "       1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154,\n",
       "       1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165,\n",
       "       1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176,\n",
       "       1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,\n",
       "       1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198,\n",
       "       1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209,\n",
       "       1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220,\n",
       "       1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231,\n",
       "       1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242,\n",
       "       1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253,\n",
       "       1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264,\n",
       "       1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275,\n",
       "       1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286,\n",
       "       1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297,\n",
       "       1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308,\n",
       "       1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319,\n",
       "       1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330,\n",
       "       1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341,\n",
       "       1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352,\n",
       "       1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363,\n",
       "       1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374,\n",
       "       1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385,\n",
       "       1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396,\n",
       "       1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407,\n",
       "       1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418,\n",
       "       1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429,\n",
       "       1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440,\n",
       "       1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451,\n",
       "       1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462,\n",
       "       1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473,\n",
       "       1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484,\n",
       "       1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495,\n",
       "       1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506,\n",
       "       1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517,\n",
       "       1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528,\n",
       "       1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539,\n",
       "       1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550,\n",
       "       1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561,\n",
       "       1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572,\n",
       "       1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583,\n",
       "       1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594,\n",
       "       1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605,\n",
       "       1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616,\n",
       "       1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627,\n",
       "       1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638,\n",
       "       1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649,\n",
       "       1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660,\n",
       "       1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671,\n",
       "       1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682,\n",
       "       1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693,\n",
       "       1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704,\n",
       "       1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715,\n",
       "       1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726,\n",
       "       1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737,\n",
       "       1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748,\n",
       "       1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759,\n",
       "       1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770,\n",
       "       1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781,\n",
       "       1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792,\n",
       "       1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803,\n",
       "       1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814,\n",
       "       1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825,\n",
       "       1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836,\n",
       "       1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847,\n",
       "       1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858,\n",
       "       1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869,\n",
       "       1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880,\n",
       "       1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891,\n",
       "       1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902,\n",
       "       1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913,\n",
       "       1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924,\n",
       "       1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935,\n",
       "       1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946,\n",
       "       1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(len(num_atoms))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split(\n",
    "    indices, \n",
    "    train_size=train_size, \n",
    "    test_size=min(len(indices)-train_size, MAX_TEST_DATA),\n",
    "    random_state=42,\n",
    "    stratify=num_atoms_binned\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = scattering_patterns[train_indices], num_atoms[train_indices]\n",
    "X_test, y_test = scattering_patterns[test_indices], num_atoms[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  6,   7,   8,   9,  10,  12,  13,  14,  15,  16,  18,  19,  20,\n",
       "         23,  24,  25,  27,  28,  29,  30,  32,  33,  35,  36,  39,  40,\n",
       "         42,  43,  44,  48,  49,  50,  51,  54,  55,  56,  57,  59,  60,\n",
       "         63,  64,  70,  71,  72,  75,  80,  81,  83,  84,  85,  87,  89,\n",
       "         90,  93,  95,  96,  98, 100]),\n",
       " array([34, 35, 35, 19, 19, 34, 51, 17, 19, 52, 35, 51, 16, 18, 56, 33, 31,\n",
       "        19, 18, 17, 49, 35, 19, 37, 18, 53, 15, 18, 17, 68, 18, 19, 36, 36,\n",
       "        34, 37, 37, 18, 33, 35, 52, 18, 18, 52, 15, 55, 19, 18, 35, 36, 36,\n",
       "        19, 16, 32, 18, 70, 16, 34]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  6,   7,   8,  12,  13,  14,  16,  18,  19,  20,  23,  24,  25,\n",
       "         27,  29,  30,  32,  33,  36,  39,  40,  42,  43,  44,  48,  49,\n",
       "         51,  54,  55,  56,  57,  59,  60,  63,  64,  70,  71,  72,  75,\n",
       "         80,  83,  84,  85,  87,  90,  93,  95,  96,  98, 100]),\n",
       " array([4, 3, 3, 4, 6, 2, 5, 3, 6, 3, 1, 1, 5, 7, 1, 2, 8, 3, 1, 1, 4, 4,\n",
       "        1, 2, 8, 1, 2, 2, 4, 1, 1, 1, 5, 3, 5, 1, 1, 5, 4, 2, 1, 3, 2, 2,\n",
       "        3, 6, 1, 6, 3, 4]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.   , -0.013, -0.023, -0.034, -0.047, -0.057, -0.066, -0.077,\n",
       "       -0.087, -0.092, -0.101, -0.111, -0.114, -0.115, -0.124, -0.045,\n",
       "        0.838,  0.499, -0.101, -0.133, -0.126, -0.119, -0.096,  0.086,\n",
       "       -0.021, -0.098, -0.026,  0.105,  0.108, -0.014, -0.063,  0.069,\n",
       "        0.038, -0.039, -0.047, -0.04 , -0.033, -0.028, -0.022, -0.016,\n",
       "       -0.012, -0.008, -0.004, -0.   ,  0.002,  0.005,  0.007,  0.008,\n",
       "        0.009,  0.011,  0.011,  0.01 ,  0.011,  0.01 ,  0.009,  0.008,\n",
       "        0.007,  0.006,  0.004,  0.003,  0.003,  0.001, -0.   , -0.001,\n",
       "       -0.002, -0.003, -0.004, -0.004, -0.005, -0.005, -0.005, -0.005,\n",
       "       -0.006, -0.005, -0.004, -0.004, -0.004, -0.003, -0.002, -0.002,\n",
       "       -0.001, -0.   ,  0.   ,  0.001,  0.002,  0.002,  0.002,  0.003,\n",
       "        0.003,  0.003,  0.003,  0.004,  0.003,  0.003,  0.003,  0.003,\n",
       "        0.002,  0.002,  0.002,  0.001,  0.001,  0.   ,  0.   , -0.   ,\n",
       "       -0.001, -0.001, -0.001, -0.002, -0.002, -0.002, -0.002, -0.002,\n",
       "       -0.002, -0.002, -0.002, -0.002, -0.002, -0.002, -0.002, -0.001,\n",
       "       -0.001, -0.001, -0.   ,  0.   ,  0.   ,  0.001,  0.001,  0.001,\n",
       "        0.001,  0.001,  0.002,  0.002,  0.002,  0.002], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and evaluate regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(\n",
    "    n_estimators=500, \n",
    "    random_state=42, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   27.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=500, random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(n_estimators=500, random_state=42, verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=500, random_state=42, verbose=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([70.504, 57.902, 30.35 , 78.112, 68.242, 86.316, 75.33 , 28.042,\n",
       "       65.476, 20.712, 66.23 , 67.192, 35.58 , 85.506, 68.758,  9.296,\n",
       "       40.274, 66.152, 57.832, 85.8  , 18.796, 12.93 , 69.436, 69.93 ,\n",
       "       76.67 , 58.056, 23.646, 49.674, 22.482, 74.97 , 31.318, 82.146,\n",
       "       18.114, 15.298, 80.026, 51.064, 46.984, 55.792, 56.146, 83.208,\n",
       "       28.94 , 77.412,  6.336, 39.73 , 80.146, 43.204, 16.322, 43.176,\n",
       "       80.69 , 54.906, 55.6  , 23.606, 53.088, 38.44 , 28.998, 24.304,\n",
       "       81.75 , 22.484, 12.402, 33.418, 18.812, 70.16 , 27.186, 84.808,\n",
       "       36.524, 57.538, 29.064,  9.328, 34.54 , 77.03 , 78.744, 14.578,\n",
       "       81.22 , 64.182, 75.518, 25.752, 28.736, 42.536, 84.692, 42.626,\n",
       "       14.294, 12.974, 57.72 , 48.84 , 45.408, 12.992, 46.036, 78.942,\n",
       "       23.192, 15.082, 30.968,  6.138, 58.168, 55.486, 53.204, 76.668,\n",
       "       81.138, 81.104, 40.174, 43.126, 69.518, 25.37 , 42.318, 78.248,\n",
       "        9.37 ,  9.134, 13.542, 49.078, 41.908, 13.17 , 52.054, 19.412,\n",
       "       31.454, 84.338, 85.028, 70.47 , 13.326, 76.85 , 16.756, 82.034,\n",
       "       28.57 , 58.086,  6.992, 12.8  , 36.388, 73.98 , 58.884, 51.358,\n",
       "       27.526, 28.69 , 73.926, 80.918, 84.428, 55.752, 18.05 ,  7.73 ,\n",
       "       18.002, 75.81 , 16.282, 33.246, 86.034, 78.172, 79.298, 75.268,\n",
       "       18.866, 31.314, 65.07 , 18.468, 42.794,  6.728, 73.022,  7.656,\n",
       "       49.192, 24.638, 19.192, 64.826, 72.456])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 83,  55,  27,  93,  60,  84,  63,  32,  60,  20,  64,  60,  32,\n",
       "        85,  57,   6,  51,  60,  64,  98,  16,  13,  75,  63,  72,  64,\n",
       "        24,  49,  25,  96,  32,  96,  18,  12,  96,  48,  48,  55,  48,\n",
       "        95,  32,  72,   6,  36,  87,  40,  13,  42,  87,  48,  55,  25,\n",
       "        48,  32,  27,  18,  98,  23,  12,  33,  19,  63,  25,  98,  27,\n",
       "        71,  29,   8,  33,  75,  72,  14,  93,  54,  90,  19,  27,  42,\n",
       "        84,  39,  16,  13,  27,  48,  43,  13,  40,  90,  19,  16,  25,\n",
       "         6,  54,  44,  51,  80,  72, 100,  32,  40,  80,  25,  42,  90,\n",
       "         8,   8,  13,  48,  40,  13,  59,  20,  27,  96,  96,  70,  12,\n",
       "       100,  14,  96,  32,  55,   7,  12,  33,  72,  64,  48,  27,  32,\n",
       "        85,  84,  93,  56,  19,   7,  19,  75,  16,  30,  93,  93, 100,\n",
       "        93,  18,  30,  64,  20,  42,   7, 100,   6,  44,  19,  16,  60,\n",
       "        75])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9287845565882852, 5.275885350318471, 7.769458870073125)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2, mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_regression(\n",
    "    scattering_patterns, \n",
    "    num_atoms, \n",
    "    max_test_data=100, \n",
    "    THRESHOLD_num = 60, \n",
    "    train_size = 250, \n",
    "    random_state=42\n",
    "):\n",
    "        # Convert scattering_files to a NumPy array\n",
    "    scattering_patterns = np.array(scattering_patterns)\n",
    "    # Ensure num_atoms is also a NumPy array\n",
    "    num_atoms = np.array(num_atoms)\n",
    "    \n",
    "    # Create variable to stratify when creating train, validation and test sets\n",
    "    num_atoms_binned = np.array([1 if value > THRESHOLD_num else 0 for value in num_atoms])\n",
    "    \n",
    "    # Split the samples into train and test sets\n",
    "    indices = np.arange(len(num_atoms))\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        indices, \n",
    "        train_size=train_size, \n",
    "        test_size=min(len(indices)-train_size, max_test_data),\n",
    "        random_state=random_state,\n",
    "        stratify=num_atoms_binned\n",
    "    )\n",
    "    \n",
    "    print(f\"train: {len(train_indices)}\")\n",
    "    print(f\"test: {len(test_indices)}\")\n",
    "    \n",
    "    # Create the training and test sets\n",
    "    X_train, y_train = scattering_patterns[train_indices], num_atoms[train_indices]\n",
    "    X_test, y_test = scattering_patterns[test_indices], num_atoms[test_indices]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_regressor(X_train, y_train, X_test, y_test, random_state=42):\n",
    "    # Create a regressor\n",
    "    reg = RandomForestRegressor(\n",
    "        n_estimators=500, \n",
    "        random_state=42, \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Train the regressor with early stopping\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test set results\n",
    "    y_pred = reg.predict(X_test)\n",
    "    \n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Calculate regression metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return y_test, y_pred, r2, mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_dict():\n",
    "    metrics_dict = {\n",
    "        \"train_size\": train_size,\n",
    "        \"y_true\": y_test_all,\n",
    "        \"y_pred\": y_pred_all,\n",
    "        \"mae\": mae_scores,\n",
    "        \"rmse\": rmse_scores,\n",
    "        \"r2\": r2_scores\n",
    "    }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 600\n",
    "iterations = 10\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 600\n",
      "test: 100\n",
      "random_state = 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8526621404036545\n",
      "MAE for number of atoms regression: 7.4753\n",
      "RMSE for number of atoms regression: 10.445617230207125\n",
      "-------------Iteration 2/10\n",
      "train: 600\n",
      "test: 100\n",
      "random_state = 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8180873724668092\n",
      "MAE for number of atoms regression: 8.519820000000003\n",
      "RMSE for number of atoms regression: 11.728432364131193\n",
      "-------------Iteration 3/10\n",
      "train: 600\n",
      "test: 100\n",
      "random_state = 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8155158297752446\n",
      "MAE for number of atoms regression: 9.0831\n",
      "RMSE for number of atoms regression: 12.089073706450796\n",
      "-------------Iteration 4/10\n",
      "train: 600\n",
      "test: 100\n",
      "random_state = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.7807323870573721\n",
      "MAE for number of atoms regression: 8.41736\n",
      "RMSE for number of atoms regression: 11.631020598382586\n",
      "-------------Iteration 5/10\n",
      "train: 600\n",
      "test: 100\n",
      "random_state = 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.829696473362321\n",
      "MAE for number of atoms regression: 8.3544\n",
      "RMSE for number of atoms regression: 11.453131917514964\n",
      "-------------Iteration 6/10\n",
      "train: 600\n",
      "test: 100\n",
      "random_state = 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8654399022220534\n",
      "MAE for number of atoms regression: 6.92586\n",
      "RMSE for number of atoms regression: 10.34305384497248\n",
      "-------------Iteration 7/10\n",
      "train: 600\n",
      "test: 100\n",
      "random_state = 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8300416446361986\n",
      "MAE for number of atoms regression: 7.94456\n",
      "RMSE for number of atoms regression: 11.513652157330444\n",
      "-------------Iteration 8/10\n",
      "train: 600\n",
      "test: 100\n",
      "random_state = 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8627765989208567\n",
      "MAE for number of atoms regression: 7.878539999999998\n",
      "RMSE for number of atoms regression: 10.728336857127482\n",
      "-------------Iteration 9/10\n",
      "train: 600\n",
      "test: 100\n",
      "random_state = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8437033157453127\n",
      "MAE for number of atoms regression: 8.2968\n",
      "RMSE for number of atoms regression: 11.622705654020496\n",
      "-------------Iteration 10/10\n",
      "train: 600\n",
      "test: 100\n",
      "random_state = 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    9.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8799840914379174\n",
      "MAE for number of atoms regression: 6.935839999999998\n",
      "RMSE for number of atoms regression: 9.691509178657368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for regression\n",
    "    X_train, y_train, X_test, y_test = prepare_dataset_regression(\n",
    "        scattering_patterns, \n",
    "        num_atoms, \n",
    "        THRESHOLD_num = 60, \n",
    "        train_size = train_size,\n",
    "        random_state = random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Regression of number of atoms\n",
    "    y_test, y_pred, r2, mae, rmse = train_and_evaluate_regressor(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_test, \n",
    "        y_test,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    print(f\"R2 for number of atoms regression: {r2}\")\n",
    "    print(f\"MAE for number of atoms regression: {mae}\")\n",
    "    print(f\"RMSE for number of atoms regression: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 600\n",
      "mean R2 for number of atoms regression: 0.8378639756027739 +/- 0.027732160536255115\n",
      "mean MAE for number of atoms regression: 7.983158 +/- 0.663905892635395\n",
      "mean RMSE for number of atoms regression: 11.124653350879493 +/- 0.730841615376173\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean R2 for number of atoms regression: {np.mean(r2_scores)} +/- {np.std(r2_scores)}\")\n",
    "print(f\"mean MAE for number of atoms regression: {np.mean(mae_scores)} +/- {np.std(mae_scores)}\")\n",
    "print(f\"mean RMSE for number of atoms regression: {np.mean(rmse_scores)} +/- {np.std(rmse_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>[56, 44, 36, 8, 96, 20, 55, 36, 87, 75, 100, 7...</td>\n",
       "      <td>[51.782, 40.204, 52.284, 10.306, 79.314, 26.28...</td>\n",
       "      <td>7.47530</td>\n",
       "      <td>10.445617</td>\n",
       "      <td>0.852662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>[20, 57, 39, 64, 28, 95, 28, 7, 60, 23, 9, 63,...</td>\n",
       "      <td>[17.83, 70.072, 36.68, 57.28, 27.05, 65.076, 2...</td>\n",
       "      <td>8.51982</td>\n",
       "      <td>11.728432</td>\n",
       "      <td>0.818087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>[24, 57, 9, 85, 100, 29, 16, 40, 83, 27, 57, 5...</td>\n",
       "      <td>[39.158, 55.17, 11.276, 71.928, 84.498, 29.148...</td>\n",
       "      <td>9.08310</td>\n",
       "      <td>12.089074</td>\n",
       "      <td>0.815516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0         600  [56, 44, 36, 8, 96, 20, 55, 36, 87, 75, 100, 7...   \n",
       "1         600  [20, 57, 39, 64, 28, 95, 28, 7, 60, 23, 9, 63,...   \n",
       "2         600  [24, 57, 9, 85, 100, 29, 16, 40, 83, 27, 57, 5...   \n",
       "\n",
       "                                              y_pred      mae       rmse  \\\n",
       "0  [51.782, 40.204, 52.284, 10.306, 79.314, 26.28...  7.47530  10.445617   \n",
       "1  [17.83, 70.072, 36.68, 57.28, 27.05, 65.076, 2...  8.51982  11.728432   \n",
       "2  [39.158, 55.17, 11.276, 71.928, 84.498, 29.148...  9.08310  12.089074   \n",
       "\n",
       "         r2  \n",
       "0  0.852662  \n",
       "1  0.818087  \n",
       "2  0.815516  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_600 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_600.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "iterations = 10\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 1000\n",
      "test: 100\n",
      "random_state = 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.882804514181462\n",
      "MAE for number of atoms regression: 7.0637599999999985\n",
      "RMSE for number of atoms regression: 9.393417576154059\n",
      "-------------Iteration 2/10\n",
      "train: 1000\n",
      "test: 100\n",
      "random_state = 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9187706565618491\n",
      "MAE for number of atoms regression: 6.2046\n",
      "RMSE for number of atoms regression: 8.464714317683734\n",
      "-------------Iteration 3/10\n",
      "train: 1000\n",
      "test: 100\n",
      "random_state = 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8943103544677131\n",
      "MAE for number of atoms regression: 6.444020000000002\n",
      "RMSE for number of atoms regression: 9.425616743746797\n",
      "-------------Iteration 4/10\n",
      "train: 1000\n",
      "test: 100\n",
      "random_state = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8735998387479604\n",
      "MAE for number of atoms regression: 7.314220000000001\n",
      "RMSE for number of atoms regression: 10.572579721146585\n",
      "-------------Iteration 5/10\n",
      "train: 1000\n",
      "test: 100\n",
      "random_state = 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8721661243061629\n",
      "MAE for number of atoms regression: 7.157400000000001\n",
      "RMSE for number of atoms regression: 10.06917669722803\n",
      "-------------Iteration 6/10\n",
      "train: 1000\n",
      "test: 100\n",
      "random_state = 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8786916244154117\n",
      "MAE for number of atoms regression: 6.922860000000001\n",
      "RMSE for number of atoms regression: 10.229619021253919\n",
      "-------------Iteration 7/10\n",
      "train: 1000\n",
      "test: 100\n",
      "random_state = 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8640206966821727\n",
      "MAE for number of atoms regression: 7.13658\n",
      "RMSE for number of atoms regression: 10.167312346928268\n",
      "-------------Iteration 8/10\n",
      "train: 1000\n",
      "test: 100\n",
      "random_state = 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8932717903764729\n",
      "MAE for number of atoms regression: 6.564040000000001\n",
      "RMSE for number of atoms regression: 8.88238112219916\n",
      "-------------Iteration 9/10\n",
      "train: 1000\n",
      "test: 100\n",
      "random_state = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8910530773675245\n",
      "MAE for number of atoms regression: 6.619699999999999\n",
      "RMSE for number of atoms regression: 9.810267998378025\n",
      "-------------Iteration 10/10\n",
      "train: 1000\n",
      "test: 100\n",
      "random_state = 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   14.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8897534523798915\n",
      "MAE for number of atoms regression: 7.176580000000001\n",
      "RMSE for number of atoms regression: 9.69641711355282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for regression\n",
    "    X_train, y_train, X_test, y_test = prepare_dataset_regression(\n",
    "        scattering_patterns, \n",
    "        num_atoms, \n",
    "        THRESHOLD_num = 60, \n",
    "        train_size = train_size,\n",
    "        random_state = random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Regression of number of atoms\n",
    "    y_test, y_pred, r2, mae, rmse = train_and_evaluate_regressor(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_test, \n",
    "        y_test,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    print(f\"R2 for number of atoms regression: {r2}\")\n",
    "    print(f\"MAE for number of atoms regression: {mae}\")\n",
    "    print(f\"RMSE for number of atoms regression: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 1000\n",
      "mean R2 for number of atoms regression: 0.8858442129486621 +/- 0.014584545008939348\n",
      "mean MAE for number of atoms regression: 6.8603760000000005 +/- 0.35565081142041555\n",
      "mean RMSE for number of atoms regression: 9.67115026582714 +/- 0.6135244932287861\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean R2 for number of atoms regression: {np.mean(r2_scores)} +/- {np.std(r2_scores)}\")\n",
    "print(f\"mean MAE for number of atoms regression: {np.mean(mae_scores)} +/- {np.std(mae_scores)}\")\n",
    "print(f\"mean RMSE for number of atoms regression: {np.mean(rmse_scores)} +/- {np.std(rmse_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>[15, 12, 72, 44, 72, 33, 8, 7, 13, 60, 27, 60,...</td>\n",
       "      <td>[12.234, 16.536, 80.648, 51.364, 75.132, 35.80...</td>\n",
       "      <td>7.06376</td>\n",
       "      <td>9.393418</td>\n",
       "      <td>0.882805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>[24, 60, 96, 89, 40, 57, 63, 6, 12, 48, 9, 24,...</td>\n",
       "      <td>[19.448, 68.622, 72.006, 82.392, 41.586, 65.30...</td>\n",
       "      <td>6.20460</td>\n",
       "      <td>8.464714</td>\n",
       "      <td>0.918771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>[35, 32, 36, 57, 40, 9, 54, 95, 13, 80, 19, 95...</td>\n",
       "      <td>[40.53, 40.784, 47.632, 62.832, 44.702, 10.742...</td>\n",
       "      <td>6.44402</td>\n",
       "      <td>9.425617</td>\n",
       "      <td>0.894310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0        1000  [15, 12, 72, 44, 72, 33, 8, 7, 13, 60, 27, 60,...   \n",
       "1        1000  [24, 60, 96, 89, 40, 57, 63, 6, 12, 48, 9, 24,...   \n",
       "2        1000  [35, 32, 36, 57, 40, 9, 54, 95, 13, 80, 19, 95...   \n",
       "\n",
       "                                              y_pred      mae      rmse  \\\n",
       "0  [12.234, 16.536, 80.648, 51.364, 75.132, 35.80...  7.06376  9.393418   \n",
       "1  [19.448, 68.622, 72.006, 82.392, 41.586, 65.30...  6.20460  8.464714   \n",
       "2  [40.53, 40.784, 47.632, 62.832, 44.702, 10.742...  6.44402  9.425617   \n",
       "\n",
       "         r2  \n",
       "0  0.882805  \n",
       "1  0.918771  \n",
       "2  0.894310  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_1000 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_1000.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1400\n",
    "iterations = 10\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 1400\n",
      "test: 100\n",
      "random_state = 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9165645527171188\n",
      "MAE for number of atoms regression: 6.1765\n",
      "RMSE for number of atoms regression: 8.582573961230977\n",
      "-------------Iteration 2/10\n",
      "train: 1400\n",
      "test: 100\n",
      "random_state = 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.8966708459219894\n",
      "MAE for number of atoms regression: 7.2125\n",
      "RMSE for number of atoms regression: 9.623664206527573\n",
      "-------------Iteration 3/10\n",
      "train: 1400\n",
      "test: 100\n",
      "random_state = 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9315768976212258\n",
      "MAE for number of atoms regression: 5.61556\n",
      "RMSE for number of atoms regression: 7.890938144479399\n",
      "-------------Iteration 4/10\n",
      "train: 1400\n",
      "test: 100\n",
      "random_state = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9340956703023853\n",
      "MAE for number of atoms regression: 5.2176800000000005\n",
      "RMSE for number of atoms regression: 7.341151212173742\n",
      "-------------Iteration 5/10\n",
      "train: 1400\n",
      "test: 100\n",
      "random_state = 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9073961557584174\n",
      "MAE for number of atoms regression: 6.315659999999999\n",
      "RMSE for number of atoms regression: 9.019766145527278\n",
      "-------------Iteration 6/10\n",
      "train: 1400\n",
      "test: 100\n",
      "random_state = 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9249423195274938\n",
      "MAE for number of atoms regression: 5.7267399999999995\n",
      "RMSE for number of atoms regression: 8.16221539289426\n",
      "-------------Iteration 7/10\n",
      "train: 1400\n",
      "test: 100\n",
      "random_state = 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9208566153691831\n",
      "MAE for number of atoms regression: 5.876240000000001\n",
      "RMSE for number of atoms regression: 8.102091680547685\n",
      "-------------Iteration 8/10\n",
      "train: 1400\n",
      "test: 100\n",
      "random_state = 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9320650779729442\n",
      "MAE for number of atoms regression: 4.94386\n",
      "RMSE for number of atoms regression: 7.066663396540124\n",
      "-------------Iteration 9/10\n",
      "train: 1400\n",
      "test: 100\n",
      "random_state = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.928182059454092\n",
      "MAE for number of atoms regression: 5.85346\n",
      "RMSE for number of atoms regression: 7.535473747548988\n",
      "-------------Iteration 10/10\n",
      "train: 1400\n",
      "test: 100\n",
      "random_state = 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   21.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9138920024836943\n",
      "MAE for number of atoms regression: 5.82912\n",
      "RMSE for number of atoms regression: 8.165539795996343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for regression\n",
    "    X_train, y_train, X_test, y_test = prepare_dataset_regression(\n",
    "        scattering_patterns, \n",
    "        num_atoms, \n",
    "        THRESHOLD_num = 60, \n",
    "        train_size = train_size,\n",
    "        random_state = random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Regression of number of atoms\n",
    "    y_test, y_pred, r2, mae, rmse = train_and_evaluate_regressor(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_test, \n",
    "        y_test,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    print(f\"R2 for number of atoms regression: {r2}\")\n",
    "    print(f\"MAE for number of atoms regression: {mae}\")\n",
    "    print(f\"RMSE for number of atoms regression: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 1400\n",
      "mean R2 for number of atoms regression: 0.9206242197128545 +/- 0.011483487032548534\n",
      "mean MAE for number of atoms regression: 5.876732 +/- 0.5886350010116626\n",
      "mean RMSE for number of atoms regression: 8.149007768346637 +/- 0.7342060851192671\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean R2 for number of atoms regression: {np.mean(r2_scores)} +/- {np.std(r2_scores)}\")\n",
    "print(f\"mean MAE for number of atoms regression: {np.mean(mae_scores)} +/- {np.std(mae_scores)}\")\n",
    "print(f\"mean RMSE for number of atoms regression: {np.mean(rmse_scores)} +/- {np.std(rmse_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>[64, 49, 84, 18, 16, 10, 27, 55, 96, 84, 24, 8...</td>\n",
       "      <td>[57.374, 48.344, 79.764, 17.288, 16.964, 12.59...</td>\n",
       "      <td>6.17650</td>\n",
       "      <td>8.582574</td>\n",
       "      <td>0.916565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400</td>\n",
       "      <td>[100, 16, 32, 63, 87, 23, 14, 13, 89, 19, 100,...</td>\n",
       "      <td>[71.502, 16.956, 26.898, 77.206, 79.448, 22.43...</td>\n",
       "      <td>7.21250</td>\n",
       "      <td>9.623664</td>\n",
       "      <td>0.896671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1400</td>\n",
       "      <td>[43, 12, 16, 64, 18, 48, 72, 55, 12, 43, 90, 2...</td>\n",
       "      <td>[41.764, 10.942, 18.218, 55.558, 21.652, 42.27...</td>\n",
       "      <td>5.61556</td>\n",
       "      <td>7.890938</td>\n",
       "      <td>0.931577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0        1400  [64, 49, 84, 18, 16, 10, 27, 55, 96, 84, 24, 8...   \n",
       "1        1400  [100, 16, 32, 63, 87, 23, 14, 13, 89, 19, 100,...   \n",
       "2        1400  [43, 12, 16, 64, 18, 48, 72, 55, 12, 43, 90, 2...   \n",
       "\n",
       "                                              y_pred      mae      rmse  \\\n",
       "0  [57.374, 48.344, 79.764, 17.288, 16.964, 12.59...  6.17650  8.582574   \n",
       "1  [71.502, 16.956, 26.898, 77.206, 79.448, 22.43...  7.21250  9.623664   \n",
       "2  [41.764, 10.942, 18.218, 55.558, 21.652, 42.27...  5.61556  7.890938   \n",
       "\n",
       "         r2  \n",
       "0  0.916565  \n",
       "1  0.896671  \n",
       "2  0.931577  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_1400 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_1400.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1800\n",
    "iterations = 10\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 1800\n",
      "test: 100\n",
      "random_state = 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9341664925300217\n",
      "MAE for number of atoms regression: 5.0501\n",
      "RMSE for number of atoms regression: 7.414816974140359\n",
      "-------------Iteration 2/10\n",
      "train: 1800\n",
      "test: 100\n",
      "random_state = 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9250635873568395\n",
      "MAE for number of atoms regression: 5.51424\n",
      "RMSE for number of atoms regression: 7.846655639187945\n",
      "-------------Iteration 3/10\n",
      "train: 1800\n",
      "test: 100\n",
      "random_state = 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.933931220959546\n",
      "MAE for number of atoms regression: 4.7465\n",
      "RMSE for number of atoms regression: 7.075097910276578\n",
      "-------------Iteration 4/10\n",
      "train: 1800\n",
      "test: 100\n",
      "random_state = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9425492712065972\n",
      "MAE for number of atoms regression: 4.76332\n",
      "RMSE for number of atoms regression: 6.855307993080983\n",
      "-------------Iteration 5/10\n",
      "train: 1800\n",
      "test: 100\n",
      "random_state = 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.944275599763329\n",
      "MAE for number of atoms regression: 4.8191999999999995\n",
      "RMSE for number of atoms regression: 6.5669760651307385\n",
      "-------------Iteration 6/10\n",
      "train: 1800\n",
      "test: 100\n",
      "random_state = 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9237550815625948\n",
      "MAE for number of atoms regression: 5.61938\n",
      "RMSE for number of atoms regression: 7.78237671408934\n",
      "-------------Iteration 7/10\n",
      "train: 1800\n",
      "test: 100\n",
      "random_state = 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9224684949078731\n",
      "MAE for number of atoms regression: 5.043040000000001\n",
      "RMSE for number of atoms regression: 7.447238135040399\n",
      "-------------Iteration 8/10\n",
      "train: 1800\n",
      "test: 100\n",
      "random_state = 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9262580558798558\n",
      "MAE for number of atoms regression: 5.52972\n",
      "RMSE for number of atoms regression: 8.13797998522975\n",
      "-------------Iteration 9/10\n",
      "train: 1800\n",
      "test: 100\n",
      "random_state = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9495996021138057\n",
      "MAE for number of atoms regression: 4.146999999999999\n",
      "RMSE for number of atoms regression: 5.978404148265655\n",
      "-------------Iteration 10/10\n",
      "train: 1800\n",
      "test: 100\n",
      "random_state = 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:   28.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for number of atoms regression: 0.9186749870909365\n",
      "MAE for number of atoms regression: 5.54536\n",
      "RMSE for number of atoms regression: 7.930204057904185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for regression\n",
    "    X_train, y_train, X_test, y_test = prepare_dataset_regression(\n",
    "        scattering_patterns, \n",
    "        num_atoms, \n",
    "        THRESHOLD_num = 60, \n",
    "        train_size = train_size,\n",
    "        random_state = random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Regression of number of atoms\n",
    "    y_test, y_pred, r2, mae, rmse = train_and_evaluate_regressor(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_test, \n",
    "        y_test,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    print(f\"R2 for number of atoms regression: {r2}\")\n",
    "    print(f\"MAE for number of atoms regression: {mae}\")\n",
    "    print(f\"RMSE for number of atoms regression: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 1800\n",
      "mean R2 for number of atoms regression: 0.9320742393371398 +/- 0.009987790734751931\n",
      "mean MAE for number of atoms regression: 5.077786 +/- 0.45282759589494986\n",
      "mean RMSE for number of atoms regression: 7.303505762234593 +/- 0.6479118775003974\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean R2 for number of atoms regression: {np.mean(r2_scores)} +/- {np.std(r2_scores)}\")\n",
    "print(f\"mean MAE for number of atoms regression: {np.mean(mae_scores)} +/- {np.std(mae_scores)}\")\n",
    "print(f\"mean RMSE for number of atoms regression: {np.mean(rmse_scores)} +/- {np.std(rmse_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1800</td>\n",
       "      <td>[25, 8, 25, 55, 32, 27, 84, 93, 93, 48, 23, 32...</td>\n",
       "      <td>[25.37, 9.328, 23.606, 55.6, 31.318, 36.524, 8...</td>\n",
       "      <td>5.05010</td>\n",
       "      <td>7.414817</td>\n",
       "      <td>0.934166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>[75, 80, 13, 59, 42, 19, 90, 16, 85, 72, 6, 63...</td>\n",
       "      <td>[75.516, 75.936, 12.838, 54.176, 42.654, 23.80...</td>\n",
       "      <td>5.51424</td>\n",
       "      <td>7.846656</td>\n",
       "      <td>0.925064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1800</td>\n",
       "      <td>[32, 14, 39, 25, 24, 84, 59, 43, 19, 85, 54, 4...</td>\n",
       "      <td>[32.068, 17.13, 38.376, 39.006, 24.032, 82.464...</td>\n",
       "      <td>4.74650</td>\n",
       "      <td>7.075098</td>\n",
       "      <td>0.933931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0        1800  [25, 8, 25, 55, 32, 27, 84, 93, 93, 48, 23, 32...   \n",
       "1        1800  [75, 80, 13, 59, 42, 19, 90, 16, 85, 72, 6, 63...   \n",
       "2        1800  [32, 14, 39, 25, 24, 84, 59, 43, 19, 85, 54, 4...   \n",
       "\n",
       "                                              y_pred      mae      rmse  \\\n",
       "0  [25.37, 9.328, 23.606, 55.6, 31.318, 36.524, 8...  5.05010  7.414817   \n",
       "1  [75.516, 75.936, 12.838, 54.176, 42.654, 23.80...  5.51424  7.846656   \n",
       "2  [32.068, 17.13, 38.376, 39.006, 24.032, 82.464...  4.74650  7.075098   \n",
       "\n",
       "         r2  \n",
       "0  0.934166  \n",
       "1  0.925064  \n",
       "2  0.933931  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_1800 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_1800.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>[56, 44, 36, 8, 96, 20, 55, 36, 87, 75, 100, 7...</td>\n",
       "      <td>[51.782, 40.204, 52.284, 10.306, 79.314, 26.28...</td>\n",
       "      <td>7.47530</td>\n",
       "      <td>10.445617</td>\n",
       "      <td>0.852662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>[20, 57, 39, 64, 28, 95, 28, 7, 60, 23, 9, 63,...</td>\n",
       "      <td>[17.83, 70.072, 36.68, 57.28, 27.05, 65.076, 2...</td>\n",
       "      <td>8.51982</td>\n",
       "      <td>11.728432</td>\n",
       "      <td>0.818087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>[24, 57, 9, 85, 100, 29, 16, 40, 83, 27, 57, 5...</td>\n",
       "      <td>[39.158, 55.17, 11.276, 71.928, 84.498, 29.148...</td>\n",
       "      <td>9.08310</td>\n",
       "      <td>12.089074</td>\n",
       "      <td>0.815516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600</td>\n",
       "      <td>[7, 57, 80, 48, 48, 50, 48, 39, 42, 18, 72, 60...</td>\n",
       "      <td>[6.572, 43.166, 70.594, 45.56, 49.264, 57.988,...</td>\n",
       "      <td>8.41736</td>\n",
       "      <td>11.631021</td>\n",
       "      <td>0.780732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600</td>\n",
       "      <td>[16, 29, 15, 40, 43, 18, 33, 96, 64, 80, 87, 3...</td>\n",
       "      <td>[23.166, 35.414, 14.646, 59.83, 45.888, 21.642...</td>\n",
       "      <td>8.35440</td>\n",
       "      <td>11.453132</td>\n",
       "      <td>0.829696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0         600  [56, 44, 36, 8, 96, 20, 55, 36, 87, 75, 100, 7...   \n",
       "1         600  [20, 57, 39, 64, 28, 95, 28, 7, 60, 23, 9, 63,...   \n",
       "2         600  [24, 57, 9, 85, 100, 29, 16, 40, 83, 27, 57, 5...   \n",
       "3         600  [7, 57, 80, 48, 48, 50, 48, 39, 42, 18, 72, 60...   \n",
       "4         600  [16, 29, 15, 40, 43, 18, 33, 96, 64, 80, 87, 3...   \n",
       "\n",
       "                                              y_pred      mae       rmse  \\\n",
       "0  [51.782, 40.204, 52.284, 10.306, 79.314, 26.28...  7.47530  10.445617   \n",
       "1  [17.83, 70.072, 36.68, 57.28, 27.05, 65.076, 2...  8.51982  11.728432   \n",
       "2  [39.158, 55.17, 11.276, 71.928, 84.498, 29.148...  9.08310  12.089074   \n",
       "3  [6.572, 43.166, 70.594, 45.56, 49.264, 57.988,...  8.41736  11.631021   \n",
       "4  [23.166, 35.414, 14.646, 59.83, 45.888, 21.642...  8.35440  11.453132   \n",
       "\n",
       "         r2  \n",
       "0  0.852662  \n",
       "1  0.818087  \n",
       "2  0.815516  \n",
       "3  0.780732  \n",
       "4  0.829696  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res = pd.concat([\n",
    "    compiled_res_600,\n",
    "    compiled_res_1000,\n",
    "    compiled_res_1400,\n",
    "    compiled_res_1800\n",
    "], ignore_index=True)\n",
    "print(len(compiled_res))\n",
    "compiled_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 56,  44,  36,   8,  96,  20,  55,  36,  87,  75, 100,  72,  33,\n",
       "        43,  16,  29,  75,  13,  48,  87,   8,  39,  39,  33,  80,  15,\n",
       "        16,   8,  55,  40,  24,  29,  40,  87,  18,  96,  72,  51,  72,\n",
       "        13,  13,  10,  25,  93,  16,  24,  24,  55,  33,   6,   8,  84,\n",
       "        36,  55,  59,  35,  48,  32,  71,  64,  96,  35,  49,  80,   6,\n",
       "        48,  87,  70,  40,  56,  10,  29,  36,  14,  51,  98,  95,  16,\n",
       "        84,  72,  25,  33,  40,  96,  64,  85,  51,  63,  57,  43,  81,\n",
       "        98,  54,  64,  83,  85,  51,  48,  55,  50])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res[\"y_true\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_res[\"y_true\"] = compiled_res[\"y_true\"].apply(lambda arr: list(arr))\n",
    "compiled_res[\"y_pred\"] = compiled_res[\"y_pred\"].apply(lambda arr: list(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56,\n",
       " 44,\n",
       " 36,\n",
       " 8,\n",
       " 96,\n",
       " 20,\n",
       " 55,\n",
       " 36,\n",
       " 87,\n",
       " 75,\n",
       " 100,\n",
       " 72,\n",
       " 33,\n",
       " 43,\n",
       " 16,\n",
       " 29,\n",
       " 75,\n",
       " 13,\n",
       " 48,\n",
       " 87,\n",
       " 8,\n",
       " 39,\n",
       " 39,\n",
       " 33,\n",
       " 80,\n",
       " 15,\n",
       " 16,\n",
       " 8,\n",
       " 55,\n",
       " 40,\n",
       " 24,\n",
       " 29,\n",
       " 40,\n",
       " 87,\n",
       " 18,\n",
       " 96,\n",
       " 72,\n",
       " 51,\n",
       " 72,\n",
       " 13,\n",
       " 13,\n",
       " 10,\n",
       " 25,\n",
       " 93,\n",
       " 16,\n",
       " 24,\n",
       " 24,\n",
       " 55,\n",
       " 33,\n",
       " 6,\n",
       " 8,\n",
       " 84,\n",
       " 36,\n",
       " 55,\n",
       " 59,\n",
       " 35,\n",
       " 48,\n",
       " 32,\n",
       " 71,\n",
       " 64,\n",
       " 96,\n",
       " 35,\n",
       " 49,\n",
       " 80,\n",
       " 6,\n",
       " 48,\n",
       " 87,\n",
       " 70,\n",
       " 40,\n",
       " 56,\n",
       " 10,\n",
       " 29,\n",
       " 36,\n",
       " 14,\n",
       " 51,\n",
       " 98,\n",
       " 95,\n",
       " 16,\n",
       " 84,\n",
       " 72,\n",
       " 25,\n",
       " 33,\n",
       " 40,\n",
       " 96,\n",
       " 64,\n",
       " 85,\n",
       " 51,\n",
       " 63,\n",
       " 57,\n",
       " 43,\n",
       " 81,\n",
       " 98,\n",
       " 54,\n",
       " 64,\n",
       " 83,\n",
       " 85,\n",
       " 51,\n",
       " 48,\n",
       " 55,\n",
       " 50]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res[\"y_true\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_res.to_csv(\"RF_results_regres_num_atoms.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   train_size  40 non-null     int64  \n",
      " 1   y_true      40 non-null     object \n",
      " 2   y_pred      40 non-null     object \n",
      " 3   mae         40 non-null     float64\n",
      " 4   rmse        40 non-null     float64\n",
      " 5   r2          40 non-null     float64\n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"RF_results_regres_num_atoms.csv\", sep=',')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>[56, 44, 36, 8, 96, 20, 55, 36, 87, 75, 100, 7...</td>\n",
       "      <td>[51.782, 40.204, 52.284, 10.306, 79.314, 26.28...</td>\n",
       "      <td>7.47530</td>\n",
       "      <td>10.445617</td>\n",
       "      <td>0.852662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>[20, 57, 39, 64, 28, 95, 28, 7, 60, 23, 9, 63,...</td>\n",
       "      <td>[17.83, 70.072, 36.68, 57.28, 27.05, 65.076, 2...</td>\n",
       "      <td>8.51982</td>\n",
       "      <td>11.728432</td>\n",
       "      <td>0.818087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>[24, 57, 9, 85, 100, 29, 16, 40, 83, 27, 57, 5...</td>\n",
       "      <td>[39.158, 55.17, 11.276, 71.928, 84.498, 29.148...</td>\n",
       "      <td>9.08310</td>\n",
       "      <td>12.089074</td>\n",
       "      <td>0.815516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0         600  [56, 44, 36, 8, 96, 20, 55, 36, 87, 75, 100, 7...   \n",
       "1         600  [20, 57, 39, 64, 28, 95, 28, 7, 60, 23, 9, 63,...   \n",
       "2         600  [24, 57, 9, 85, 100, 29, 16, 40, 83, 27, 57, 5...   \n",
       "\n",
       "                                              y_pred      mae       rmse  \\\n",
       "0  [51.782, 40.204, 52.284, 10.306, 79.314, 26.28...  7.47530  10.445617   \n",
       "1  [17.83, 70.072, 36.68, 57.28, 27.05, 65.076, 2...  8.51982  11.728432   \n",
       "2  [39.158, 55.17, 11.276, 71.928, 84.498, 29.148...  9.08310  12.089074   \n",
       "\n",
       "         r2  \n",
       "0  0.852662  \n",
       "1  0.818087  \n",
       "2  0.815516  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rmse</th>\n",
       "      <th colspan=\"2\" halign=\"left\">r2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>7.983158</td>\n",
       "      <td>0.221302</td>\n",
       "      <td>11.124653</td>\n",
       "      <td>0.243614</td>\n",
       "      <td>0.837864</td>\n",
       "      <td>0.009244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>6.860376</td>\n",
       "      <td>0.118550</td>\n",
       "      <td>9.671150</td>\n",
       "      <td>0.204508</td>\n",
       "      <td>0.885844</td>\n",
       "      <td>0.004862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>5.876732</td>\n",
       "      <td>0.196212</td>\n",
       "      <td>8.149008</td>\n",
       "      <td>0.244735</td>\n",
       "      <td>0.920624</td>\n",
       "      <td>0.003828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>5.077786</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>7.303506</td>\n",
       "      <td>0.215971</td>\n",
       "      <td>0.932074</td>\n",
       "      <td>0.003329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mae                 rmse                  r2          \n",
       "                mean       sem       mean       sem      mean       sem\n",
       "train_size                                                             \n",
       "600         7.983158  0.221302  11.124653  0.243614  0.837864  0.009244\n",
       "1000        6.860376  0.118550   9.671150  0.204508  0.885844  0.004862\n",
       "1400        5.876732  0.196212   8.149008  0.244735  0.920624  0.003828\n",
       "1800        5.077786  0.150943   7.303506  0.215971  0.932074  0.003329"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_res = df.select_dtypes(include = [\"int\", \"float\"]).groupby(['train_size']).agg(['mean', 'sem'])\n",
    "grouped_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row=30\n",
    "max_true = max(literal_eval(df.sort_values(['train_size']).iloc[row,1]))\n",
    "max_pred = max(literal_eval(df.sort_values(['train_size']).iloc[row,2]))\n",
    "plt.figure(figsize=(3.5, 3.5))\n",
    "plt.scatter(literal_eval(df.sort_values(['train_size']).iloc[row,1]), \n",
    "            literal_eval(df.sort_values(['train_size']).iloc[row,2]),\n",
    "           color='#0C5DA5')\n",
    "plt.title(f\"training size = {df.sort_values(['train_size']).iloc[row,0]}\", fontsize=12)\n",
    "plt.xlabel('y true', fontsize=14)\n",
    "plt.ylabel('y pred', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.plot([0,max(max_true, max_pred)],[0,max(max_true, max_pred)], color='#00B945', linestyle='dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debyecalculator_env]",
   "language": "python",
   "name": "conda-env-debyecalculator_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
