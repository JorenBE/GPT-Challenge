{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - pair distribution function (PDF) - structure type 7cat unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicky/anaconda3/envs/debyecalculator_env/lib/python3.9/site-packages/numpy/core/getlimits.py:542: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from debyecalculator import DebyeCalculator\n",
    "from ase.io import read\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import tiktoken\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, r2_score, mean_absolute_error, root_mean_squared_error\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import pycm\n",
    "from ast import literal_eval\n",
    "import sys\n",
    "sys.path.append(\"/mnt/c/Users/44907688G/Documents/home_vicky/LLMs_models/gptchem-gptj/plotutils/\")\n",
    "from plotutils import *\n",
    "plt.style.use(\"/mnt/c/Users/44907688G/Documents/home_vicky/LLMs_models/gptchem-gptj/plotutils/kevin.mplstyle\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xyz_files():\n",
    "    # Initialise DebyeCalculator object\n",
    "    calc = DebyeCalculator()\n",
    "    print(calc)\n",
    "    \n",
    "    # Load XYZ files\n",
    "    XYZ_files = sorted(glob.glob(\"../xyz_files/*.xyz\"))\n",
    "    random.shuffle(XYZ_files)\n",
    "\n",
    "    # Calculate Pair Distribution Function for all XYZ files\n",
    "    scattering_files = []\n",
    "    structure_types = []\n",
    "    num_atoms = []\n",
    "\n",
    "    for iter, xyz_file in enumerate(XYZ_files):\n",
    "        # Extract structure type\n",
    "        structure_type = os.path.basename(xyz_file).split('_')[0]\n",
    "\n",
    "        # Calculate the scattering pattern\n",
    "        scatt_x, scatt_Int = calc.gr(structure_source=xyz_file)\n",
    "\n",
    "        # Normalise the scattering files\n",
    "        scatt_Int /= max(scatt_Int)\n",
    "        scattering_files.append(scatt_Int)\n",
    "\n",
    "        # Increment the count for this structure type\n",
    "        structure_types.append(structure_type)\n",
    "\n",
    "        atoms = read(xyz_file)\n",
    "        num_atoms.append(len(atoms))\n",
    "\n",
    "    return scattering_files, structure_types, num_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12127/1612413307.py:3: UserWarning: Warning: Your system might have a CUDA-enabled GPU, but CUDA is not available. Computations will run on the CPU instead. For optimal performance, please install Pytorch with CUDA support. If you do not have a CUDA-enabled CPU, you can surpress this warning by specifying the 'device' argument as 'cpu'\n",
      "  calc = DebyeCalculator()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebyeCalculator{'qmin': 1.0, 'qmax': 30.0, 'qdamp': 0.04, 'qstep': 0.05, 'rmin': 0.0, 'rmax': 20.0, 'rstep': 0.01, 'rthres': 0.0, 'biso': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# Simulate scattering data\n",
    "scattering_files, structure_types, num_atoms = process_xyz_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scattering_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.24081259e-03, -2.43981788e-03, -3.55886901e-03,\n",
       "       -4.56686504e-03, -5.44242794e-03, -6.17583841e-03, -6.76981779e-03,\n",
       "       -7.23938225e-03, -7.61045050e-03, -7.91762862e-03, -8.20107665e-03,\n",
       "       -8.50310456e-03, -8.86432454e-03, -9.32015758e-03, -9.89775546e-03,\n",
       "       -1.06134415e-02, -1.14714708e-02, -1.24634868e-02, -1.35693504e-02,\n",
       "       -1.47587219e-02, -1.59940217e-02, -1.72333848e-02, -1.84345916e-02,\n",
       "       -1.95586290e-02, -2.05732044e-02, -2.14555021e-02, -2.21943278e-02,\n",
       "       -2.27909349e-02, -2.32591350e-02, -2.36239322e-02, -2.39193980e-02,\n",
       "       -2.41856966e-02, -2.44655330e-02, -2.48004626e-02, -2.52271071e-02,\n",
       "       -2.57741194e-02, -2.64594071e-02, -2.72887163e-02, -2.82550789e-02,\n",
       "       -2.93392893e-02, -3.05116437e-02, -3.17345411e-02, -3.29658240e-02,\n",
       "       -3.41622792e-02, -3.52836587e-02, -3.62959877e-02, -3.71749178e-02,\n",
       "       -3.79074812e-02, -3.84935588e-02, -3.89457569e-02, -3.92884202e-02,\n",
       "       -3.95554863e-02, -3.97875607e-02, -4.00282070e-02, -4.03202996e-02,\n",
       "       -4.07022499e-02, -4.12044451e-02, -4.18465957e-02, -4.26361896e-02,\n",
       "       -4.35675271e-02, -4.46221568e-02, -4.57707383e-02, -4.69754003e-02,\n",
       "       -4.81928736e-02, -4.93786745e-02, -5.04906923e-02, -5.14931269e-02,\n",
       "       -5.23593836e-02, -5.30747734e-02, -5.36375418e-02, -5.40593043e-02,\n",
       "       -5.43640181e-02, -5.45857698e-02, -5.47659956e-02, -5.49499206e-02,\n",
       "       -5.51821254e-02, -5.55032901e-02, -5.59460223e-02, -5.65323383e-02,\n",
       "       -5.72714172e-02, -5.81588969e-02, -5.91770783e-02, -6.02965169e-02,\n",
       "       -6.14784360e-02, -6.26783147e-02, -6.38495684e-02, -6.49476647e-02,\n",
       "       -6.59342259e-02, -6.67802244e-02, -6.74687549e-02, -6.79964572e-02,\n",
       "       -6.83739781e-02, -6.86250180e-02, -6.87843561e-02, -6.88948333e-02,\n",
       "       -6.90037310e-02, -6.91583306e-02, -6.94020987e-02, -6.97705969e-02,\n",
       "       -7.02883825e-02, -7.09666684e-02, -7.18025640e-02, -7.27788582e-02,\n",
       "       -7.38656372e-02, -7.50229061e-02, -7.62039125e-02, -7.73592591e-02,\n",
       "       -7.84413517e-02, -7.94084743e-02, -8.02284926e-02, -8.08819532e-02,\n",
       "       -8.13635513e-02, -8.16830397e-02, -8.18642676e-02, -8.19430798e-02,\n",
       "       -8.19645822e-02, -8.19788352e-02, -8.20367336e-02, -8.21854770e-02,\n",
       "       -8.24643001e-02, -8.29008371e-02, -8.35089758e-02, -8.42872784e-02,\n",
       "       -8.52187723e-02, -8.62727687e-02, -8.74072090e-02, -8.85722116e-02,\n",
       "       -8.97147134e-02, -9.07827765e-02, -9.17304903e-02, -9.25217271e-02,\n",
       "       -9.31337327e-02, -9.35592130e-02, -9.38067660e-02, -9.39007327e-02,\n",
       "       -9.38789546e-02, -9.37894955e-02, -9.36865881e-02, -9.36258808e-02,\n",
       "       -9.36595351e-02, -9.38315764e-02, -9.41738486e-02, -9.47033018e-02,\n",
       "       -9.54200551e-02, -9.63075086e-02, -9.73333120e-02, -9.84524116e-02,\n",
       "       -9.96107683e-02, -1.00749806e-01, -1.01811975e-01, -1.02745444e-01,\n",
       "       -1.03508934e-01, -1.04075611e-01, -1.04435302e-01, -1.04595780e-01,\n",
       "       -1.04582347e-01, -1.04435667e-01, -1.04208253e-01, -1.03960104e-01,\n",
       "       -1.03753559e-01, -1.03647873e-01, -1.03693344e-01, -1.03927419e-01,\n",
       "       -1.04371153e-01, -1.05026655e-01, -1.05877213e-01, -1.06888101e-01,\n",
       "       -1.08009689e-01, -1.09181575e-01, -1.10337690e-01, -1.11412108e-01,\n",
       "       -1.12344913e-01, -1.13087811e-01, -1.13607973e-01, -1.13891743e-01,\n",
       "       -1.13945991e-01, -1.13797531e-01, -1.13491528e-01, -1.13087215e-01,\n",
       "       -1.12653494e-01, -1.12262264e-01, -1.11982822e-01, -1.11875102e-01,\n",
       "       -1.11984521e-01, -1.12337641e-01, -1.12939358e-01, -1.13772236e-01,\n",
       "       -1.14797801e-01, -1.15959197e-01, -1.17186159e-01, -1.18400991e-01,\n",
       "       -1.19525231e-01, -1.20486595e-01, -1.21225700e-01, -1.21701375e-01,\n",
       "       -1.21894747e-01, -1.21811479e-01, -1.21481538e-01, -1.20957285e-01,\n",
       "       -1.20309383e-01, -1.19620435e-01, -1.18978389e-01, -1.18468747e-01,\n",
       "       -1.18166678e-01, -1.18130304e-01, -1.18395038e-01, -1.18969910e-01,\n",
       "       -1.19835876e-01, -1.20947212e-01, -1.22234344e-01, -1.23609908e-01,\n",
       "       -1.24975652e-01, -1.26231149e-01, -1.27282426e-01, -1.28050968e-01,\n",
       "       -1.28480569e-01, -1.28543690e-01, -1.28244370e-01, -1.27619013e-01,\n",
       "       -1.26734108e-01, -1.25681296e-01, -1.24569185e-01, -1.23514459e-01,\n",
       "       -1.22630849e-01, -1.22017518e-01, -1.21748522e-01, -1.21863000e-01,\n",
       "       -1.22357711e-01, -1.23182356e-01, -1.24237746e-01, -1.25376970e-01,\n",
       "       -1.26410887e-01, -1.27115145e-01, -1.27239615e-01, -1.26520097e-01,\n",
       "       -1.24690384e-01, -1.21492140e-01, -1.16686612e-01, -1.10061593e-01,\n",
       "       -1.01437114e-01, -9.06679109e-02, -7.76424929e-02, -6.22795448e-02,\n",
       "       -4.45220284e-02, -2.43305378e-02, -1.67425314e-03,  2.34756581e-02,\n",
       "        5.11520430e-02,  8.13953653e-02,  1.14253238e-01,  1.49776816e-01,\n",
       "        1.88011691e-01,  2.28986531e-01,  2.72697270e-01,  3.19088519e-01,\n",
       "        3.68034363e-01,  4.19318944e-01,  4.72618908e-01,  5.27489901e-01,\n",
       "        5.83356798e-01,  6.39512658e-01,  6.95123255e-01,  7.49239743e-01,\n",
       "        8.00822437e-01,  8.48763645e-01,  8.91932547e-01,  9.29210246e-01,\n",
       "        9.59535837e-01,  9.81951296e-01,  9.95646894e-01,  1.00000000e+00,\n",
       "        9.94609892e-01,  9.79322970e-01,  9.54249382e-01,  9.19767141e-01,\n",
       "        8.76514137e-01,  8.25371504e-01,  7.67431796e-01,  7.03961909e-01,\n",
       "        6.36354804e-01,  5.66078603e-01,  4.94622082e-01,  4.23439175e-01,\n",
       "        3.53898585e-01,  2.87236571e-01,  2.24518389e-01,  1.66608498e-01,\n",
       "        1.14149898e-01,  6.75610453e-02,  2.70300973e-02, -7.46678282e-03,\n",
       "       -3.61461975e-02, -5.93875051e-02, -7.76997060e-02, -9.16840583e-02,\n",
       "       -1.01995468e-01, -1.09306335e-01, -1.14272207e-01, -1.17503487e-01,\n",
       "       -1.19541764e-01, -1.20843709e-01, -1.21772148e-01, -1.22592770e-01,\n",
       "       -1.23478658e-01, -1.24518499e-01, -1.25730276e-01, -1.27076641e-01,\n",
       "       -1.28482103e-01, -1.29850566e-01, -1.31080806e-01, -1.32080585e-01,\n",
       "       -1.32776886e-01, -1.33123830e-01, -1.33106038e-01, -1.32738978e-01,\n",
       "       -1.32066220e-01, -1.31154224e-01, -1.30085588e-01, -1.28950164e-01,\n",
       "       -1.27837986e-01, -1.26831248e-01, -1.25997290e-01, -1.25384986e-01,\n",
       "       -1.25020549e-01, -1.24907702e-01, -1.25028372e-01, -1.25345528e-01,\n",
       "       -1.25807524e-01, -1.26353353e-01, -1.26918361e-01, -1.27439275e-01,\n",
       "       -1.27860054e-01, -1.28135338e-01, -1.28234401e-01, -1.28141522e-01,\n",
       "       -1.27857804e-01, -1.27398938e-01, -1.26793966e-01, -1.26081303e-01,\n",
       "       -1.25306278e-01, -1.24516211e-01, -1.23757429e-01, -1.23070620e-01,\n",
       "       -1.22489311e-01, -1.22036628e-01, -1.21724583e-01, -1.21553741e-01,\n",
       "       -1.21513776e-01, -1.21584624e-01, -1.21738642e-01, -1.21942893e-01,\n",
       "       -1.22162163e-01, -1.22360930e-01, -1.22506566e-01, -1.22571252e-01,\n",
       "       -1.22533515e-01, -1.22380078e-01, -1.22105613e-01, -1.21713839e-01,\n",
       "       -1.21215858e-01, -1.20630048e-01, -1.19980387e-01, -1.19294465e-01,\n",
       "       -1.18602142e-01, -1.17932908e-01, -1.17314681e-01, -1.16771221e-01,\n",
       "       -1.16321281e-01, -1.15976952e-01, -1.15742862e-01, -1.15616113e-01,\n",
       "       -1.15585864e-01, -1.15634382e-01, -1.15737215e-01, -1.15866177e-01,\n",
       "       -1.15989409e-01, -1.16074659e-01, -1.16091043e-01, -1.16011508e-01,\n",
       "       -1.15814924e-01, -1.15487598e-01, -1.15025260e-01, -1.14433378e-01,\n",
       "       -1.13727689e-01, -1.12933300e-01, -1.12083822e-01, -1.11217991e-01,\n",
       "       -1.10378720e-01, -1.09608710e-01, -1.08947307e-01, -1.08427033e-01,\n",
       "       -1.08070537e-01, -1.07887894e-01, -1.07875057e-01, -1.08012997e-01,\n",
       "       -1.08268403e-01, -1.08595483e-01, -1.08938880e-01, -1.09237820e-01,\n",
       "       -1.09431289e-01, -1.09462872e-01, -1.09286346e-01, -1.08870216e-01,\n",
       "       -1.08201519e-01, -1.07287593e-01, -1.06156781e-01, -1.04855560e-01,\n",
       "       -1.03445224e-01, -1.01993084e-01, -1.00566044e-01, -9.92180184e-02,\n",
       "       -9.79797170e-02, -9.68466327e-02, -9.57681015e-02, -9.46386009e-02,\n",
       "       -9.32912976e-02, -9.14949402e-02, -8.89564157e-02, -8.53257924e-02,\n",
       "       -8.02092254e-02, -7.31834546e-02, -6.38184920e-02, -5.16988039e-02,\n",
       "       -3.64536718e-02, -1.77797098e-02,  4.52678697e-03,  3.05519477e-02,\n",
       "        6.02355562e-02,  9.33667645e-02,  1.29564539e-01,  1.68289974e-01,\n",
       "        2.08843112e-01,  2.50387728e-01,  2.91972041e-01,  3.32569569e-01,\n",
       "        3.71104032e-01,  4.06507283e-01,  4.37749565e-01,  4.63896632e-01,\n",
       "        4.84140664e-01,  4.97845978e-01,  5.04572511e-01,  5.04100621e-01,\n",
       "        4.96441334e-01,  4.81836140e-01,  4.60749477e-01,  4.33843672e-01,\n",
       "        4.01957005e-01,  3.66056621e-01,  3.27207208e-01,  2.86512375e-01,\n",
       "        2.45081887e-01,  2.03970701e-01,  1.64154649e-01,  1.26477972e-01,\n",
       "        9.16424543e-02,  6.01722486e-02,  3.24205756e-02,  8.55571125e-03,\n",
       "       -1.14177056e-02, -2.76513454e-02, -4.04214934e-02, -5.01064658e-02,\n",
       "       -5.71505576e-02, -6.20356165e-02, -6.52473792e-02, -6.72493353e-02,\n",
       "       -6.84580877e-02, -6.92265183e-02, -6.98308572e-02, -7.04668313e-02,\n",
       "       -7.12497830e-02, -7.22213611e-02, -7.33604878e-02, -7.45985135e-02,\n",
       "       -7.58347660e-02, -7.69542381e-02, -7.78433159e-02, -7.84041807e-02,\n",
       "       -7.85658360e-02, -7.82920122e-02, -7.75841177e-02, -7.64807686e-02,\n",
       "       -7.50548393e-02, -7.34038800e-02, -7.16432258e-02, -6.98918030e-02,\n",
       "       -6.82637319e-02, -6.68554455e-02, -6.57372475e-02, -6.49458095e-02,\n",
       "       -6.44798651e-02, -6.42996728e-02, -6.43276498e-02, -6.44542873e-02,\n",
       "       -6.45441860e-02, -6.44467697e-02, -6.40051514e-02, -6.30676523e-02,\n",
       "       -6.14986904e-02, -5.91868982e-02, -5.60545176e-02, -5.20613007e-02,\n",
       "       -4.72091883e-02, -4.15415391e-02, -3.51426676e-02, -2.81321779e-02,\n",
       "       -2.06609294e-02, -1.29015287e-02, -5.04245516e-03,  2.72299210e-03,\n",
       "        1.02023892e-02,  1.72145814e-02,  2.35933661e-02,  2.91958489e-02,\n",
       "        3.39039490e-02,  3.76287065e-02,  4.03098464e-02,  4.19167653e-02,\n",
       "        4.24467325e-02,  4.19229344e-02,  4.03920971e-02,  3.79212163e-02,\n",
       "        3.45948339e-02,  3.05116028e-02,  2.57819630e-02,  2.05239784e-02,\n",
       "        1.48626408e-02,  8.92553199e-03,  2.84140045e-03, -3.26386979e-03,\n",
       "       -9.26731247e-03, -1.50547829e-02, -2.05204431e-02, -2.55720820e-02,\n",
       "       -3.01313624e-02, -3.41380052e-02, -3.75507064e-02, -4.03482914e-02,\n",
       "       -4.25302163e-02, -4.41167057e-02, -4.51469570e-02, -4.56771702e-02,\n",
       "       -4.57779057e-02, -4.55295779e-02, -4.50184532e-02, -4.43322659e-02,\n",
       "       -4.35553417e-02, -4.27644812e-02, -4.20244969e-02, -4.13859896e-02,\n",
       "       -4.08833139e-02, -4.05326113e-02, -4.03335877e-02, -4.02703732e-02,\n",
       "       -4.03138511e-02, -4.04255651e-02, -4.05610092e-02, -4.06745151e-02,\n",
       "       -4.07227091e-02, -4.06686328e-02, -4.04852331e-02, -4.01566550e-02,\n",
       "       -3.96794416e-02, -3.90638597e-02, -3.83312069e-02, -3.75128314e-02,\n",
       "       -3.66468541e-02, -3.57748270e-02, -3.49381790e-02, -3.41745876e-02,\n",
       "       -3.35152596e-02, -3.29814926e-02, -3.25839333e-02, -3.23213562e-02,\n",
       "       -3.21806930e-02, -3.21392864e-02, -3.21655758e-02, -3.22233066e-02,\n",
       "       -3.22741941e-02, -3.22805494e-02, -3.22100446e-02, -3.20368856e-02,\n",
       "       -3.17450836e-02, -3.13293524e-02, -3.07948105e-02, -3.01576145e-02,\n",
       "       -2.94422321e-02, -2.86800675e-02, -2.79061645e-02, -2.71565951e-02,\n",
       "       -2.64639072e-02, -2.58572940e-02, -2.53566597e-02, -2.49730870e-02,\n",
       "       -2.47073676e-02, -2.45506130e-02, -2.44838502e-02, -2.44811252e-02,\n",
       "       -2.45113242e-02, -2.45409068e-02, -2.45365854e-02, -2.44690441e-02,\n",
       "       -2.43144967e-02, -2.40575150e-02, -2.36918107e-02, -2.32204255e-02,\n",
       "       -2.26567797e-02, -2.20210496e-02, -2.13409457e-02, -2.06468161e-02,\n",
       "       -1.99707914e-02, -1.93428081e-02, -1.87888909e-02, -1.83280129e-02,\n",
       "       -1.79710984e-02, -1.77200101e-02, -1.75679289e-02, -1.74980909e-02,\n",
       "       -1.74890347e-02, -1.75123457e-02, -1.75382309e-02, -1.75368004e-02,\n",
       "       -1.74812526e-02, -1.73495244e-02, -1.71269719e-02, -1.68070421e-02,\n",
       "       -1.63918640e-02, -1.58924349e-02, -1.53265363e-02, -1.47186145e-02,\n",
       "       -1.40964575e-02, -1.34881688e-02, -1.29219079e-02, -1.24216285e-02,\n",
       "       -1.20044462e-02, -1.16813192e-02, -1.14547322e-02, -1.13185225e-02,\n",
       "       -1.12588629e-02, -1.12558166e-02, -1.12844771e-02, -1.13175577e-02,\n",
       "       -1.13278115e-02, -1.12905828e-02, -1.11853415e-02, -1.09979911e-02,\n",
       "       -1.07226586e-02, -1.03602437e-02, -9.92019475e-03, -9.41909850e-03,\n",
       "       -8.87799729e-03, -8.32258165e-03, -7.77878752e-03, -7.27242464e-03,\n",
       "       -6.82504149e-03, -6.45357044e-03, -6.16819086e-03, -5.97117376e-03,\n",
       "       -5.85787604e-03, -5.81597537e-03, -5.82679734e-03, -5.86894620e-03,\n",
       "       -5.91615075e-03, -5.94383338e-03, -5.92909707e-03, -5.85269881e-03,\n",
       "       -5.70190558e-03, -5.46988286e-03, -5.15802857e-03, -4.77443123e-03,\n",
       "       -4.33377596e-03, -3.85568151e-03, -3.36320116e-03, -2.88091158e-03,\n",
       "       -2.43221410e-03, -2.03743530e-03, -1.71197311e-03, -1.46603107e-03,\n",
       "       -1.30220712e-03, -1.21600262e-03, -1.19656033e-03, -1.22706231e-03,\n",
       "       -1.28679897e-03, -1.35284069e-03, -1.40178541e-03, -1.41224544e-03,\n",
       "       -1.36624579e-03, -1.25218637e-03, -1.06281915e-03, -7.99366098e-04,\n",
       "       -4.69260267e-04, -8.57363266e-05,  3.33085394e-04,  7.65886973e-04,\n",
       "        1.18980824e-03,  1.58350193e-03,  1.92749756e-03,  2.20688642e-03,\n",
       "        2.41268799e-03,  2.54217372e-03,  2.59903981e-03,  2.59338575e-03,\n",
       "        2.54058745e-03,  2.45940429e-03,  2.37222132e-03,  2.29994440e-03,\n",
       "        2.26307474e-03,  2.27785902e-03,  2.35653319e-03,  2.50458950e-03,\n",
       "        2.72193924e-03,  3.00184079e-03,  3.33177624e-03,  3.69518227e-03,\n",
       "        4.07196581e-03,  4.44132043e-03,  4.78237402e-03,  5.07793529e-03,\n",
       "        5.31322462e-03,  5.47985686e-03,  5.57490811e-03,  5.60196768e-03,\n",
       "        5.57033345e-03,  5.49395522e-03,  5.39090112e-03,  5.28115034e-03,\n",
       "        5.18511701e-03,  5.12162177e-03,  5.10609895e-03,  5.15041267e-03,\n",
       "        5.25951153e-03,  5.43360040e-03,  5.66638447e-03,  5.94670558e-03,\n",
       "        6.25833729e-03,  6.58325898e-03,  6.90148631e-03,  7.19377026e-03,\n",
       "        7.44329672e-03,  7.63671333e-03,  7.76566984e-03,  7.82776438e-03,\n",
       "        7.82540254e-03,  7.76809454e-03,  7.66813522e-03,  7.54281925e-03,\n",
       "        7.41084199e-03,  7.29148090e-03,  7.20231887e-03,  7.15830829e-03,\n",
       "        7.17005646e-03,  7.24304235e-03,  7.37702753e-03,  7.56653165e-03,\n",
       "        7.80093716e-03,  8.06580111e-03,  8.34284257e-03,  8.61413963e-03,\n",
       "        8.86138808e-03,  9.06848349e-03,  9.22319945e-03,  9.31733008e-03,\n",
       "        9.34817083e-03,  9.31843370e-03,  9.23634693e-03,  9.11426917e-03,\n",
       "        8.96803476e-03,  8.81527085e-03,  8.67405254e-03,  8.56089219e-03,\n",
       "        8.49050935e-03,  8.47282261e-03,  8.51289928e-03,  8.61065648e-03,\n",
       "        8.76117684e-03,  8.95416550e-03,  9.17611644e-03,  9.41017736e-03,\n",
       "        9.63910110e-03,  9.84548032e-03,  1.00144884e-02,  1.01338150e-02,\n",
       "        1.01960488e-02,  1.01986034e-02,  1.01439152e-02,  1.00396303e-02,\n",
       "        9.89741646e-03,  9.73215420e-03,  9.56043601e-03,  9.39967949e-03,\n",
       "        9.26577300e-03,  9.17199999e-03,  9.12780967e-03,  9.13875271e-03,\n",
       "        9.20452178e-03,  9.32046585e-03,  9.47694946e-03,  9.66099370e-03,\n",
       "        9.85706970e-03,  1.00484081e-02,  1.02187432e-02,  1.03537161e-02,\n",
       "        1.04419570e-02,  1.04760174e-02,  1.04537485e-02,  1.03771370e-02,\n",
       "        1.02533894e-02,  1.00934021e-02,  9.91185941e-03,  9.72432736e-03,\n",
       "        9.54675674e-03,  9.39492043e-03,  9.28097405e-03,  9.21441335e-03,\n",
       "        9.20020882e-03,  9.23820212e-03,  9.32418834e-03,  9.44884401e-03,\n",
       "        9.60003864e-03,  9.76297446e-03,  9.92167275e-03,  1.00605320e-02,\n",
       "        1.01660602e-02,  1.02274176e-02,  1.02375327e-02,  1.01940297e-02,\n",
       "        1.00990701e-02,  9.95929819e-03,  9.78515483e-03,  9.59046092e-03,\n",
       "        9.38993506e-03,  9.19923652e-03,  9.03271511e-03,  8.90254974e-03,\n",
       "        8.81771930e-03,  8.78272671e-03,  8.79763626e-03,  8.85829981e-03,\n",
       "        8.95647984e-03,  9.08005796e-03,  9.21483338e-03,  9.34529770e-03,\n",
       "        9.45826061e-03,  9.53909010e-03,  9.57794860e-03,  9.56830103e-03,\n",
       "        9.50750802e-03,  9.39785969e-03,  9.24552791e-03,  9.06066690e-03,\n",
       "        8.85603577e-03,  8.64589028e-03,  8.44552461e-03,  8.26826971e-03,\n",
       "        8.12568236e-03,  8.02640896e-03,  7.97487982e-03,  7.97174219e-03,\n",
       "        8.01206473e-03,  8.08819663e-03,  8.18887632e-03,  8.30098521e-03,\n",
       "        8.40930082e-03,  8.50034505e-03,  8.56128242e-03,  8.58222693e-03,\n",
       "        8.55719205e-03,  8.48323386e-03,  8.36319569e-03,  8.20191484e-03,\n",
       "        8.01000651e-03,  7.79933436e-03,  7.58372666e-03,  7.37712905e-03,\n",
       "        7.19282776e-03,  7.04204803e-03,  6.93296408e-03,  6.86949072e-03,\n",
       "        6.85211644e-03,  6.87724259e-03,  6.93616876e-03,  7.01945787e-03,\n",
       "        7.11324438e-03,  7.20381550e-03,  7.27792131e-03,  7.32356589e-03,\n",
       "        7.33135222e-03,  7.29477825e-03,  7.21205398e-03,  7.08485162e-03,\n",
       "        6.91885129e-03,  6.72327634e-03,  6.50973478e-03,  6.29172195e-03,\n",
       "        6.08241465e-03,  5.89511823e-03,  5.73959807e-03,  5.62446332e-03,\n",
       "        5.55333402e-03,  5.52638248e-03,  5.54034021e-03,  5.58719272e-03,\n",
       "        5.65685844e-03,  5.73709141e-03,  5.81471762e-03,  5.87666966e-03,\n",
       "        5.91132697e-03,  5.90997888e-03,  5.86621929e-03,  5.77831361e-03,\n",
       "        5.64749213e-03,  5.48040541e-03,  5.28455013e-03,  5.07202046e-03,\n",
       "        4.85535245e-03,  4.64733643e-03,  4.45985049e-03,  4.30379109e-03,\n",
       "        4.18630708e-03,  4.11129836e-03,  4.07894468e-03,  4.08571819e-03,\n",
       "        4.12456412e-03,  4.18564025e-03,  4.25674208e-03,  4.32570232e-03,\n",
       "        4.37949225e-03,  4.40753950e-03,  4.40069474e-03,  4.35357867e-03,\n",
       "        4.26402083e-03,  4.13374696e-03,  3.96841252e-03,  3.77602200e-03,\n",
       "        3.56749864e-03,  3.35511612e-03,  3.15107522e-03,  2.96776043e-03,\n",
       "        2.81411153e-03,  2.69780355e-03,  2.62268679e-03,  2.58851261e-03,\n",
       "        2.59232102e-03,  2.62695760e-03,  2.68287561e-03,  2.74886144e-03,\n",
       "        2.81266822e-03,  2.86242878e-03,  2.88707623e-03,  2.87836371e-03,\n",
       "        2.83131236e-03,  2.74379295e-03,  2.61645112e-03,  2.45619775e-03,\n",
       "        2.26970389e-03,  2.06799246e-03,  1.86292327e-03,  1.66594982e-03,\n",
       "        1.48901273e-03,  1.34092756e-03,  1.22890773e-03,  1.15649181e-03,\n",
       "        1.12411962e-03,  1.12812046e-03,  1.16194750e-03,  1.21674570e-03,\n",
       "        1.28085143e-03,  1.34309521e-03,  1.39185728e-03,  1.41660566e-03,\n",
       "        1.40946242e-03,  1.36506162e-03,  1.28198799e-03,  1.16118055e-03,\n",
       "        1.00785645e-03,  8.30108824e-04,  6.37691061e-04,  4.41919256e-04,\n",
       "        2.54813378e-04,  8.65015245e-05, -5.33981947e-05, -1.58499606e-04,\n",
       "       -2.25362717e-04, -2.53517937e-04, -2.46402691e-04, -2.10591126e-04,\n",
       "       -1.54639565e-04, -8.92751486e-05, -2.55326140e-05,  2.47886437e-05,\n",
       "        5.21381407e-05,  4.88838268e-05,  1.00533462e-05, -6.65884218e-05,\n",
       "       -1.78993141e-04, -3.22582840e-04, -4.89651167e-04, -6.70906797e-04,\n",
       "       -8.54867627e-04, -1.03079178e-03, -1.18806097e-03, -1.31799118e-03,\n",
       "       -1.41398574e-03, -1.47296069e-03, -1.49459776e-03, -1.48241920e-03,\n",
       "       -1.44188164e-03, -1.38212938e-03, -1.31329359e-03, -1.24620122e-03,\n",
       "       -1.19194854e-03, -1.15930277e-03, -1.15648890e-03, -1.18831417e-03,\n",
       "       -1.25644077e-03, -1.35871419e-03, -1.49122439e-03, -1.64631463e-03,\n",
       "       -1.81455840e-03, -1.98579719e-03, -2.14898959e-03, -2.29372573e-03,\n",
       "       -2.41222582e-03, -2.49749352e-03, -2.54701613e-03, -2.56036548e-03,\n",
       "       -2.54103006e-03, -2.49431003e-03, -2.42907321e-03, -2.35488103e-03,\n",
       "       -2.28260830e-03, -2.22227536e-03, -2.18362547e-03, -2.17362843e-03,\n",
       "       -2.19650241e-03, -2.25437712e-03, -2.34599411e-03, -2.46609631e-03,\n",
       "       -2.60802079e-03, -2.76253070e-03, -2.91993003e-03, -3.06925760e-03,\n",
       "       -3.20037617e-03, -3.30605358e-03, -3.37984180e-03, -3.41892499e-03,\n",
       "       -3.42308148e-03, -3.39508196e-03, -3.34124430e-03, -3.26912059e-03,\n",
       "       -3.18860705e-03, -3.10973544e-03, -3.04275798e-03, -2.99651898e-03,\n",
       "       -2.97777308e-03, -2.99116550e-03, -3.03875771e-03, -3.11823003e-03,\n",
       "       -3.22563667e-03, -3.35385371e-03, -3.49450135e-03, -3.63722933e-03,\n",
       "       -3.77207412e-03, -3.88973602e-03, -3.98228830e-03, -4.04405640e-03,\n",
       "       -4.07192577e-03, -4.06616321e-03, -4.02909564e-03, -3.96703556e-03,\n",
       "       -3.88751831e-03, -3.79986363e-03, -3.71390698e-03, -3.63941281e-03,\n",
       "       -3.58506851e-03, -3.55767016e-03, -3.56133445e-03, -3.59769096e-03,\n",
       "       -3.66538297e-03, -3.75965168e-03, -3.87442368e-03, -4.00065491e-03,\n",
       "       -4.12915694e-03, -4.24977858e-03, -4.35397401e-03, -4.43315785e-03,\n",
       "       -4.48283553e-03, -4.49954765e-03, -4.48349956e-03, -4.43739071e-03,\n",
       "       -4.36721835e-03, -4.27971035e-03, -4.18499159e-03, -4.09175502e-03,\n",
       "       -4.00974182e-03, -3.94721841e-03, -3.91075201e-03, -3.90482950e-03,\n",
       "       -3.93058546e-03, -3.98640241e-03, -4.06793458e-03, -4.16922709e-03,\n",
       "       -4.28204425e-03, -4.39627934e-03, -4.50315885e-03, -4.59355861e-03,\n",
       "       -4.66049416e-03, -4.69812099e-03, -4.70364559e-03, -4.67826426e-03,\n",
       "       -4.62325290e-03, -4.54486348e-03, -4.45020339e-03, -4.34822636e-03,\n",
       "       -4.24786797e-03, -4.15872410e-03, -4.08869190e-03, -4.04420495e-03,\n",
       "       -4.02877200e-03, -4.04453510e-03, -4.08917246e-03, -4.15919721e-03,\n",
       "       -4.24803933e-03, -4.34756093e-03, -4.44919569e-03, -4.54315869e-03,\n",
       "       -4.62125428e-03, -4.67599183e-03, -4.70297458e-03, -4.69869608e-03,\n",
       "       -4.66363179e-03, -4.60061524e-03, -4.51518828e-03, -4.41371836e-03,\n",
       "       -4.30511963e-03, -4.19862848e-03, -4.10321122e-03, -4.02627699e-03,\n",
       "       -3.97393992e-03, -3.95040028e-03, -3.95684596e-03, -3.99170909e-03,\n",
       "       -4.05084249e-03, -4.12847148e-03, -4.21598181e-03, -4.30561602e-03,\n",
       "       -4.38805623e-03, -4.45465883e-03, -4.49852971e-03, -4.51552868e-03,\n",
       "       -4.50224336e-03, -4.45891777e-03, -4.38904017e-03, -4.29651514e-03,\n",
       "       -4.18951362e-03, -4.07545315e-03, -3.96352913e-03, -3.86244268e-03,\n",
       "       -3.77960992e-03, -3.72097199e-03, -3.69021227e-03, -3.68848233e-03,\n",
       "       -3.71447508e-03, -3.76426568e-03, -3.83163989e-03, -3.90916597e-03,\n",
       "       -3.98824085e-03, -4.06030426e-03, -4.11686068e-03, -4.15176619e-03,\n",
       "       -4.15992504e-03, -4.13920311e-03, -4.08938061e-03, -4.01315745e-03,\n",
       "       -3.91588220e-03, -3.80423455e-03, -3.68607510e-03, -3.57023557e-03,\n",
       "       -3.46496492e-03, -3.37766367e-03, -3.31392582e-03, -3.27747338e-03,\n",
       "       -3.26901465e-03, -3.28792608e-03, -3.32929054e-03, -3.38862790e-03,\n",
       "       -3.45736556e-03, -3.52727971e-03, -3.59053980e-03, -3.63867753e-03,\n",
       "       -3.66581883e-03, -3.66719300e-03, -3.63972900e-03, -3.58472834e-03,\n",
       "       -3.50417173e-03, -3.40300030e-03, -3.28795286e-03, -3.16736032e-03,\n",
       "       -3.04866815e-03, -2.94076372e-03, -2.85009760e-03, -2.78287404e-03,\n",
       "       -2.74206139e-03, -2.72907177e-03, -2.74216221e-03, -2.77759763e-03,\n",
       "       -2.82986392e-03, -2.89155263e-03, -2.95464485e-03, -3.01056379e-03,\n",
       "       -3.05206887e-03, -3.07328464e-03, -3.06904665e-03, -3.03777470e-03,\n",
       "       -2.97850347e-03, -2.89488933e-03, -2.79197446e-03, -2.67521827e-03,\n",
       "       -2.55276007e-03, -2.43331539e-03, -2.32387544e-03, -2.23189429e-03,\n",
       "       -2.16251542e-03, -2.11916491e-03, -2.10240879e-03, -2.11155554e-03,\n",
       "       -2.14268640e-03, -2.18957965e-03, -2.24600406e-03, -2.30358914e-03,\n",
       "       -2.35429569e-03, -2.39087711e-03, -2.40721530e-03, -2.39935727e-03,\n",
       "       -2.36453116e-03, -2.30362546e-03, -2.21884460e-03, -2.11471645e-03,\n",
       "       -1.99780869e-03, -1.87584327e-03, -1.75637007e-03, -1.64723850e-03,\n",
       "       -1.55497272e-03, -1.48529105e-03, -1.44059490e-03, -1.42257370e-03,\n",
       "       -1.42937619e-03, -1.45770202e-03, -1.50156126e-03, -1.55390496e-03,\n",
       "       -1.60796172e-03, -1.65532285e-03, -1.68841542e-03, -1.70281564e-03,\n",
       "       -1.69231836e-03, -1.65632414e-03, -1.59469491e-03, -1.50999345e-03,\n",
       "       -1.40686170e-03, -1.29141274e-03, -1.17116142e-03, -1.05341210e-03,\n",
       "       -9.45973152e-04, -8.55266815e-04, -7.86556455e-04, -7.42648903e-04,\n",
       "       -7.24460580e-04, -7.30509637e-04, -7.56951398e-04, -7.98965048e-04,\n",
       "       -8.49718868e-04, -9.01517749e-04, -9.46427870e-04, -9.78306867e-04,\n",
       "       -9.90657136e-04, -9.79901291e-04, -9.43933788e-04, -8.82854278e-04,\n",
       "       -7.99861562e-04, -6.98797288e-04, -5.86160750e-04, -4.68533020e-04,\n",
       "       -3.54399905e-04, -2.49682955e-04, -1.62276017e-04, -9.61047190e-05,\n",
       "       -5.38434033e-05, -3.71347051e-05, -4.38953539e-05, -7.10718377e-05,\n",
       "       -1.12668007e-04, -1.62949116e-04, -2.14163854e-04, -2.58773856e-04,\n",
       "       -2.90252035e-04, -3.03299923e-04, -2.93638499e-04, -2.58784246e-04,\n",
       "       -2.00414506e-04, -1.20524317e-04, -2.26554748e-05,  8.57558334e-05,\n",
       "        1.98909300e-04,  3.09110677e-04,  4.08846681e-04,  4.92630003e-04,\n",
       "        5.55209932e-04,  5.93963428e-04,  6.08146656e-04,  5.99179417e-04,\n",
       "        5.70943928e-04,  5.27704484e-04,  4.76721616e-04,  4.25036298e-04,\n",
       "        3.79367557e-04,  3.46730463e-04,  3.32338706e-04,  3.40459344e-04,\n",
       "        3.72164155e-04,  4.27543360e-04,  5.03651041e-04,  5.96824626e-04,\n",
       "        7.00602017e-04,  8.08254350e-04,  9.13365162e-04,  1.00776285e-03,\n",
       "        1.08658965e-03,  1.14435959e-03,  1.17912062e-03,  1.18982128e-03,\n",
       "        1.17783085e-03,  1.14682072e-03,  1.10169279e-03,  1.04878657e-03,\n",
       "        9.95161245e-04,  9.47823573e-04,  9.13351658e-04,  8.96420039e-04,\n",
       "        9.01324849e-04,  9.29070229e-04,  9.79993842e-04,  1.05158449e-03,\n",
       "        1.13907235e-03,  1.23703433e-03,  1.33842381e-03,  1.43723062e-03,\n",
       "        1.52578647e-03,  1.59820146e-03,  1.65076554e-03,  1.68024295e-03,\n",
       "        1.68663159e-03,  1.67066976e-03,  1.63565867e-03,  1.58777216e-03,\n",
       "        1.53228187e-03,  1.47589704e-03,  1.42557442e-03,  1.38784479e-03,\n",
       "        1.36808888e-03,  1.36924104e-03,  1.39271747e-03,  1.43888302e-03,\n",
       "        1.50451635e-03,  1.58592290e-03,  1.67759974e-03,  1.77236367e-03,\n",
       "        1.86396122e-03,  1.94592623e-03,  2.01221695e-03,  2.05895794e-03,\n",
       "        2.08259467e-03,  2.08346220e-03,  2.06305785e-03,  2.02446338e-03,\n",
       "        1.97237334e-03,  1.91370677e-03,  1.85387291e-03,  1.80058694e-03,\n",
       "        1.75951701e-03,  1.73559599e-03,  1.73234195e-03,  1.75122090e-03,\n",
       "        1.79187616e-03,  1.85156683e-03,  1.92667579e-03,  2.01126025e-03,\n",
       "        2.09911377e-03,  2.18402292e-03,  2.25855014e-03,  2.31794477e-03,\n",
       "        2.35780491e-03,  2.37604859e-03,  2.37179617e-03,  2.34651193e-03,\n",
       "        2.30320147e-03,  2.24718498e-03,  2.18412955e-03,  2.12153839e-03,\n",
       "        2.06451770e-03,  2.01971387e-03,  1.99185242e-03,  1.98384328e-03,\n",
       "        1.99748785e-03,  2.03261292e-03,  2.08641449e-03,  2.15489091e-03,\n",
       "        2.23247055e-03,  2.31362786e-03,  2.39109341e-03,  2.45860568e-03,\n",
       "        2.51126569e-03,  2.54480680e-03,  2.55694380e-03,  2.54657865e-03,\n",
       "        2.51654186e-03,  2.46967911e-03,  2.40935083e-03,  2.34275474e-03,\n",
       "        2.27585481e-03,  2.21515656e-03,  2.16651079e-03,  2.13443767e-03,\n",
       "        2.12202454e-03,  2.13067210e-03,  2.16016034e-03,  2.20763660e-03,\n",
       "        2.26974930e-03,  2.34084716e-03,  2.41463259e-03,  2.48490227e-03,\n",
       "        2.54557352e-03,  2.59131915e-03,  2.61838944e-03,  2.62454082e-03,\n",
       "        2.60951929e-03,  2.57400027e-03,  2.52199289e-03,  2.45820126e-03,\n",
       "        2.38800747e-03,  2.31756107e-03,  2.25321669e-03,  2.20082072e-03,\n",
       "        2.16487562e-03,  2.14781146e-03,  2.15204363e-03,  2.17622123e-03,\n",
       "        2.21824367e-03,  2.27435399e-03,  2.33870652e-03,  2.40578828e-03,\n",
       "        2.46941531e-03,  2.52378546e-03,  2.56333081e-03,  2.58446345e-03,\n",
       "        2.58508348e-03,  2.56490079e-03,  2.52492749e-03,  2.46911193e-03,\n",
       "        2.40149582e-03,  2.32776930e-03,  2.25405116e-03,  2.18684948e-03,\n",
       "        2.13082344e-03,  2.09128740e-03,  2.07092613e-03,  2.07018014e-03,\n",
       "        2.08960706e-03,  2.12631910e-03,  2.17661844e-03,  2.23494857e-03,\n",
       "        2.29600538e-03,  2.35356879e-03,  2.40157242e-03,  2.43544276e-03,\n",
       "        2.45100050e-03,  2.44674226e-03,  2.42180168e-03,  2.37867981e-03,\n",
       "        2.31892755e-03,  2.24825321e-03,  2.17164401e-03,  2.09502969e-03,\n",
       "        2.02519703e-03,  1.96678308e-03,  1.92432769e-03,  1.90022669e-03,\n",
       "        1.89600361e-03,  1.91106112e-03,  1.94319920e-03,  1.98848592e-03,\n",
       "        2.04169215e-03,  2.09737592e-03,  2.14922545e-03,  2.19206698e-03,\n",
       "        2.22079433e-03,  2.23181630e-03,  2.22299853e-03,  2.19425326e-03,\n",
       "        2.14739027e-03,  2.08497536e-03,  2.01175618e-03,  1.93309493e-03,\n",
       "        1.85466302e-03,  1.78248214e-03,  1.72167784e-03,  1.67656504e-03,\n",
       "        1.64994074e-03,  1.64269016e-03,  1.65444368e-03,  1.68267742e-03,\n",
       "        1.72360858e-03,  1.77258346e-03,  1.82345940e-03,  1.87067944e-03,\n",
       "        1.90902082e-03,  1.93330029e-03,  1.94017251e-03,  1.92825869e-03,\n",
       "        1.89660804e-03,  1.84680789e-03,  1.78196444e-03,  1.70758599e-03,\n",
       "        1.62728271e-03,  1.54773390e-03,  1.47443532e-03,  1.41236442e-03,\n",
       "        1.36567105e-03,  1.33704324e-03,  1.32775214e-03,  1.33675954e-03,\n",
       "        1.36175100e-03,  1.39967469e-03,  1.44474627e-03,  1.49179180e-03,\n",
       "        1.53583463e-03,  1.57016120e-03,  1.59099663e-03,  1.59502053e-03,\n",
       "        1.58003869e-03,  1.54606323e-03,  1.49493397e-03,  1.42884860e-03,\n",
       "        1.35298993e-03,  1.27228443e-03,  1.19225134e-03,  1.11834286e-03,\n",
       "        1.05561165e-03,  1.00841175e-03,  9.78658907e-04,  9.67818778e-04,\n",
       "        9.75284260e-04,  9.98350792e-04,  1.03349041e-03,  1.07598992e-03,\n",
       "        1.12055033e-03,  1.16096414e-03,  1.19291176e-03,  1.21148839e-03,\n",
       "        1.21322344e-03,  1.19630352e-03,  1.16147811e-03,  1.10923487e-03,\n",
       "        1.04299199e-03,  9.66976164e-04,  8.86477355e-04,  8.06699623e-04,\n",
       "        7.33015535e-04,  6.70878566e-04,  6.23811735e-04,  5.93707839e-04,\n",
       "        5.82493609e-04,  5.88950119e-04,  6.10971299e-04,  6.44352112e-04,\n",
       "        6.85107778e-04,  7.27559847e-04,  7.65906589e-04,  7.96330860e-04,\n",
       "        8.13171908e-04,  8.13667430e-04,  7.96011300e-04,  7.60293624e-04,\n",
       "        7.08407839e-04,  6.42477185e-04,  5.67109440e-04,  4.87775251e-04,\n",
       "        4.09276981e-04,  3.37291625e-04,  2.76025996e-04,  2.29545985e-04,\n",
       "        2.00727329e-04,  1.89357932e-04,  1.95578716e-04,  2.17333727e-04,\n",
       "        2.49705539e-04,  2.90034252e-04,  3.31277522e-04,  3.68917041e-04,\n",
       "        3.98005504e-04,  4.14185459e-04,  4.13999805e-04,  3.96612624e-04,\n",
       "        3.61094979e-04,  3.10009142e-04,  2.45002651e-04,  1.71405933e-04,\n",
       "        9.37843797e-05,  1.69555587e-05, -5.34566971e-05, -1.12605725e-04,\n",
       "       -1.57066184e-04, -1.85095385e-04, -1.95041212e-04, -1.87616562e-04,\n",
       "       -1.65538033e-04, -1.33048336e-04, -9.30505921e-05, -5.18157540e-05,\n",
       "       -1.43522848e-05,  1.45530494e-05,  3.07103219e-05,  3.09146963e-05,\n",
       "        1.43791140e-05, -1.99043388e-05, -6.99414595e-05, -1.32402900e-04,\n",
       "       -2.03808013e-04, -2.79112806e-04, -3.52934730e-04, -4.20878670e-04,\n",
       "       -4.77802852e-04, -5.19708265e-04, -5.44994953e-04, -5.53468359e-04,\n",
       "       -5.44814218e-04, -5.21840993e-04, -4.87843587e-04, -4.47827886e-04,\n",
       "       -4.06071456e-04, -3.67906818e-04, -3.38542130e-04, -3.21741536e-04,\n",
       "       -3.20225576e-04, -3.35824589e-04, -3.68061126e-04, -4.16283234e-04,\n",
       "       -4.76070505e-04, -5.44639246e-04, -6.16699923e-04, -6.87173218e-04,\n",
       "       -7.51742919e-04, -8.05387390e-04, -8.44745431e-04, -8.67538911e-04,\n",
       "       -8.73297220e-04, -8.62787827e-04, -8.37925647e-04, -8.02498485e-04,\n",
       "       -7.61246250e-04, -7.18985451e-04, -6.79555931e-04, -6.48815650e-04,\n",
       "       -6.30899798e-04, -6.27553207e-04, -6.41302380e-04, -6.71075657e-04,\n",
       "       -7.16427283e-04, -7.73311069e-04, -8.38420237e-04, -9.07012320e-04,\n",
       "       -9.74401017e-04, -1.03497470e-03, -1.08472444e-03, -1.12074416e-03,\n",
       "       -1.14037981e-03, -1.14357763e-03, -1.13008602e-03, -1.10341050e-03,\n",
       "       -1.06600509e-03, -1.02288451e-03, -9.78909200e-04, -9.37977107e-04,\n",
       "       -9.06132860e-04, -8.86146561e-04, -8.81172018e-04, -8.92151147e-04,\n",
       "       -9.19404498e-04, -9.61348298e-04, -1.01525604e-03, -1.07673695e-03,\n",
       "       -1.14126375e-03, -1.20422314e-03, -1.26076839e-03, -1.30674907e-03,\n",
       "       -1.33881392e-03, -1.35515269e-03, -1.35464908e-03, -1.33900926e-03,\n",
       "       -1.30933174e-03, -1.26992690e-03, -1.22480455e-03, -1.17830141e-03,\n",
       "       -1.13620039e-03, -1.10190629e-03, -1.08022161e-03, -1.07271189e-03,\n",
       "       -1.08103163e-03, -1.10564171e-03, -1.14424212e-03, -1.19418697e-03,\n",
       "       -1.25181209e-03, -1.31245260e-03, -1.37110834e-03, -1.42366881e-03,\n",
       "       -1.46531791e-03, -1.49358623e-03, -1.50631845e-03, -1.50252692e-03,\n",
       "       -1.48378476e-03, -1.45148765e-03, -1.40944775e-03, -1.36185542e-03,\n",
       "       -1.31386181e-03, -1.26959872e-03, -1.23352301e-03, -1.20913517e-03,\n",
       "       -1.19947549e-03, -1.20502186e-03, -1.22674508e-03, -1.26147678e-03,\n",
       "       -1.30769110e-03, -1.36143330e-03, -1.41737028e-03, -1.47186464e-03,\n",
       "       -1.52048864e-03, -1.55794306e-03, -1.58201111e-03, -1.59103400e-03,\n",
       "       -1.58372649e-03, -1.56199711e-03, -1.52749266e-03, -1.48243667e-03,\n",
       "       -1.43299310e-03, -1.38286932e-03, -1.33643602e-03, -1.29848288e-03,\n",
       "       -1.27160084e-03, -1.25928130e-03, -1.26234151e-03, -1.28067832e-03,\n",
       "       -1.31219660e-03, -1.35508180e-03, -1.40469882e-03, -1.45684986e-03,\n",
       "       -1.50749949e-03, -1.55109598e-03, -1.58457283e-03, -1.60531129e-03,\n",
       "       -1.61081506e-03, -1.59980392e-03, -1.57486834e-03, -1.53750647e-03,\n",
       "       -1.49097003e-03, -1.43877720e-03, -1.38669461e-03, -1.33823906e-03,\n",
       "       -1.29790127e-03, -1.26960315e-03, -1.25520758e-03, -1.25512516e-03,\n",
       "       -1.27078767e-03, -1.29920465e-03, -1.33819703e-03, -1.38414826e-03,\n",
       "       -1.43263058e-03, -1.47892768e-03, -1.51913252e-03, -1.54885068e-03,\n",
       "       -1.56548340e-03, -1.56748050e-03, -1.55387970e-03, -1.52598729e-03,\n",
       "       -1.48603937e-03, -1.43732154e-03, -1.38378236e-03, -1.32941315e-03,\n",
       "       -1.27940427e-03, -1.23708544e-03, -1.20628008e-03, -1.18999381e-03,\n",
       "       -1.18790637e-03, -1.20041089e-03, -1.22602284e-03, -1.26225338e-03,\n",
       "       -1.30431820e-03, -1.34899700e-03, -1.39193179e-03, -1.42794161e-03,\n",
       "       -1.45437790e-03, -1.46767276e-03, -1.46647729e-03, -1.45029626e-03,\n",
       "       -1.42001570e-03, -1.37801503e-03, -1.32757192e-03, -1.27220212e-03,\n",
       "       -1.21635862e-03, -1.16518827e-03, -1.12138456e-03, -1.08979177e-03,\n",
       "       -1.07108359e-03, -1.06728077e-03, -1.07771042e-03, -1.10080268e-03,\n",
       "       -1.13367673e-03, -1.17368402e-03, -1.21505128e-03, -1.25482748e-03,\n",
       "       -1.28778722e-03, -1.31101022e-03, -1.32140412e-03, -1.31762656e-03,\n",
       "       -1.29913841e-03, -1.26695493e-03, -1.22350955e-03, -1.17086899e-03,\n",
       "       -1.11453119e-03, -1.05755718e-03, -1.00539310e-03, -9.60804755e-04,\n",
       "       -9.27402172e-04, -9.07602429e-04, -9.01833759e-04, -9.10615316e-04,\n",
       "       -9.31341259e-04, -9.61868907e-04, -9.98849981e-04, -1.03805738e-03,\n",
       "       -1.07457826e-03, -1.10486848e-03, -1.12541264e-03, -1.13346777e-03,\n",
       "       -1.12733117e-03, -1.10668561e-03, -1.07278826e-03, -1.02785171e-03,\n",
       "       -9.74678260e-04, -9.17620782e-04, -8.60057131e-04, -8.07069940e-04,\n",
       "       -7.61924079e-04, -7.28100771e-04, -7.07302126e-04, -7.01102952e-04,\n",
       "       -7.07591709e-04, -7.27072242e-04, -7.55798654e-04, -7.90447521e-04,\n",
       "       -8.27396521e-04, -8.61710694e-04, -8.89685354e-04, -9.08269372e-04,\n",
       "       -9.14460630e-04, -9.06823028e-04, -8.85162852e-04, -8.50305718e-04,\n",
       "       -8.04464449e-04, -7.51188491e-04, -6.93689741e-04, -6.36545999e-04,\n",
       "       -5.83215035e-04, -5.37951943e-04, -5.04134921e-04, -4.82994830e-04,\n",
       "       -4.75931127e-04, -4.82315314e-04, -5.00586524e-04, -5.28134988e-04,\n",
       "       -5.61385008e-04, -5.96419268e-04, -6.29089132e-04, -6.55930606e-04,\n",
       "       -6.72783703e-04, -6.77355507e-04, -6.68685418e-04, -6.46230124e-04,\n",
       "       -6.10807969e-04, -5.64474612e-04, -5.11273334e-04, -4.53873101e-04,\n",
       "       -3.97125958e-04, -3.44277243e-04, -2.99542211e-04, -2.65677663e-04,\n",
       "       -2.44873198e-04, -2.37604138e-04, -2.43245668e-04, -2.61204696e-04,\n",
       "       -2.87731586e-04, -3.19851591e-04, -3.53765528e-04, -3.85235122e-04,\n",
       "       -4.10869281e-04, -4.26479441e-04, -4.30394197e-04, -4.21115634e-04,\n",
       "       -3.97947588e-04, -3.62935185e-04, -3.17133177e-04, -2.64234695e-04,\n",
       "       -2.07750636e-04, -1.51861313e-04, -9.99414260e-05, -5.59956607e-05,\n",
       "       -2.29368034e-05, -2.90138928e-06,  3.78335812e-06, -2.37465429e-06,\n",
       "       -1.96592937e-05, -4.65019584e-05, -7.82900825e-05, -1.11856687e-04,\n",
       "       -1.42303281e-04, -1.67249091e-04, -1.82593270e-04, -1.86331294e-04,\n",
       "       -1.77109439e-04, -1.54539171e-04, -1.18926589e-04, -7.45900470e-05,\n",
       "       -2.29309862e-05,  3.29803479e-05,  8.73907848e-05,  1.37621086e-04,\n",
       "        1.80465970e-04,  2.12037892e-04,  2.31149592e-04,  2.36539694e-04,\n",
       "        2.29974175e-04,  2.12053783e-04,  1.85158977e-04,  1.53381741e-04,\n",
       "        1.20050034e-04,  8.89618459e-05,  6.46605695e-05,  4.88660480e-05,\n",
       "        4.51789201e-05,  5.40818619e-05,  7.60244511e-05,  1.09753200e-04,\n",
       "        1.53121291e-04,  2.03783216e-04,  2.57154024e-04,  3.10520001e-04,\n",
       "        3.59309866e-04,  3.99688754e-04,  4.29724751e-04,  4.47331986e-04,\n",
       "        4.51984029e-04,  4.44084581e-04,  4.25137056e-04,  3.98200849e-04,\n",
       "        3.65901971e-04,  3.32228810e-04,  3.00856133e-04,  2.76355946e-04,\n",
       "        2.60084315e-04,  2.55934981e-04,  2.64420902e-04,  2.84966663e-04,\n",
       "        3.17556580e-04,  3.59911646e-04,  4.08428226e-04,  4.59834730e-04,\n",
       "        5.10722806e-04,  5.57282532e-04,  5.95298188e-04,  6.23396889e-04,\n",
       "        6.39230886e-04,  6.42127707e-04,  6.32803189e-04,  6.12256583e-04,\n",
       "        5.83929592e-04,  5.51466539e-04,  5.16770291e-04,  4.85219003e-04,\n",
       "        4.59245231e-04,  4.42831777e-04,  4.37378767e-04,  4.44146746e-04,\n",
       "        4.63563163e-04,  4.95101616e-04,  5.34859020e-04,  5.81204251e-04,\n",
       "        6.30294904e-04,  6.78847544e-04,  7.22408935e-04,  7.58833950e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scattering_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19524"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "num_tokens = len(encoding.encode(str(scattering_files[0])))\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scattering_files[0].round(3)[::15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "num_tokens = len(encoding.encode(str(scattering_files[0].round(3)[::15])))\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering_patterns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(scattering_files)):\n",
    "    pattern = scattering_files[i].round(3)[::15]\n",
    "    scattering_patterns.append(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scattering_patterns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare clasification dataset for structure type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering_patterns = np.array(scattering_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "encoded_structure_types = le.fit_transform(structure_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = {i: np.where(encoded_structure_types == i)[0] for i in np.unique(encoded_structure_types)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([   5,   41,   50,   57,   68,   69,   77,   83,   86,   92,  104,\n",
       "         105,  115,  118,  120,  124,  128,  137,  141,  146,  155,  168,\n",
       "         179,  188,  193,  203,  222,  235,  253,  265,  268,  270,  275,\n",
       "         292,  317,  366,  378,  382,  390,  394,  395,  403,  413,  417,\n",
       "         463,  488,  502,  516,  526,  540,  548,  552,  581,  582,  601,\n",
       "         611,  612,  619,  635,  639,  643,  653,  656,  667,  677,  682,\n",
       "         697,  700,  711,  713,  717,  722,  724,  730,  732,  753,  755,\n",
       "         764,  776,  811,  816,  831,  837,  843,  849,  855,  868,  885,\n",
       "         898,  911,  917,  926,  934,  964,  971,  977,  989,  997, 1004,\n",
       "        1006, 1010, 1011, 1019, 1023, 1034, 1038, 1039, 1042, 1046, 1058,\n",
       "        1062, 1069, 1097, 1098, 1109, 1120, 1127, 1146, 1154, 1157, 1159,\n",
       "        1164, 1180, 1183, 1184, 1188, 1209, 1213, 1221, 1234, 1238, 1243,\n",
       "        1257, 1264, 1299, 1310, 1314, 1327, 1342, 1367, 1373, 1389, 1395,\n",
       "        1410, 1419, 1429, 1448, 1455, 1472, 1473, 1478, 1503, 1522, 1523,\n",
       "        1527, 1528, 1549, 1551, 1560, 1562, 1564, 1566, 1572, 1573, 1580,\n",
       "        1596, 1609, 1612, 1613, 1616, 1632, 1633, 1637, 1646, 1666, 1667,\n",
       "        1669, 1672, 1673, 1679, 1681, 1713, 1717, 1721, 1728, 1732, 1755,\n",
       "        1771, 1780, 1790, 1792, 1823, 1831, 1851, 1867, 1871, 1876, 1877,\n",
       "        1889, 1896, 1903, 1905, 1918, 1932, 1937, 1938, 1939, 1942, 1954]),\n",
       " 1: array([   4,    9,   25,   26,   27,   38,   39,   43,   45,   52,   56,\n",
       "          58,   59,   78,   80,   87,   91,   96,   99,  103,  121,  132,\n",
       "         163,  164,  165,  172,  174,  177,  178,  180,  184,  190,  191,\n",
       "         194,  197,  211,  213,  223,  225,  226,  236,  257,  258,  261,\n",
       "         274,  282,  287,  294,  295,  299,  304,  311,  326,  328,  337,\n",
       "         338,  344,  353,  354,  367,  373,  396,  398,  401,  402,  408,\n",
       "         415,  416,  434,  436,  439,  445,  452,  455,  465,  466,  468,\n",
       "         478,  480,  481,  483,  489,  493,  496,  497,  518,  521,  522,\n",
       "         535,  554,  556,  557,  563,  575,  587,  589,  593,  605,  610,\n",
       "         618,  621,  623,  633,  647,  648,  654,  655,  668,  685,  693,\n",
       "         705,  707,  708,  710,  715,  718,  723,  725,  729,  736,  740,\n",
       "         746,  752,  759,  761,  771,  777,  784,  786,  791,  792,  805,\n",
       "         806,  807,  810,  814,  820,  821,  822,  824,  825,  838,  851,\n",
       "         854,  866,  876,  877,  880,  889,  894,  900,  901,  906,  912,\n",
       "         913,  915,  935,  939,  947,  948,  949,  951,  953,  962,  969,\n",
       "         973,  987,  990,  993,  995,  996,  998, 1002, 1030, 1032, 1037,\n",
       "        1043, 1045, 1047, 1061, 1066, 1068, 1073, 1075, 1076, 1078, 1080,\n",
       "        1093, 1095, 1102, 1105, 1107, 1113, 1115, 1128, 1130, 1143, 1160,\n",
       "        1167, 1169, 1171, 1173, 1177, 1186, 1193, 1203, 1205, 1207, 1242,\n",
       "        1252, 1254, 1255, 1262, 1267, 1271, 1272, 1275, 1287, 1289, 1290,\n",
       "        1295, 1296, 1298, 1300, 1301, 1305, 1316, 1328, 1348, 1352, 1370,\n",
       "        1376, 1388, 1408, 1411, 1416, 1417, 1421, 1424, 1428, 1431, 1432,\n",
       "        1434, 1439, 1443, 1449, 1451, 1457, 1468, 1470, 1482, 1485, 1488,\n",
       "        1494, 1495, 1497, 1498, 1514, 1517, 1520, 1534, 1537, 1541, 1542,\n",
       "        1554, 1556, 1558, 1563, 1567, 1581, 1583, 1584, 1594, 1598, 1601,\n",
       "        1605, 1606, 1617, 1620, 1622, 1626, 1627, 1628, 1647, 1651, 1656,\n",
       "        1658, 1662, 1668, 1676, 1682, 1683, 1684, 1694, 1699, 1704, 1708,\n",
       "        1709, 1720, 1722, 1727, 1736, 1747, 1749, 1752, 1757, 1768, 1774,\n",
       "        1785, 1787, 1788, 1795, 1803, 1807, 1809, 1810, 1817, 1822, 1824,\n",
       "        1830, 1837, 1844, 1848, 1855, 1857, 1860, 1874, 1879, 1892, 1898,\n",
       "        1909, 1910, 1915, 1924, 1930, 1935, 1936, 1947, 1949, 1950, 1951,\n",
       "        1955]),\n",
       " 2: array([   6,   14,   63,   73,   89,   93,  123,  219,  361,  381,  443,\n",
       "         446,  456,  473,  485,  504,  577,  591,  616,  646,  650,  659,\n",
       "         679,  691,  694,  731,  735,  762,  793,  798,  841,  847,  848,\n",
       "         872,  910,  921,  928,  936,  942,  961,  981, 1015, 1022, 1026,\n",
       "        1052, 1057, 1060, 1067, 1070, 1083, 1092, 1096, 1110, 1111, 1135,\n",
       "        1156, 1166, 1224, 1261, 1263, 1266, 1270, 1319, 1326, 1340, 1341,\n",
       "        1345, 1354, 1358, 1360, 1403, 1413, 1447, 1474, 1490, 1491, 1500,\n",
       "        1507, 1512, 1531, 1538, 1574, 1582, 1592, 1661, 1692, 1723, 1745,\n",
       "        1759, 1818, 1841, 1872, 1887, 1921, 1952]),\n",
       " 3: array([   1,    7,    8,   10,   11,   12,   15,   19,   20,   22,   23,\n",
       "          28,   30,   31,   32,   33,   34,   35,   36,   37,   40,   44,\n",
       "          46,   47,   48,   49,   53,   54,   60,   61,   62,   64,   65,\n",
       "          67,   71,   72,   75,   79,   82,   85,   88,   90,   94,   95,\n",
       "          97,   98,  100,  101,  108,  109,  110,  111,  112,  113,  119,\n",
       "         122,  125,  126,  129,  131,  133,  134,  135,  136,  138,  139,\n",
       "         140,  142,  143,  144,  145,  147,  148,  149,  150,  151,  152,\n",
       "         153,  154,  156,  157,  158,  159,  160,  161,  162,  166,  167,\n",
       "         169,  173,  175,  181,  183,  186,  187,  189,  192,  195,  196,\n",
       "         198,  199,  201,  202,  204,  205,  206,  207,  208,  209,  210,\n",
       "         212,  214,  215,  216,  218,  220,  221,  224,  227,  228,  229,\n",
       "         230,  231,  232,  233,  237,  238,  241,  243,  245,  246,  247,\n",
       "         248,  249,  250,  251,  252,  254,  255,  259,  260,  262,  264,\n",
       "         266,  267,  269,  271,  272,  273,  278,  280,  281,  283,  284,\n",
       "         286,  288,  290,  291,  293,  296,  297,  298,  300,  305,  306,\n",
       "         307,  308,  310,  314,  315,  318,  319,  320,  321,  322,  324,\n",
       "         325,  329,  333,  336,  339,  340,  341,  342,  343,  345,  346,\n",
       "         347,  348,  349,  350,  351,  352,  355,  356,  357,  358,  359,\n",
       "         360,  362,  364,  365,  369,  374,  375,  376,  379,  380,  383,\n",
       "         384,  385,  387,  389,  391,  392,  393,  397,  399,  400,  407,\n",
       "         410,  411,  412,  414,  418,  419,  422,  423,  424,  425,  426,\n",
       "         428,  429,  430,  431,  432,  433,  435,  437,  440,  441,  442,\n",
       "         444,  447,  449,  450,  451,  453,  454,  457,  458,  459,  460,\n",
       "         461,  462,  464,  467,  469,  470,  471,  472,  474,  475,  476,\n",
       "         479,  484,  486,  487,  490,  492,  494,  495,  498,  499,  500,\n",
       "         501,  505,  506,  508,  509,  513,  514,  515,  519,  520,  523,\n",
       "         524,  525,  529,  530,  531,  532,  537,  538,  539,  541,  542,\n",
       "         544,  546,  549,  550,  551,  553,  555,  558,  559,  560,  561,\n",
       "         562,  564,  566,  567,  568,  570,  571,  572,  573,  576,  578,\n",
       "         580,  583,  584,  585,  586,  590,  592,  594,  595,  597,  598,\n",
       "         599,  600,  603,  604,  606,  607,  608,  609,  613,  614,  615,\n",
       "         620,  622,  624,  626,  627,  628,  630,  631,  632,  634,  636,\n",
       "         637,  640,  641,  642,  645,  649,  651,  652,  657,  660,  661,\n",
       "         662,  663,  664,  665,  669,  670,  671,  672,  673,  674,  675,\n",
       "         676,  680,  683,  684,  686,  687,  688,  689,  692,  695,  701,\n",
       "         702,  703,  704,  712,  714,  716,  719,  720,  721,  726,  727,\n",
       "         728,  733,  734,  737,  738,  739,  741,  742,  743,  744,  745,\n",
       "         747,  748,  749,  750,  751,  754,  756,  758,  763,  765,  766,\n",
       "         767,  768,  769,  770,  773,  774,  775,  778,  780,  781,  783,\n",
       "         787,  789,  790,  795,  796,  797,  799,  800,  802,  803,  804,\n",
       "         808,  809,  815,  817,  818,  823,  826,  827,  829,  830,  832,\n",
       "         833,  835,  839,  842,  844,  845,  846,  850,  852,  853,  858,\n",
       "         859,  860,  861,  862,  863,  864,  865,  869,  870,  873,  875,\n",
       "         878,  881,  882,  883,  884,  888,  891,  893,  895,  896,  899,\n",
       "         902,  903,  904,  905,  908,  909,  914,  918,  919,  920,  922,\n",
       "         923,  924,  925,  929,  930,  931,  932,  937,  938,  940,  941,\n",
       "         943,  944,  950,  952,  954,  955,  957,  959,  960,  963,  966,\n",
       "         968,  970,  974,  978,  979,  982,  983,  984,  985,  988,  991,\n",
       "         994,  999, 1000, 1001, 1003, 1007, 1008, 1009, 1014, 1018, 1020,\n",
       "        1021, 1024, 1025, 1027, 1028, 1031, 1033, 1035, 1036, 1040, 1041,\n",
       "        1044, 1048, 1049, 1050, 1051, 1054, 1055, 1056, 1063, 1064, 1065,\n",
       "        1071, 1072, 1079, 1081, 1082, 1085, 1087, 1090, 1091, 1099, 1100,\n",
       "        1101, 1103, 1108, 1112, 1114, 1116, 1118, 1119, 1121, 1122, 1123,\n",
       "        1125, 1126, 1129, 1131, 1132, 1133, 1134, 1136, 1137, 1138, 1140,\n",
       "        1142, 1144, 1145, 1147, 1148, 1151, 1152, 1153, 1158, 1161, 1162,\n",
       "        1165, 1168, 1170, 1172, 1174, 1176, 1179, 1181, 1182, 1185, 1187,\n",
       "        1191, 1192, 1194, 1196, 1197, 1198, 1199, 1201, 1202, 1206, 1210,\n",
       "        1211, 1212, 1216, 1218, 1219, 1220, 1222, 1223, 1226, 1228, 1229,\n",
       "        1230, 1231, 1233, 1235, 1236, 1237, 1239, 1240, 1241, 1244, 1245,\n",
       "        1246, 1247, 1248, 1249, 1253, 1258, 1259, 1260, 1265, 1268, 1269,\n",
       "        1273, 1274, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284,\n",
       "        1286, 1288, 1291, 1292, 1293, 1294, 1297, 1303, 1304, 1306, 1307,\n",
       "        1308, 1309, 1311, 1320, 1321, 1322, 1323, 1324, 1325, 1329, 1330,\n",
       "        1331, 1332, 1333, 1334, 1335, 1337, 1338, 1339, 1343, 1344, 1346,\n",
       "        1347, 1349, 1350, 1351, 1353, 1355, 1356, 1357, 1359, 1362, 1363,\n",
       "        1364, 1366, 1368, 1369, 1371, 1372, 1374, 1377, 1380, 1381, 1382,\n",
       "        1383, 1385, 1386, 1391, 1393, 1394, 1396, 1397, 1398, 1399, 1401,\n",
       "        1402, 1405, 1406, 1407, 1414, 1415, 1418, 1420, 1425, 1426, 1427,\n",
       "        1430, 1435, 1436, 1437, 1438, 1440, 1441, 1444, 1445, 1446, 1450,\n",
       "        1452, 1453, 1454, 1456, 1458, 1459, 1461, 1462, 1463, 1464, 1465,\n",
       "        1466, 1469, 1471, 1475, 1476, 1481, 1483, 1484, 1486, 1487, 1489,\n",
       "        1499, 1501, 1502, 1505, 1506, 1508, 1509, 1513, 1515, 1516, 1518,\n",
       "        1519, 1521, 1524, 1525, 1526, 1529, 1530, 1532, 1540, 1543, 1544,\n",
       "        1545, 1547, 1548, 1550, 1552, 1553, 1555, 1557, 1559, 1561, 1565,\n",
       "        1568, 1569, 1570, 1571, 1575, 1576, 1577, 1578, 1579, 1585, 1586,\n",
       "        1587, 1588, 1589, 1590, 1593, 1595, 1597, 1602, 1604, 1607, 1610,\n",
       "        1611, 1614, 1615, 1618, 1623, 1625, 1629, 1630, 1631, 1634, 1635,\n",
       "        1636, 1639, 1640, 1641, 1642, 1643, 1644, 1648, 1650, 1652, 1653,\n",
       "        1654, 1655, 1659, 1660, 1663, 1665, 1670, 1671, 1675, 1677, 1678,\n",
       "        1680, 1685, 1686, 1687, 1688, 1690, 1693, 1695, 1697, 1700, 1701,\n",
       "        1702, 1705, 1706, 1707, 1710, 1711, 1712, 1715, 1716, 1726, 1729,\n",
       "        1730, 1731, 1733, 1734, 1735, 1737, 1738, 1743, 1746, 1748, 1750,\n",
       "        1751, 1753, 1754, 1756, 1758, 1762, 1763, 1765, 1766, 1767, 1769,\n",
       "        1773, 1775, 1776, 1777, 1778, 1779, 1781, 1783, 1784, 1786, 1791,\n",
       "        1793, 1794, 1797, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1811,\n",
       "        1812, 1814, 1815, 1816, 1819, 1821, 1825, 1826, 1827, 1832, 1833,\n",
       "        1835, 1836, 1838, 1839, 1840, 1842, 1843, 1846, 1847, 1849, 1850,\n",
       "        1852, 1853, 1854, 1856, 1858, 1859, 1861, 1863, 1864, 1873, 1875,\n",
       "        1878, 1880, 1881, 1884, 1885, 1888, 1890, 1893, 1894, 1895, 1897,\n",
       "        1899, 1900, 1902, 1904, 1907, 1908, 1912, 1913, 1914, 1916, 1917,\n",
       "        1922, 1923, 1925, 1927, 1928, 1929, 1931, 1933, 1934, 1940, 1941,\n",
       "        1943, 1945, 1946, 1948, 1953, 1956]),\n",
       " 4: array([   0,    2,   51,   81,  130,  285,  302,  334,  406,  420,  511,\n",
       "         574,  588,  760,  813,  840,  933,  958,  967, 1013, 1117, 1155,\n",
       "        1204, 1227, 1250, 1251, 1318, 1365, 1378, 1510, 1533, 1599, 1603,\n",
       "        1619, 1664, 1714, 1829, 1920]),\n",
       " 5: array([  42,   74,  106,  200,  234,  256,  277,  289,  303,  332,  363,\n",
       "         372,  377,  404,  405,  477,  503,  510,  533,  545,  617,  678,\n",
       "         698,  772,  779,  785,  812,  819,  834,  871,  874,  879,  916,\n",
       "         927,  956,  972,  980, 1016, 1084, 1086, 1094, 1106, 1139, 1149,\n",
       "        1163, 1178, 1190, 1200, 1215, 1217, 1232, 1285, 1312, 1317, 1336,\n",
       "        1375, 1392, 1409, 1460, 1467, 1480, 1511, 1536, 1591, 1649, 1725,\n",
       "        1742, 1744, 1772, 1789, 1834, 1862, 1870, 1882, 1886, 1901]),\n",
       " 6: array([   3,   13,   16,   17,   18,   21,   24,   29,   55,   66,   70,\n",
       "          76,   84,  102,  107,  114,  116,  117,  127,  170,  171,  176,\n",
       "         182,  185,  217,  239,  240,  242,  244,  263,  276,  279,  301,\n",
       "         309,  312,  313,  316,  323,  327,  330,  331,  335,  368,  370,\n",
       "         371,  386,  388,  409,  421,  427,  438,  448,  482,  491,  507,\n",
       "         512,  517,  527,  528,  534,  536,  543,  547,  565,  569,  579,\n",
       "         596,  602,  625,  629,  638,  644,  658,  666,  681,  690,  696,\n",
       "         699,  706,  709,  757,  782,  788,  794,  801,  828,  836,  856,\n",
       "         857,  867,  886,  887,  890,  892,  897,  907,  945,  946,  965,\n",
       "         975,  976,  986,  992, 1005, 1012, 1017, 1029, 1053, 1059, 1074,\n",
       "        1077, 1088, 1089, 1104, 1124, 1141, 1150, 1175, 1189, 1195, 1208,\n",
       "        1214, 1225, 1256, 1302, 1313, 1315, 1361, 1379, 1384, 1387, 1390,\n",
       "        1400, 1404, 1412, 1422, 1423, 1433, 1442, 1477, 1479, 1492, 1493,\n",
       "        1496, 1504, 1535, 1539, 1546, 1600, 1608, 1621, 1624, 1638, 1645,\n",
       "        1657, 1674, 1689, 1691, 1696, 1698, 1703, 1718, 1719, 1724, 1739,\n",
       "        1740, 1741, 1760, 1761, 1764, 1770, 1782, 1796, 1805, 1808, 1813,\n",
       "        1820, 1828, 1845, 1865, 1866, 1868, 1869, 1883, 1891, 1906, 1911,\n",
       "        1919, 1926, 1944])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for cat in class_indices:\n",
    "    print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n",
      "342\n",
      "95\n",
      "1007\n",
      "38\n",
      "76\n",
      "190\n"
     ]
    }
   ],
   "source": [
    "for indices in class_indices.values():\n",
    "    print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
       "         11,   12,   13,   14,   15,   16,   17,   18,   19,   20,   21,\n",
       "         22,   23,   24,   25,   26,   27,   28,   29,   30,   31,   32,\n",
       "         33,   34,   35,   36,   37,   38,   39,   40,   41,   42,   43,\n",
       "         44,   45,   46,   47,   48,   49,   50,   51,   52,   53,   54,\n",
       "         55,   56,   57,   58,   59,   60,   61,   62,   63,   64,   65,\n",
       "         66,   67,   68,   69,   70,   71,   72,   73,   74,   75,   76,\n",
       "         77,   78,   79,   80,   81,   82,   83,   84,   85,   86,   87,\n",
       "         88,   89,   90,   91,   92,   93,   94,   95,   96,   97,   98,\n",
       "         99,  100,  101,  102,  103,  104,  105,  106,  107,  108,  109,\n",
       "        110,  111,  112,  113,  114,  115,  116,  117,  118,  119,  120,\n",
       "        121,  122,  123,  124,  125,  126,  127,  128,  129,  130,  131,\n",
       "        132,  133,  134,  135,  136,  137,  138,  139,  140,  141,  142,\n",
       "        143,  144,  145,  146,  147,  148,  149,  150,  151,  152,  153,\n",
       "        154,  155,  156,  157,  158,  159,  160,  161,  162,  163,  164,\n",
       "        165,  166,  167,  168,  169,  170,  171,  172,  173,  174,  175,\n",
       "        176,  177,  178,  179,  180,  181,  182,  183,  184,  185,  186,\n",
       "        187,  188,  189,  190,  191,  192,  193,  194,  195,  196,  197,\n",
       "        198,  199,  200,  201,  202,  203,  204,  205,  206,  207,  208,\n",
       "        209,  210,  211,  212,  213,  214,  215,  216,  217,  218,  219,\n",
       "        220,  221,  222,  223,  224,  225,  226,  227,  228,  229,  230,\n",
       "        231,  232,  233,  234,  235,  236,  237,  238,  239,  240,  241,\n",
       "        242,  243,  244,  245,  246,  247,  248,  249,  250,  251,  252,\n",
       "        253,  254,  255,  256,  257,  258,  259,  260,  261,  262,  263,\n",
       "        264,  265,  266,  267,  268,  269,  270,  271,  272,  273,  274,\n",
       "        275,  276,  277,  278,  279,  280,  281,  282,  283,  284,  285,\n",
       "        286,  287,  288,  289,  290,  291,  292,  293,  294,  295,  296,\n",
       "        297,  298,  299,  300,  301,  302,  303,  304,  305,  306,  307,\n",
       "        308,  309,  310,  311,  312,  313,  314,  315,  316,  317,  318,\n",
       "        319,  320,  321,  322,  323,  324,  325,  326,  327,  328,  329,\n",
       "        330,  331,  332,  333,  334,  335,  336,  337,  338,  339,  340,\n",
       "        341,  342,  343,  344,  345,  346,  347,  348,  349,  350,  351,\n",
       "        352,  353,  354,  355,  356,  357,  358,  359,  360,  361,  362,\n",
       "        363,  364,  365,  366,  367,  368,  369,  370,  371,  372,  373,\n",
       "        374,  375,  376,  377,  378,  379,  380,  381,  382,  383,  384,\n",
       "        385,  386,  387,  388,  389,  390,  391,  392,  393,  394,  395,\n",
       "        396,  397,  398,  399,  400,  401,  402,  403,  404,  405,  406,\n",
       "        407,  408,  409,  410,  411,  412,  413,  414,  415,  416,  417,\n",
       "        418,  419,  420,  421,  422,  423,  424,  425,  426,  427,  428,\n",
       "        429,  430,  431,  432,  433,  434,  435,  436,  437,  438,  439,\n",
       "        440,  441,  442,  443,  444,  445,  446,  447,  448,  449,  450,\n",
       "        451,  452,  453,  454,  455,  456,  457,  458,  459,  460,  461,\n",
       "        462,  463,  464,  465,  466,  467,  468,  469,  470,  471,  472,\n",
       "        473,  474,  475,  476,  477,  478,  479,  480,  481,  482,  483,\n",
       "        484,  485,  486,  487,  488,  489,  490,  491,  492,  493,  494,\n",
       "        495,  496,  497,  498,  499,  500,  501,  502,  503,  504,  505,\n",
       "        506,  507,  508,  509,  510,  511,  512,  513,  514,  515,  516,\n",
       "        517,  518,  519,  520,  521,  522,  523,  524,  525,  526,  527,\n",
       "        528,  529,  530,  531,  532,  533,  534,  535,  536,  537,  538,\n",
       "        539,  540,  541,  542,  543,  544,  545,  546,  547,  548,  549,\n",
       "        550,  551,  552,  553,  554,  555,  556,  557,  558,  559,  560,\n",
       "        561,  562,  563,  564,  565,  566,  567,  568,  569,  570,  571,\n",
       "        572,  573,  574,  575,  576,  577,  578,  579,  580,  581,  582,\n",
       "        583,  584,  585,  586,  587,  588,  589,  590,  591,  592,  593,\n",
       "        594,  595,  596,  597,  598,  599,  600,  601,  602,  603,  604,\n",
       "        605,  606,  607,  608,  609,  610,  611,  612,  613,  614,  615,\n",
       "        616,  617,  618,  619,  620,  621,  622,  623,  624,  625,  626,\n",
       "        627,  628,  629,  630,  631,  632,  633,  634,  635,  636,  637,\n",
       "        638,  639,  640,  641,  642,  643,  644,  645,  646,  647,  648,\n",
       "        649,  650,  651,  652,  653,  654,  655,  656,  657,  658,  659,\n",
       "        660,  661,  662,  663,  664,  665,  666,  667,  668,  669,  670,\n",
       "        671,  672,  673,  674,  675,  676,  677,  678,  679,  680,  681,\n",
       "        682,  683,  684,  685,  686,  687,  688,  689,  690,  691,  692,\n",
       "        693,  694,  695,  696,  697,  698,  699,  700,  701,  702,  703,\n",
       "        704,  705,  706,  707,  708,  709,  710,  711,  712,  713,  714,\n",
       "        715,  716,  717,  718,  719,  720,  721,  722,  723,  724,  725,\n",
       "        726,  727,  728,  729,  730,  731,  732,  733,  734,  735,  736,\n",
       "        737,  738,  739,  740,  741,  742,  743,  744,  745,  746,  747,\n",
       "        748,  749,  750,  751,  752,  753,  754,  755,  756,  757,  758,\n",
       "        759,  760,  761,  762,  763,  764,  765,  766,  767,  768,  769,\n",
       "        770,  771,  772,  773,  774,  775,  776,  777,  778,  779,  780,\n",
       "        781,  782,  783,  784,  785,  786,  787,  788,  789,  790,  791,\n",
       "        792,  793,  794,  795,  796,  797,  798,  799,  800,  801,  802,\n",
       "        803,  804,  805,  806,  807,  808,  809,  810,  811,  812,  813,\n",
       "        814,  815,  816,  817,  818,  819,  820,  821,  822,  823,  824,\n",
       "        825,  826,  827,  828,  829,  830,  831,  832,  833,  834,  835,\n",
       "        836,  837,  838,  839,  840,  841,  842,  843,  844,  845,  846,\n",
       "        847,  848,  849,  850,  851,  852,  853,  854,  855,  856,  857,\n",
       "        858,  859,  860,  861,  862,  863,  864,  865,  866,  867,  868,\n",
       "        869,  870,  871,  872,  873,  874,  875,  876,  877,  878,  879,\n",
       "        880,  881,  882,  883,  884,  885,  886,  887,  888,  889,  890,\n",
       "        891,  892,  893,  894,  895,  896,  897,  898,  899,  900,  901,\n",
       "        902,  903,  904,  905,  906,  907,  908,  909,  910,  911,  912,\n",
       "        913,  914,  915,  916,  917,  918,  919,  920,  921,  922,  923,\n",
       "        924,  925,  926,  927,  928,  929,  930,  931,  932,  933,  934,\n",
       "        935,  936,  937,  938,  939,  940,  941,  942,  943,  944,  945,\n",
       "        946,  947,  948,  949,  950,  951,  952,  953,  954,  955,  956,\n",
       "        957,  958,  959,  960,  961,  962,  963,  964,  965,  966,  967,\n",
       "        968,  969,  970,  971,  972,  973,  974,  975,  976,  977,  978,\n",
       "        979,  980,  981,  982,  983,  984,  985,  986,  987,  988,  989,\n",
       "        990,  991,  992,  993,  994,  995,  996,  997,  998,  999, 1000,\n",
       "       1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011,\n",
       "       1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022,\n",
       "       1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033,\n",
       "       1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044,\n",
       "       1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055,\n",
       "       1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066,\n",
       "       1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077,\n",
       "       1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088,\n",
       "       1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099,\n",
       "       1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110,\n",
       "       1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121,\n",
       "       1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132,\n",
       "       1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143,\n",
       "       1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154,\n",
       "       1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165,\n",
       "       1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176,\n",
       "       1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,\n",
       "       1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198,\n",
       "       1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209,\n",
       "       1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220,\n",
       "       1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231,\n",
       "       1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242,\n",
       "       1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253,\n",
       "       1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264,\n",
       "       1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275,\n",
       "       1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286,\n",
       "       1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297,\n",
       "       1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308,\n",
       "       1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319,\n",
       "       1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330,\n",
       "       1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341,\n",
       "       1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352,\n",
       "       1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363,\n",
       "       1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374,\n",
       "       1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385,\n",
       "       1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396,\n",
       "       1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407,\n",
       "       1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418,\n",
       "       1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429,\n",
       "       1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440,\n",
       "       1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451,\n",
       "       1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462,\n",
       "       1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473,\n",
       "       1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484,\n",
       "       1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495,\n",
       "       1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506,\n",
       "       1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517,\n",
       "       1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528,\n",
       "       1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539,\n",
       "       1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550,\n",
       "       1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561,\n",
       "       1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572,\n",
       "       1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583,\n",
       "       1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594,\n",
       "       1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605,\n",
       "       1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616,\n",
       "       1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627,\n",
       "       1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638,\n",
       "       1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649,\n",
       "       1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660,\n",
       "       1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671,\n",
       "       1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682,\n",
       "       1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693,\n",
       "       1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704,\n",
       "       1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715,\n",
       "       1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726,\n",
       "       1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737,\n",
       "       1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748,\n",
       "       1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759,\n",
       "       1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770,\n",
       "       1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781,\n",
       "       1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792,\n",
       "       1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803,\n",
       "       1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814,\n",
       "       1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825,\n",
       "       1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836,\n",
       "       1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847,\n",
       "       1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858,\n",
       "       1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869,\n",
       "       1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880,\n",
       "       1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891,\n",
       "       1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902,\n",
       "       1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913,\n",
       "       1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924,\n",
       "       1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935,\n",
       "       1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946,\n",
       "       1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(len(num_atoms))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TEST_DATA = 2000\n",
    "train_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_test_indices = train_test_split(\n",
    "    indices, \n",
    "    train_size=train_size,\n",
    "    test_size=min(len(indices)-train_size, MAX_TEST_DATA),\n",
    "    random_state=42,\n",
    "    stratify=encoded_structure_types,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1757"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_test = encoded_structure_types[val_test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices, test_indices = train_test_split(\n",
    "    val_test_indices, \n",
    "    test_size=0.5, \n",
    "    random_state=42,\n",
    "    stratify=y_val_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = scattering_patterns[train_indices], encoded_structure_types[train_indices]\n",
    "X_val, y_val = scattering_patterns[val_indices], encoded_structure_types[val_indices]\n",
    "X_test, y_test = scattering_patterns[test_indices], encoded_structure_types[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6]), array([ 21,  35,  10, 103,   4,   8,  19]))\n",
      "0: 10.5\n",
      "1: 17.5\n",
      "2: 5.0\n",
      "3: 51.5\n",
      "4: 2.0\n",
      "5: 4.0\n",
      "6: 9.5\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))\n",
    "for n in np.unique(y_train):\n",
    "    print(f'{n}: {np.unique(y_train, return_counts=True)[1][n]/len(y_train)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6]), array([ 94, 153,  43, 452,  17,  34,  85]))\n",
      "0: 10.70615034168565\n",
      "1: 17.425968109339408\n",
      "2: 4.89749430523918\n",
      "3: 51.48063781321185\n",
      "4: 1.9362186788154898\n",
      "5: 3.8724373576309796\n",
      "6: 9.681093394077449\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_val, return_counts=True))\n",
    "for n in np.unique(y_val):\n",
    "    print(f'{n}: {np.unique(y_val, return_counts=True)[1][n]/len(y_val)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6]), array([ 94, 154,  42, 452,  17,  34,  86]))\n",
      "0: 10.693970420932878\n",
      "1: 17.51990898748578\n",
      "2: 4.778156996587031\n",
      "3: 51.42207053469852\n",
      "4: 1.9340159271899888\n",
      "5: 3.8680318543799777\n",
      "6: 9.783845278725826\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_test, return_counts=True))\n",
    "for n in np.unique(y_test):\n",
    "    print(f'{n}: {np.unique(y_test, return_counts=True)[1][n]/len(y_test)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.   , -0.008, -0.016, -0.024, -0.031, -0.039, -0.047, -0.053,\n",
       "       -0.06 , -0.068, -0.073, -0.077, -0.085, -0.091, -0.091, -0.097,\n",
       "       -0.107, -0.073,  0.635,  0.708, -0.07 , -0.119, -0.111, -0.11 ,\n",
       "       -0.116, -0.089,  0.112, -0.015, -0.108, -0.104, -0.098, -0.016,\n",
       "        0.403,  0.064, -0.08 , -0.082, -0.05 ,  0.092, -0.021, -0.063,\n",
       "       -0.049,  0.096,  0.077, -0.037, -0.038, -0.032, -0.028, -0.024,\n",
       "       -0.019, -0.016, -0.012, -0.008,  0.009,  0.009,  0.   ,  0.002,\n",
       "        0.003,  0.005,  0.006,  0.007,  0.007,  0.008,  0.008,  0.008,\n",
       "        0.008,  0.008,  0.007,  0.006,  0.005,  0.005,  0.003,  0.002,\n",
       "        0.002,  0.001, -0.   , -0.001, -0.002, -0.003, -0.003, -0.004,\n",
       "       -0.004, -0.005, -0.005, -0.005, -0.005, -0.005, -0.004, -0.004,\n",
       "       -0.004, -0.003, -0.003, -0.002, -0.002, -0.001, -0.001, -0.   ,\n",
       "        0.001,  0.001,  0.001,  0.002,  0.002,  0.003,  0.003,  0.003,\n",
       "        0.003,  0.003,  0.003,  0.003,  0.003,  0.003,  0.002,  0.002,\n",
       "        0.002,  0.001,  0.001,  0.001,  0.   , -0.   , -0.   , -0.001,\n",
       "       -0.001, -0.001, -0.002, -0.002, -0.002, -0.002, -0.002, -0.002,\n",
       "       -0.002, -0.002, -0.002, -0.002, -0.002, -0.002], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(\n",
    "    n_estimators=500, \n",
    "    random_state=42, \n",
    "    early_stopping_rounds=10, \n",
    "    #use_label_encoder=False, \n",
    "    eval_metric='mlogloss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.28500\tvalidation_1-mlogloss:1.46071\n",
      "[1]\tvalidation_0-mlogloss:0.96352\tvalidation_1-mlogloss:1.22516\n",
      "[2]\tvalidation_0-mlogloss:0.74513\tvalidation_1-mlogloss:1.07674\n",
      "[3]\tvalidation_0-mlogloss:0.58813\tvalidation_1-mlogloss:0.96907\n",
      "[4]\tvalidation_0-mlogloss:0.47276\tvalidation_1-mlogloss:0.88938\n",
      "[5]\tvalidation_0-mlogloss:0.37590\tvalidation_1-mlogloss:0.82858\n",
      "[6]\tvalidation_0-mlogloss:0.30086\tvalidation_1-mlogloss:0.78518\n",
      "[7]\tvalidation_0-mlogloss:0.24563\tvalidation_1-mlogloss:0.75087\n",
      "[8]\tvalidation_0-mlogloss:0.20208\tvalidation_1-mlogloss:0.73052\n",
      "[9]\tvalidation_0-mlogloss:0.16770\tvalidation_1-mlogloss:0.70978\n",
      "[10]\tvalidation_0-mlogloss:0.14136\tvalidation_1-mlogloss:0.68713\n",
      "[11]\tvalidation_0-mlogloss:0.12106\tvalidation_1-mlogloss:0.67261\n",
      "[12]\tvalidation_0-mlogloss:0.10416\tvalidation_1-mlogloss:0.65920\n",
      "[13]\tvalidation_0-mlogloss:0.09080\tvalidation_1-mlogloss:0.65417\n",
      "[14]\tvalidation_0-mlogloss:0.08039\tvalidation_1-mlogloss:0.64592\n",
      "[15]\tvalidation_0-mlogloss:0.07140\tvalidation_1-mlogloss:0.64200\n",
      "[16]\tvalidation_0-mlogloss:0.06440\tvalidation_1-mlogloss:0.63922\n",
      "[17]\tvalidation_0-mlogloss:0.05865\tvalidation_1-mlogloss:0.63752\n",
      "[18]\tvalidation_0-mlogloss:0.05372\tvalidation_1-mlogloss:0.63408\n",
      "[19]\tvalidation_0-mlogloss:0.04933\tvalidation_1-mlogloss:0.63323\n",
      "[20]\tvalidation_0-mlogloss:0.04596\tvalidation_1-mlogloss:0.63358\n",
      "[21]\tvalidation_0-mlogloss:0.04277\tvalidation_1-mlogloss:0.63031\n",
      "[22]\tvalidation_0-mlogloss:0.04022\tvalidation_1-mlogloss:0.63052\n",
      "[23]\tvalidation_0-mlogloss:0.03785\tvalidation_1-mlogloss:0.63099\n",
      "[24]\tvalidation_0-mlogloss:0.03573\tvalidation_1-mlogloss:0.62728\n",
      "[25]\tvalidation_0-mlogloss:0.03414\tvalidation_1-mlogloss:0.62655\n",
      "[26]\tvalidation_0-mlogloss:0.03290\tvalidation_1-mlogloss:0.62792\n",
      "[27]\tvalidation_0-mlogloss:0.03177\tvalidation_1-mlogloss:0.62850\n",
      "[28]\tvalidation_0-mlogloss:0.03076\tvalidation_1-mlogloss:0.62882\n",
      "[29]\tvalidation_0-mlogloss:0.02994\tvalidation_1-mlogloss:0.62870\n",
      "[30]\tvalidation_0-mlogloss:0.02910\tvalidation_1-mlogloss:0.62815\n",
      "[31]\tvalidation_0-mlogloss:0.02839\tvalidation_1-mlogloss:0.62797\n",
      "[32]\tvalidation_0-mlogloss:0.02772\tvalidation_1-mlogloss:0.63080\n",
      "[33]\tvalidation_0-mlogloss:0.02708\tvalidation_1-mlogloss:0.63066\n",
      "[34]\tvalidation_0-mlogloss:0.02653\tvalidation_1-mlogloss:0.62954\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=10,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=10,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=10,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_iteration = clf.best_iteration\n",
    "best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f24fe938df0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = clf.evals_result()\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(results[\"validation_0\"][\"mlogloss\"], label=\"training loss\")\n",
    "plt.plot(results[\"validation_1\"][\"mlogloss\"], label=\"validation loss\")\n",
    "plt.axvline(best_iteration, color=\"gray\", label=\"optimal tree number\")\n",
    "plt.xlabel(\"number of trees\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 0, 3, 2, 3, 3, 3, 3, 3, 6, 3, 3, 1, 1, 1, 1, 1, 1, 6, 3, 3,\n",
       "       0, 3, 1, 3, 3, 3, 3, 1, 0, 1, 0, 6, 3, 0, 3, 2, 3, 4, 0, 3, 0, 6,\n",
       "       3, 3, 3, 1, 3, 1, 5, 3, 3, 3, 3, 4, 1, 3, 3, 3, 4, 1, 3, 0, 1, 3,\n",
       "       3, 3, 1, 1, 0, 3, 3, 3, 1, 3, 3, 4, 1, 3, 2, 3, 3, 3, 3, 3, 3, 3,\n",
       "       6, 6, 1, 5, 1, 6, 6, 3, 3, 3, 3, 0, 3, 3, 3, 3, 1, 3, 0, 3, 6, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 6, 3, 2, 3, 3, 6, 1, 0, 3, 0, 6, 3,\n",
       "       3, 0, 3, 5, 3, 0, 3, 3, 3, 2, 6, 3, 3, 3, 3, 3, 1, 1, 3, 0, 0, 3,\n",
       "       1, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 6, 3, 1, 1, 0, 3, 3, 1, 1, 3, 3,\n",
       "       3, 3, 3, 6, 3, 3, 6, 3, 0, 0, 3, 0, 1, 3, 3, 1, 3, 6, 1, 3, 3, 1,\n",
       "       3, 3, 6, 2, 0, 3, 3, 3, 1, 3, 3, 0, 0, 3, 3, 3, 1, 0, 3, 3, 3, 3,\n",
       "       3, 3, 6, 6, 2, 3, 1, 1, 3, 3, 3, 0, 3, 3, 3, 1, 3, 1, 3, 2, 3, 1,\n",
       "       1, 3, 3, 1, 6, 3, 3, 3, 3, 1, 3, 6, 3, 3, 0, 3, 1, 1, 3, 1, 0, 2,\n",
       "       0, 6, 6, 3, 1, 6, 1, 0, 1, 3, 1, 4, 3, 3, 3, 1, 3, 3, 6, 3, 3, 3,\n",
       "       0, 3, 1, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 0, 6, 3, 6, 1, 2, 1, 3, 3,\n",
       "       3, 1, 6, 0, 1, 3, 3, 3, 3, 6, 1, 3, 3, 3, 1, 3, 2, 3, 1, 3, 3, 3,\n",
       "       3, 3, 3, 3, 6, 1, 1, 1, 0, 0, 3, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3,\n",
       "       0, 3, 3, 0, 6, 3, 1, 3, 5, 3, 3, 3, 1, 6, 4, 3, 3, 3, 2, 3, 6, 5,\n",
       "       3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 0, 3, 1,\n",
       "       3, 1, 0, 3, 5, 3, 3, 6, 3, 3, 6, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 6,\n",
       "       3, 3, 1, 6, 0, 3, 3, 1, 3, 0, 6, 3, 6, 3, 3, 3, 3, 3, 2, 0, 1, 3,\n",
       "       3, 3, 3, 3, 1, 3, 5, 3, 3, 1, 3, 0, 0, 1, 0, 3, 1, 6, 3, 0, 3, 6,\n",
       "       6, 1, 3, 3, 2, 3, 5, 3, 0, 1, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 0, 3,\n",
       "       3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 6, 6, 0, 0, 6,\n",
       "       3, 5, 3, 5, 1, 1, 3, 0, 3, 6, 3, 1, 3, 3, 3, 3, 3, 3, 5, 5, 1, 2,\n",
       "       1, 3, 6, 3, 2, 3, 6, 3, 3, 3, 3, 3, 1, 0, 6, 1, 3, 0, 3, 1, 3, 3,\n",
       "       2, 3, 6, 1, 1, 6, 3, 3, 3, 0, 3, 3, 3, 1, 1, 3, 2, 3, 5, 3, 6, 3,\n",
       "       3, 3, 3, 6, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 6,\n",
       "       1, 3, 6, 3, 3, 0, 3, 3, 3, 3, 3, 5, 6, 3, 0, 1, 2, 3, 3, 2, 3, 3,\n",
       "       6, 1, 3, 1, 6, 3, 0, 3, 3, 6, 3, 6, 3, 0, 3, 1, 3, 3, 3, 3, 3, 3,\n",
       "       3, 1, 3, 1, 0, 3, 3, 3, 0, 0, 3, 3, 6, 0, 3, 3, 6, 1, 6, 3, 6, 3,\n",
       "       6, 3, 0, 3, 1, 3, 3, 3, 5, 3, 3, 4, 3, 3, 1, 1, 0, 3, 2, 0, 3, 3,\n",
       "       3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3,\n",
       "       3, 1, 3, 3, 3, 3, 3, 3, 3, 5, 0, 4, 6, 3, 1, 1, 3, 3, 3, 1, 3, 3,\n",
       "       3, 1, 3, 6, 3, 0, 3, 3, 1, 3, 3, 1, 5, 6, 3, 3, 3, 1, 1, 3, 6, 2,\n",
       "       3, 3, 6, 1, 1, 5, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 6, 3, 3, 1, 3, 3,\n",
       "       3, 3, 2, 3, 3, 6, 3, 3, 2, 6, 0, 0, 3, 3, 1, 3, 3, 4, 3, 6, 3, 5,\n",
       "       3, 3, 5, 0, 3, 3, 6, 3, 3, 3, 3, 0, 1, 6, 3, 3, 3, 0, 3, 3, 1, 3,\n",
       "       1, 1, 6, 3, 3, 6, 3, 5, 6, 3, 3, 3, 6, 3, 1, 3, 3, 3, 3, 6, 3, 3,\n",
       "       3, 3, 0, 1, 3, 3, 3, 3, 6, 0, 6, 3, 3, 3, 1, 3, 3, 3, 0, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 1, 1, 0, 0, 3, 5, 0, 3, 3, 6, 6, 3, 3, 6, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HCP', 'Oct', 'BCC', 'HCP', 'FCC', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'SC', 'HCP', 'HCP', 'Dec', 'Dec', 'Dec', 'Dec', 'Dec',\n",
       "       'Dec', 'SC', 'HCP', 'HCP', 'BCC', 'HCP', 'Dec', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'BCC', 'Dec', 'BCC', 'SC', 'HCP', 'BCC',\n",
       "       'HCP', 'FCC', 'HCP', 'Ico', 'BCC', 'HCP', 'BCC', 'SC', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'Dec', 'Oct', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'Ico', 'Dec', 'HCP', 'HCP', 'HCP', 'Ico', 'Dec', 'HCP',\n",
       "       'BCC', 'Dec', 'HCP', 'HCP', 'HCP', 'Dec', 'Dec', 'BCC', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'Ico', 'Dec', 'HCP', 'FCC',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'SC', 'SC', 'Dec',\n",
       "       'Oct', 'Dec', 'SC', 'SC', 'HCP', 'HCP', 'HCP', 'HCP', 'BCC', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'BCC', 'HCP', 'SC', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'SC', 'HCP',\n",
       "       'HCP', 'SC', 'HCP', 'FCC', 'HCP', 'HCP', 'SC', 'Dec', 'BCC', 'HCP',\n",
       "       'BCC', 'SC', 'HCP', 'HCP', 'BCC', 'HCP', 'Oct', 'HCP', 'BCC',\n",
       "       'HCP', 'HCP', 'HCP', 'FCC', 'SC', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'Dec', 'Dec', 'HCP', 'BCC', 'BCC', 'HCP', 'Dec', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'BCC', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'SC', 'HCP', 'Dec', 'Dec', 'BCC', 'HCP', 'HCP', 'Dec', 'Dec',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'SC', 'HCP', 'HCP', 'SC', 'HCP',\n",
       "       'BCC', 'BCC', 'HCP', 'BCC', 'Dec', 'HCP', 'HCP', 'Dec', 'HCP',\n",
       "       'SC', 'Dec', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'SC', 'FCC', 'BCC',\n",
       "       'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'BCC', 'BCC', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'BCC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'SC', 'SC', 'FCC', 'HCP', 'Dec', 'Dec', 'HCP', 'HCP', 'HCP',\n",
       "       'BCC', 'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'Dec', 'HCP', 'FCC',\n",
       "       'HCP', 'Dec', 'Dec', 'HCP', 'HCP', 'Dec', 'SC', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'SC', 'HCP', 'HCP', 'BCC', 'HCP',\n",
       "       'Dec', 'Dec', 'HCP', 'Dec', 'BCC', 'FCC', 'BCC', 'SC', 'SC', 'HCP',\n",
       "       'Dec', 'SC', 'Dec', 'BCC', 'Dec', 'HCP', 'Dec', 'Ico', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'SC', 'HCP', 'HCP', 'HCP',\n",
       "       'BCC', 'HCP', 'Dec', 'HCP', 'HCP', 'SC', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'BCC', 'SC', 'HCP', 'SC', 'Dec', 'FCC',\n",
       "       'Dec', 'HCP', 'HCP', 'HCP', 'Dec', 'SC', 'BCC', 'Dec', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'SC', 'Dec', 'HCP', 'HCP', 'HCP', 'Dec',\n",
       "       'HCP', 'FCC', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'SC', 'Dec', 'Dec', 'Dec', 'BCC', 'BCC', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'BCC', 'HCP', 'HCP', 'BCC', 'HCP',\n",
       "       'HCP', 'HCP', 'BCC', 'HCP', 'HCP', 'BCC', 'SC', 'HCP', 'Dec',\n",
       "       'HCP', 'Oct', 'HCP', 'HCP', 'HCP', 'Dec', 'SC', 'Ico', 'HCP',\n",
       "       'HCP', 'HCP', 'FCC', 'HCP', 'SC', 'Oct', 'HCP', 'Dec', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP', 'HCP', 'BCC', 'HCP',\n",
       "       'Dec', 'HCP', 'Dec', 'BCC', 'HCP', 'Oct', 'HCP', 'HCP', 'SC',\n",
       "       'HCP', 'HCP', 'SC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'Dec', 'Dec', 'Dec', 'HCP', 'SC', 'HCP', 'HCP', 'Dec', 'SC', 'BCC',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'BCC', 'SC', 'HCP', 'SC', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'FCC', 'BCC', 'Dec', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'Oct', 'HCP', 'HCP', 'Dec', 'HCP',\n",
       "       'BCC', 'BCC', 'Dec', 'BCC', 'HCP', 'Dec', 'SC', 'HCP', 'BCC',\n",
       "       'HCP', 'SC', 'SC', 'Dec', 'HCP', 'HCP', 'FCC', 'HCP', 'Oct', 'HCP',\n",
       "       'BCC', 'Dec', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'SC', 'HCP', 'BCC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'FCC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'Dec', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'SC', 'SC', 'BCC', 'BCC', 'SC', 'HCP',\n",
       "       'Oct', 'HCP', 'Oct', 'Dec', 'Dec', 'HCP', 'BCC', 'HCP', 'SC',\n",
       "       'HCP', 'Dec', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'Oct',\n",
       "       'Oct', 'Dec', 'FCC', 'Dec', 'HCP', 'SC', 'HCP', 'FCC', 'HCP', 'SC',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'Dec', 'BCC', 'SC', 'Dec',\n",
       "       'HCP', 'BCC', 'HCP', 'Dec', 'HCP', 'HCP', 'FCC', 'HCP', 'SC',\n",
       "       'Dec', 'Dec', 'SC', 'HCP', 'HCP', 'HCP', 'BCC', 'HCP', 'HCP',\n",
       "       'HCP', 'Dec', 'Dec', 'HCP', 'FCC', 'HCP', 'Oct', 'HCP', 'SC',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'SC', 'HCP', 'HCP', 'HCP', 'Dec',\n",
       "       'Dec', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'Dec',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'SC', 'Dec', 'HCP', 'SC', 'HCP', 'HCP',\n",
       "       'BCC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'Oct', 'SC', 'HCP',\n",
       "       'BCC', 'Dec', 'FCC', 'HCP', 'HCP', 'FCC', 'HCP', 'HCP', 'SC',\n",
       "       'Dec', 'HCP', 'Dec', 'SC', 'HCP', 'BCC', 'HCP', 'HCP', 'SC', 'HCP',\n",
       "       'SC', 'HCP', 'BCC', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'Dec', 'BCC', 'HCP', 'HCP',\n",
       "       'HCP', 'BCC', 'BCC', 'HCP', 'HCP', 'SC', 'BCC', 'HCP', 'HCP', 'SC',\n",
       "       'Dec', 'SC', 'HCP', 'SC', 'HCP', 'SC', 'HCP', 'BCC', 'HCP', 'Dec',\n",
       "       'HCP', 'HCP', 'HCP', 'Oct', 'HCP', 'HCP', 'Ico', 'HCP', 'HCP',\n",
       "       'Dec', 'Dec', 'BCC', 'HCP', 'FCC', 'BCC', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'SC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'BCC', 'BCC', 'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'Dec', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'Oct', 'BCC', 'Ico', 'SC', 'HCP', 'Dec',\n",
       "       'Dec', 'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP', 'Dec',\n",
       "       'HCP', 'SC', 'HCP', 'BCC', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP',\n",
       "       'Dec', 'Oct', 'SC', 'HCP', 'HCP', 'HCP', 'Dec', 'Dec', 'HCP', 'SC',\n",
       "       'FCC', 'HCP', 'HCP', 'SC', 'Dec', 'Dec', 'Oct', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'SC', 'HCP', 'HCP', 'HCP', 'SC', 'HCP',\n",
       "       'HCP', 'Dec', 'HCP', 'HCP', 'HCP', 'HCP', 'FCC', 'HCP', 'HCP',\n",
       "       'SC', 'HCP', 'HCP', 'FCC', 'SC', 'BCC', 'BCC', 'HCP', 'HCP', 'Dec',\n",
       "       'HCP', 'HCP', 'Ico', 'HCP', 'SC', 'HCP', 'Oct', 'HCP', 'HCP',\n",
       "       'Oct', 'BCC', 'HCP', 'HCP', 'SC', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'BCC', 'Dec', 'SC', 'HCP', 'HCP', 'HCP', 'BCC', 'HCP', 'HCP',\n",
       "       'Dec', 'HCP', 'Dec', 'Dec', 'SC', 'HCP', 'HCP', 'SC', 'HCP', 'Oct',\n",
       "       'SC', 'HCP', 'HCP', 'HCP', 'SC', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'SC', 'HCP', 'HCP', 'HCP', 'HCP', 'BCC', 'Dec', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'SC', 'BCC', 'SC', 'HCP', 'HCP', 'HCP', 'Dec',\n",
       "       'HCP', 'HCP', 'HCP', 'BCC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'Dec', 'Dec', 'BCC', 'BCC', 'HCP',\n",
       "       'Oct', 'BCC', 'HCP', 'HCP', 'SC', 'SC', 'HCP', 'HCP', 'SC', 'Dec'],\n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = le.inverse_transform(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HCP', 'Oct', 'BCC', 'HCP', 'FCC', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'Dec', 'SC', 'SC', 'HCP', 'Dec', 'Oct', 'Dec', 'Dec', 'Dec', 'FCC',\n",
       "       'SC', 'HCP', 'HCP', 'BCC', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'Dec', 'BCC', 'Dec', 'BCC', 'SC', 'HCP', 'BCC', 'HCP',\n",
       "       'Ico', 'HCP', 'BCC', 'BCC', 'HCP', 'BCC', 'SC', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'Dec', 'Dec', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'Dec', 'Dec', 'HCP', 'HCP', 'HCP', 'Ico', 'Dec', 'HCP', 'BCC',\n",
       "       'Dec', 'HCP', 'HCP', 'Dec', 'HCP', 'Dec', 'BCC', 'HCP', 'HCP',\n",
       "       'HCP', 'Dec', 'HCP', 'HCP', 'BCC', 'Dec', 'HCP', 'FCC', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'SC', 'SC', 'Oct', 'Dec',\n",
       "       'Dec', 'SC', 'BCC', 'HCP', 'HCP', 'HCP', 'HCP', 'BCC', 'HCP',\n",
       "       'HCP', 'HCP', 'SC', 'Dec', 'Dec', 'BCC', 'HCP', 'SC', 'FCC', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'SC', 'HCP', 'FCC', 'SC',\n",
       "       'HCP', 'FCC', 'HCP', 'HCP', 'SC', 'Dec', 'BCC', 'HCP', 'BCC',\n",
       "       'BCC', 'HCP', 'HCP', 'BCC', 'HCP', 'Oct', 'HCP', 'BCC', 'HCP',\n",
       "       'HCP', 'HCP', 'FCC', 'SC', 'HCP', 'HCP', 'HCP', 'Oct', 'Dec',\n",
       "       'Dec', 'Dec', 'FCC', 'BCC', 'BCC', 'HCP', 'Dec', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'BCC', 'Ico', 'HCP', 'HCP', 'HCP', 'BCC',\n",
       "       'HCP', 'Oct', 'Dec', 'BCC', 'HCP', 'Dec', 'Dec', 'Oct', 'Dec',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'SC', 'Dec', 'HCP', 'SC', 'HCP', 'BCC',\n",
       "       'BCC', 'HCP', 'BCC', 'Dec', 'HCP', 'HCP', 'Dec', 'HCP', 'SC',\n",
       "       'Oct', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'SC', 'Oct', 'BCC',\n",
       "       'HCP', 'HCP', 'HCP', 'FCC', 'HCP', 'HCP', 'SC', 'BCC', 'HCP',\n",
       "       'HCP', 'Oct', 'Dec', 'BCC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'Ico', 'BCC', 'FCC', 'Dec', 'Dec', 'Dec', 'HCP', 'HCP',\n",
       "       'HCP', 'BCC', 'HCP', 'HCP', 'HCP', 'FCC', 'Dec', 'Dec', 'HCP',\n",
       "       'FCC', 'HCP', 'Dec', 'Ico', 'HCP', 'HCP', 'FCC', 'SC', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'BCC', 'HCP', 'HCP', 'BCC',\n",
       "       'HCP', 'Dec', 'Dec', 'HCP', 'Dec', 'BCC', 'Oct', 'BCC', 'SC', 'SC',\n",
       "       'HCP', 'Oct', 'Dec', 'Oct', 'BCC', 'Dec', 'HCP', 'Dec', 'Oct',\n",
       "       'Dec', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'SC', 'HCP', 'Dec',\n",
       "       'HCP', 'BCC', 'HCP', 'Dec', 'HCP', 'HCP', 'SC', 'Dec', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'SC', 'BCC', 'SC', 'FCC', 'SC', 'Dec',\n",
       "       'FCC', 'FCC', 'HCP', 'HCP', 'HCP', 'Dec', 'SC', 'BCC', 'Dec',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'SC', 'Dec', 'HCP', 'Dec', 'HCP',\n",
       "       'HCP', 'HCP', 'Oct', 'HCP', 'Dec', 'HCP', 'HCP', 'Dec', 'HCP',\n",
       "       'HCP', 'Ico', 'HCP', 'SC', 'Dec', 'Dec', 'SC', 'BCC', 'BCC', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'BCC', 'HCP', 'HCP', 'BCC', 'HCP',\n",
       "       'HCP', 'HCP', 'BCC', 'HCP', 'HCP', 'BCC', 'SC', 'HCP', 'Dec',\n",
       "       'HCP', 'Dec', 'HCP', 'Dec', 'Dec', 'HCP', 'SC', 'BCC', 'HCP',\n",
       "       'HCP', 'HCP', 'Oct', 'HCP', 'SC', 'Oct', 'Dec', 'Dec', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP', 'HCP', 'BCC', 'HCP',\n",
       "       'Dec', 'HCP', 'FCC', 'BCC', 'HCP', 'FCC', 'HCP', 'HCP', 'SC',\n",
       "       'Dec', 'Ico', 'BCC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'Dec', 'Dec', 'Dec', 'HCP', 'SC', 'HCP', 'HCP', 'Dec', 'SC', 'BCC',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'BCC', 'SC', 'Dec', 'SC', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'Oct', 'BCC', 'Dec', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'FCC', 'HCP', 'HCP', 'Dec', 'HCP',\n",
       "       'SC', 'BCC', 'FCC', 'BCC', 'HCP', 'Dec', 'SC', 'HCP', 'BCC', 'HCP',\n",
       "       'SC', 'FCC', 'Dec', 'HCP', 'HCP', 'Ico', 'Dec', 'Dec', 'HCP',\n",
       "       'BCC', 'FCC', 'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'SC', 'HCP', 'BCC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'FCC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'Dec', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'SC', 'SC', 'BCC', 'BCC', 'Dec', 'HCP',\n",
       "       'Dec', 'HCP', 'FCC', 'Oct', 'FCC', 'HCP', 'BCC', 'HCP', 'Ico',\n",
       "       'HCP', 'FCC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'Dec',\n",
       "       'FCC', 'Dec', 'Ico', 'Dec', 'HCP', 'SC', 'HCP', 'Oct', 'HCP', 'SC',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'SC', 'Dec', 'BCC', 'SC', 'Dec', 'HCP',\n",
       "       'SC', 'HCP', 'Dec', 'HCP', 'HCP', 'FCC', 'HCP', 'SC', 'Dec', 'FCC',\n",
       "       'SC', 'HCP', 'HCP', 'HCP', 'BCC', 'HCP', 'HCP', 'Dec', 'Dec',\n",
       "       'Dec', 'HCP', 'Ico', 'HCP', 'Dec', 'HCP', 'SC', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'SC', 'HCP', 'HCP', 'HCP', 'FCC', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP',\n",
       "       'Dec', 'HCP', 'SC', 'FCC', 'HCP', 'SC', 'HCP', 'HCP', 'BCC', 'HCP',\n",
       "       'HCP', 'HCP', 'Oct', 'HCP', 'Dec', 'SC', 'HCP', 'BCC', 'FCC',\n",
       "       'FCC', 'HCP', 'HCP', 'Ico', 'HCP', 'HCP', 'SC', 'Dec', 'Dec',\n",
       "       'Dec', 'SC', 'HCP', 'BCC', 'HCP', 'HCP', 'Dec', 'HCP', 'SC', 'HCP',\n",
       "       'BCC', 'HCP', 'FCC', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'Dec', 'HCP', 'Dec', 'BCC', 'Oct', 'HCP', 'HCP', 'BCC',\n",
       "       'BCC', 'HCP', 'HCP', 'SC', 'BCC', 'Dec', 'HCP', 'Ico', 'Dec',\n",
       "       'BCC', 'HCP', 'SC', 'HCP', 'FCC', 'HCP', 'BCC', 'HCP', 'Dec',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'BCC', 'HCP', 'HCP',\n",
       "       'Dec', 'Dec', 'BCC', 'SC', 'Dec', 'BCC', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'SC', 'HCP', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP',\n",
       "       'BCC', 'BCC', 'HCP', 'HCP', 'SC', 'Oct', 'HCP', 'FCC', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'Dec', 'SC', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'Oct', 'BCC', 'BCC', 'SC', 'Dec', 'Oct',\n",
       "       'Dec', 'HCP', 'HCP', 'Oct', 'Dec', 'HCP', 'HCP', 'Dec', 'Dec',\n",
       "       'HCP', 'SC', 'HCP', 'BCC', 'HCP', 'HCP', 'Dec', 'HCP', 'HCP',\n",
       "       'FCC', 'Oct', 'SC', 'HCP', 'Dec', 'HCP', 'Oct', 'Dec', 'HCP',\n",
       "       'Oct', 'Oct', 'SC', 'HCP', 'FCC', 'Ico', 'Dec', 'Dec', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'HCP', 'HCP', 'SC', 'HCP', 'HCP', 'HCP', 'SC',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'HCP', 'HCP', 'Ico', 'HCP',\n",
       "       'SC', 'SC', 'HCP', 'HCP', 'FCC', 'SC', 'BCC', 'BCC', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'HCP', 'Ico', 'HCP', 'SC', 'HCP', 'FCC', 'HCP',\n",
       "       'HCP', 'Oct', 'BCC', 'Dec', 'HCP', 'SC', 'HCP', 'HCP', 'HCP',\n",
       "       'Dec', 'BCC', 'Dec', 'BCC', 'HCP', 'HCP', 'HCP', 'BCC', 'Ico',\n",
       "       'HCP', 'FCC', 'Dec', 'HCP', 'Dec', 'SC', 'Dec', 'HCP', 'SC', 'HCP',\n",
       "       'Oct', 'SC', 'HCP', 'Dec', 'HCP', 'SC', 'Dec', 'Dec', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'BCC', 'HCP', 'Dec', 'HCP', 'HCP', 'BCC', 'Dec',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'SC', 'BCC', 'SC', 'Dec', 'HCP', 'HCP',\n",
       "       'Dec', 'HCP', 'Oct', 'HCP', 'BCC', 'HCP', 'HCP', 'HCP', 'HCP',\n",
       "       'HCP', 'HCP', 'Dec', 'HCP', 'HCP', 'Dec', 'FCC', 'BCC', 'BCC',\n",
       "       'Dec', 'Oct', 'BCC', 'Dec', 'HCP', 'SC', 'SC', 'HCP', 'HCP', 'SC',\n",
       "       'Dec'], dtype='<U3')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = le.inverse_transform(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "kappa = cohen_kappa_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8100113765642776,\n",
       " 0.5798237850594804,\n",
       " 0.8100113765642776,\n",
       " 0.7940915157222028,\n",
       " 0.7080071131904331)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, f1_macro, f1_micro, f1_weighted, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_classification(scattering_patterns, structure_types, max_test_data=2000, train_size=200, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepares the dataset for classification by splitting it into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    scattering_patterns (list or numpy.ndarray): The scattering patterns for each structure.\n",
    "    structure_types (list of str): The structure type for each scattering pattern.\n",
    "    num_data_per_class (int): Number of data in the less represented class.\n",
    "    train_size (int): The number of samples used for training.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - X_train (numpy.ndarray): The training set features.\n",
    "        - y_train (numpy.ndarray): The training set labels.\n",
    "        - X_val (numpy.ndarray): The validation set features.\n",
    "        - y_val (numpy.ndarray): The validation set labels.\n",
    "        - X_test (numpy.ndarray): The test set features.\n",
    "        - y_test (numpy.ndarray): The test set labels.\n",
    "        - le (LabelEncoder): The label encoder used to encode the structure types.\n",
    "    \"\"\"\n",
    "    # Convert scattering_files to a NumPy array\n",
    "    scattering_patterns = np.array(scattering_patterns)\n",
    "    \n",
    "    # Encode the structure types into integers\n",
    "    le = LabelEncoder()\n",
    "    encoded_structure_types = le.fit_transform(structure_types)\n",
    "    \n",
    "    # Create a dictionary to store indices of each class\n",
    "    class_indices = {i: np.where(encoded_structure_types == i)[0] for i in np.unique(encoded_structure_types)}\n",
    "    \n",
    "    # Split the samples into train and val_test sets\n",
    "    indices = np.arange(len(num_atoms))\n",
    "    train_indices, val_test_indices = train_test_split(\n",
    "        indices, \n",
    "        train_size=train_size,\n",
    "        test_size=min(len(indices)-train_size, max_test_data),\n",
    "        random_state=random_state,\n",
    "        stratify=encoded_structure_types,\n",
    "    )\n",
    "    y_val_test = encoded_structure_types[val_test_indices]\n",
    "    \n",
    "    # Split the val_test samples equally into validation and test sets\n",
    "    val_indices, test_indices = train_test_split(\n",
    "        val_test_indices, \n",
    "        test_size=0.5, \n",
    "        random_state=random_state,\n",
    "        stratify=y_val_test\n",
    "    )\n",
    "    \n",
    "    print(f\"train: {len(train_indices)}\")\n",
    "    print(f\"validation: {len(val_indices)}\")\n",
    "    print(f\"test: {len(test_indices)}\")\n",
    "    \n",
    "    # Create the training, validation, and test sets\n",
    "    X_train, y_train = scattering_patterns[train_indices], encoded_structure_types[train_indices]\n",
    "    X_val, y_val = scattering_patterns[val_indices], encoded_structure_types[val_indices]\n",
    "    X_test, y_test = scattering_patterns[test_indices], encoded_structure_types[test_indices]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_classifier(X_train, y_train, X_val, y_val, X_test, y_test, le, random_state=42):\n",
    "    \"\"\"\n",
    "    Trains an XGBoost classifier and evaluates its performance on the test set.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (numpy.ndarray): The training set features.\n",
    "    y_train (numpy.ndarray): The training set labels.\n",
    "    X_val (numpy.ndarray): The validation set features.\n",
    "    y_val (numpy.ndarray): The validation set labels.\n",
    "    X_test (numpy.ndarray): The test set features.\n",
    "    y_test (numpy.ndarray): The test set labels.\n",
    "    le (LabelEncoder): The label encoder used to encode the structure types.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - X_train (numpy.ndarray): The training set features.\n",
    "        - y_train (numpy.ndarray): The training set labels.\n",
    "        - X_val (numpy.ndarray): The validation set features.\n",
    "        - y_val (numpy.ndarray): The validation set labels.\n",
    "        - X_test (numpy.ndarray): The test set features.\n",
    "        - y_test (numpy.ndarray): The test set labels.\n",
    "        - classification metrics: acc, f1_macro, f1_micro, f1_weighted, and kappa scores of the classifier on the test set.\n",
    "    \"\"\"\n",
    "    # Create a classifier\n",
    "    clf = XGBClassifier(\n",
    "        n_estimators=500, \n",
    "        random_state=random_state, \n",
    "        early_stopping_rounds=10, \n",
    "        #use_label_encoder=False, \n",
    "        eval_metric='mlogloss'\n",
    "    )\n",
    "    \n",
    "    # Train the classifier with early stopping\n",
    "    clf.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "        verbose=10\n",
    "    )\n",
    "    \n",
    "    # Predict the test set results\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Convert the predictions back to the original classes\n",
    "    #y_pred = le.inverse_transform(y_pred)\n",
    "    \n",
    "    # Convert the test labels back to the original classes\n",
    "    #y_test = le.inverse_transform(y_test)\n",
    "    \n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Calculate classification metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    \n",
    "    return y_test, y_pred, acc, f1_macro, f1_micro, f1_weighted, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_dict():\n",
    "    metrics_dict = {\n",
    "        \"train_size\": train_size,\n",
    "        \"y_true\": y_test_all,\n",
    "        \"y_pred\": y_pred_all,\n",
    "        \"accuracy\": acc_scores,\n",
    "        \"f1_macro\": f1macro_scores,\n",
    "        \"f1_micro\": f1micro_scores,\n",
    "        \"f1_weighted\": f1weighted_scores,\n",
    "        \"kappa\": kappa_scores\n",
    "    }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 600\n",
    "iterations = 10\n",
    "max_test_data = 2000\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "acc_scores = []\n",
    "f1macro_scores = []\n",
    "f1micro_scores = []\n",
    "f1weighted_scores = []\n",
    "kappa_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 600\n",
      "validation: 678\n",
      "test: 679\n",
      "random_state = 42\n",
      "[0]\tvalidation_0-mlogloss:1.23921\tvalidation_1-mlogloss:1.36167\n",
      "[10]\tvalidation_0-mlogloss:0.11943\tvalidation_1-mlogloss:0.42948\n",
      "[20]\tvalidation_0-mlogloss:0.03095\tvalidation_1-mlogloss:0.34797\n",
      "[30]\tvalidation_0-mlogloss:0.01642\tvalidation_1-mlogloss:0.33549\n",
      "[40]\tvalidation_0-mlogloss:0.01205\tvalidation_1-mlogloss:0.33210\n",
      "[50]\tvalidation_0-mlogloss:0.01027\tvalidation_1-mlogloss:0.33501\n",
      "[54]\tvalidation_0-mlogloss:0.00975\tvalidation_1-mlogloss:0.33440\n",
      "Accuracy for structure type classification: 0.9116347569955817\n",
      "F1 macro for structure type classification: 0.7688208407965477\n",
      "F1 micro for structure type classification: 0.9116347569955817\n",
      "F1 weighted for structure type classification: 0.9043412263564486\n",
      "Kappa for structure type classification: 0.869417217439244\n",
      "-------------Iteration 2/10\n",
      "train: 600\n",
      "validation: 678\n",
      "test: 679\n",
      "random_state = 43\n",
      "[0]\tvalidation_0-mlogloss:1.22749\tvalidation_1-mlogloss:1.33627\n",
      "[10]\tvalidation_0-mlogloss:0.11897\tvalidation_1-mlogloss:0.45452\n",
      "[20]\tvalidation_0-mlogloss:0.03100\tvalidation_1-mlogloss:0.38034\n",
      "[30]\tvalidation_0-mlogloss:0.01636\tvalidation_1-mlogloss:0.36532\n",
      "[40]\tvalidation_0-mlogloss:0.01207\tvalidation_1-mlogloss:0.36893\n",
      "Accuracy for structure type classification: 0.9042709867452136\n",
      "F1 macro for structure type classification: 0.7684517002256076\n",
      "F1 micro for structure type classification: 0.9042709867452136\n",
      "F1 weighted for structure type classification: 0.8996408287189616\n",
      "Kappa for structure type classification: 0.8579351590765705\n",
      "-------------Iteration 3/10\n",
      "train: 600\n",
      "validation: 678\n",
      "test: 679\n",
      "random_state = 44\n",
      "[0]\tvalidation_0-mlogloss:1.21708\tvalidation_1-mlogloss:1.33602\n",
      "[10]\tvalidation_0-mlogloss:0.11349\tvalidation_1-mlogloss:0.45932\n",
      "[20]\tvalidation_0-mlogloss:0.02925\tvalidation_1-mlogloss:0.41658\n",
      "[30]\tvalidation_0-mlogloss:0.01551\tvalidation_1-mlogloss:0.41349\n",
      "[35]\tvalidation_0-mlogloss:0.01292\tvalidation_1-mlogloss:0.41254\n",
      "Accuracy for structure type classification: 0.8969072164948454\n",
      "F1 macro for structure type classification: 0.7347874824219666\n",
      "F1 micro for structure type classification: 0.8969072164948454\n",
      "F1 weighted for structure type classification: 0.8888340338830459\n",
      "Kappa for structure type classification: 0.8476656271734009\n",
      "-------------Iteration 4/10\n",
      "train: 600\n",
      "validation: 678\n",
      "test: 679\n",
      "random_state = 45\n",
      "[0]\tvalidation_0-mlogloss:1.22888\tvalidation_1-mlogloss:1.34500\n",
      "[10]\tvalidation_0-mlogloss:0.12565\tvalidation_1-mlogloss:0.46093\n",
      "[20]\tvalidation_0-mlogloss:0.03198\tvalidation_1-mlogloss:0.37052\n",
      "[30]\tvalidation_0-mlogloss:0.01674\tvalidation_1-mlogloss:0.34749\n",
      "[40]\tvalidation_0-mlogloss:0.01217\tvalidation_1-mlogloss:0.33838\n",
      "[50]\tvalidation_0-mlogloss:0.01026\tvalidation_1-mlogloss:0.33498\n",
      "[60]\tvalidation_0-mlogloss:0.00910\tvalidation_1-mlogloss:0.32822\n",
      "[70]\tvalidation_0-mlogloss:0.00831\tvalidation_1-mlogloss:0.32619\n",
      "[80]\tvalidation_0-mlogloss:0.00781\tvalidation_1-mlogloss:0.32278\n",
      "[90]\tvalidation_0-mlogloss:0.00746\tvalidation_1-mlogloss:0.32132\n",
      "[100]\tvalidation_0-mlogloss:0.00715\tvalidation_1-mlogloss:0.32009\n",
      "[110]\tvalidation_0-mlogloss:0.00687\tvalidation_1-mlogloss:0.31964\n",
      "[117]\tvalidation_0-mlogloss:0.00673\tvalidation_1-mlogloss:0.31938\n",
      "Accuracy for structure type classification: 0.8998527245949927\n",
      "F1 macro for structure type classification: 0.7694083910973324\n",
      "F1 micro for structure type classification: 0.8998527245949927\n",
      "F1 weighted for structure type classification: 0.8942517694806624\n",
      "Kappa for structure type classification: 0.8517862244521271\n",
      "-------------Iteration 5/10\n",
      "train: 600\n",
      "validation: 678\n",
      "test: 679\n",
      "random_state = 46\n",
      "[0]\tvalidation_0-mlogloss:1.24664\tvalidation_1-mlogloss:1.33477\n",
      "[10]\tvalidation_0-mlogloss:0.13016\tvalidation_1-mlogloss:0.42009\n",
      "[20]\tvalidation_0-mlogloss:0.03277\tvalidation_1-mlogloss:0.32824\n",
      "[30]\tvalidation_0-mlogloss:0.01731\tvalidation_1-mlogloss:0.31151\n",
      "[40]\tvalidation_0-mlogloss:0.01257\tvalidation_1-mlogloss:0.30739\n",
      "[50]\tvalidation_0-mlogloss:0.01052\tvalidation_1-mlogloss:0.30297\n",
      "[60]\tvalidation_0-mlogloss:0.00936\tvalidation_1-mlogloss:0.30284\n",
      "[70]\tvalidation_0-mlogloss:0.00858\tvalidation_1-mlogloss:0.30196\n",
      "[80]\tvalidation_0-mlogloss:0.00799\tvalidation_1-mlogloss:0.30189\n",
      "[86]\tvalidation_0-mlogloss:0.00773\tvalidation_1-mlogloss:0.30260\n",
      "Accuracy for structure type classification: 0.9072164948453608\n",
      "F1 macro for structure type classification: 0.7909761047972549\n",
      "F1 micro for structure type classification: 0.9072164948453608\n",
      "F1 weighted for structure type classification: 0.9026478308006151\n",
      "Kappa for structure type classification: 0.8633012600302306\n",
      "-------------Iteration 6/10\n",
      "train: 600\n",
      "validation: 678\n",
      "test: 679\n",
      "random_state = 47\n",
      "[0]\tvalidation_0-mlogloss:1.23600\tvalidation_1-mlogloss:1.33979\n",
      "[10]\tvalidation_0-mlogloss:0.12095\tvalidation_1-mlogloss:0.40447\n",
      "[20]\tvalidation_0-mlogloss:0.03092\tvalidation_1-mlogloss:0.32991\n",
      "[30]\tvalidation_0-mlogloss:0.01648\tvalidation_1-mlogloss:0.31636\n",
      "[40]\tvalidation_0-mlogloss:0.01213\tvalidation_1-mlogloss:0.31605\n",
      "[50]\tvalidation_0-mlogloss:0.01030\tvalidation_1-mlogloss:0.31421\n",
      "[60]\tvalidation_0-mlogloss:0.00919\tvalidation_1-mlogloss:0.31212\n",
      "[70]\tvalidation_0-mlogloss:0.00848\tvalidation_1-mlogloss:0.31181\n",
      "[72]\tvalidation_0-mlogloss:0.00834\tvalidation_1-mlogloss:0.31208\n",
      "Accuracy for structure type classification: 0.8924889543446245\n",
      "F1 macro for structure type classification: 0.7510668968591198\n",
      "F1 micro for structure type classification: 0.8924889543446245\n",
      "F1 weighted for structure type classification: 0.8862850407087156\n",
      "Kappa for structure type classification: 0.8403649573915788\n",
      "-------------Iteration 7/10\n",
      "train: 600\n",
      "validation: 678\n",
      "test: 679\n",
      "random_state = 48\n",
      "[0]\tvalidation_0-mlogloss:1.24121\tvalidation_1-mlogloss:1.34164\n",
      "[10]\tvalidation_0-mlogloss:0.12030\tvalidation_1-mlogloss:0.49794\n",
      "[20]\tvalidation_0-mlogloss:0.03073\tvalidation_1-mlogloss:0.43543\n",
      "[30]\tvalidation_0-mlogloss:0.01647\tvalidation_1-mlogloss:0.43257\n",
      "[33]\tvalidation_0-mlogloss:0.01468\tvalidation_1-mlogloss:0.43165\n",
      "Accuracy for structure type classification: 0.8910162002945509\n",
      "F1 macro for structure type classification: 0.7679601253625972\n",
      "F1 micro for structure type classification: 0.8910162002945509\n",
      "F1 weighted for structure type classification: 0.8861761206839103\n",
      "Kappa for structure type classification: 0.8387427027269897\n",
      "-------------Iteration 8/10\n",
      "train: 600\n",
      "validation: 678\n",
      "test: 679\n",
      "random_state = 49\n",
      "[0]\tvalidation_0-mlogloss:1.22982\tvalidation_1-mlogloss:1.33208\n",
      "[10]\tvalidation_0-mlogloss:0.12302\tvalidation_1-mlogloss:0.47090\n",
      "[20]\tvalidation_0-mlogloss:0.03092\tvalidation_1-mlogloss:0.39350\n",
      "[30]\tvalidation_0-mlogloss:0.01624\tvalidation_1-mlogloss:0.38538\n",
      "[40]\tvalidation_0-mlogloss:0.01177\tvalidation_1-mlogloss:0.38717\n",
      "[42]\tvalidation_0-mlogloss:0.01132\tvalidation_1-mlogloss:0.38781\n",
      "Accuracy for structure type classification: 0.8998527245949927\n",
      "F1 macro for structure type classification: 0.7313279055962337\n",
      "F1 micro for structure type classification: 0.8998527245949927\n",
      "F1 weighted for structure type classification: 0.8901037714924022\n",
      "Kappa for structure type classification: 0.8510157722192107\n",
      "-------------Iteration 9/10\n",
      "train: 600\n",
      "validation: 678\n",
      "test: 679\n",
      "random_state = 50\n",
      "[0]\tvalidation_0-mlogloss:1.22552\tvalidation_1-mlogloss:1.35176\n",
      "[10]\tvalidation_0-mlogloss:0.12657\tvalidation_1-mlogloss:0.44109\n",
      "[20]\tvalidation_0-mlogloss:0.03173\tvalidation_1-mlogloss:0.36118\n",
      "[30]\tvalidation_0-mlogloss:0.01705\tvalidation_1-mlogloss:0.34860\n",
      "[40]\tvalidation_0-mlogloss:0.01243\tvalidation_1-mlogloss:0.34683\n",
      "[43]\tvalidation_0-mlogloss:0.01173\tvalidation_1-mlogloss:0.34791\n",
      "Accuracy for structure type classification: 0.9057437407952872\n",
      "F1 macro for structure type classification: 0.7518684098385979\n",
      "F1 micro for structure type classification: 0.9057437407952872\n",
      "F1 weighted for structure type classification: 0.900357196805489\n",
      "Kappa for structure type classification: 0.8616918684774202\n",
      "-------------Iteration 10/10\n",
      "train: 600\n",
      "validation: 678\n",
      "test: 679\n",
      "random_state = 51\n",
      "[0]\tvalidation_0-mlogloss:1.23673\tvalidation_1-mlogloss:1.32135\n",
      "[10]\tvalidation_0-mlogloss:0.11995\tvalidation_1-mlogloss:0.41057\n",
      "[20]\tvalidation_0-mlogloss:0.03017\tvalidation_1-mlogloss:0.33579\n",
      "[30]\tvalidation_0-mlogloss:0.01593\tvalidation_1-mlogloss:0.32514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\tvalidation_0-mlogloss:0.01183\tvalidation_1-mlogloss:0.31846\n",
      "[50]\tvalidation_0-mlogloss:0.01003\tvalidation_1-mlogloss:0.31997\n",
      "[54]\tvalidation_0-mlogloss:0.00951\tvalidation_1-mlogloss:0.32074\n",
      "Accuracy for structure type classification: 0.8748159057437408\n",
      "F1 macro for structure type classification: 0.7379129527726175\n",
      "F1 micro for structure type classification: 0.8748159057437408\n",
      "F1 weighted for structure type classification: 0.869634477682614\n",
      "Kappa for structure type classification: 0.8153179098268856\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for classification\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, le = prepare_dataset_classification(\n",
    "        scattering_patterns, \n",
    "        structure_types, \n",
    "        max_test_data=max_test_data, \n",
    "        train_size=train_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Classification of structure_type\n",
    "    y_test, y_pred, acc, f1_macro, f1_micro, f1_weighted, kappa = train_and_evaluate_classifier(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_val, \n",
    "        y_val, \n",
    "        X_test, \n",
    "        y_test, \n",
    "        le,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    acc_scores.append(acc)\n",
    "    f1macro_scores.append(f1_macro)\n",
    "    f1micro_scores.append(f1_micro)\n",
    "    f1weighted_scores.append(f1_weighted)\n",
    "    kappa_scores.append(kappa)\n",
    "    print(f\"Accuracy for structure type classification: {acc}\")\n",
    "    print(f\"F1 macro for structure type classification: {f1_macro}\")\n",
    "    print(f\"F1 micro for structure type classification: {f1_micro}\")\n",
    "    print(f\"F1 weighted for structure type classification: {f1_weighted}\")\n",
    "    print(f\"Kappa for structure type classification: {kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 600\n",
      "mean accuracy for structure type classification: 0.898379970544919 +/- 0.009966965723527902\n",
      "mean F1 macro for structure type classification: 0.7572580809767875 +/- 0.018102426750650158\n",
      "mean F1 micro for structure type classification: 0.898379970544919 +/- 0.009966965723527902\n",
      "mean F1 weighted for structure type classification: 0.8922272296612865 +/- 0.009893812439235972\n",
      "mean Kappa for structure type classification: 0.8497238698813658 +/- 0.01478152822051094\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean accuracy for structure type classification: {np.mean(acc_scores)} +/- {np.std(acc_scores)}\")\n",
    "print(f\"mean F1 macro for structure type classification: {np.mean(f1macro_scores)} +/- {np.std(f1macro_scores)}\")\n",
    "print(f\"mean F1 micro for structure type classification: {np.mean(f1micro_scores)} +/- {np.std(f1micro_scores)}\")\n",
    "print(f\"mean F1 weighted for structure type classification: {np.mean(f1weighted_scores)} +/- {np.std(f1weighted_scores)}\")\n",
    "print(f\"mean Kappa for structure type classification: {np.mean(kappa_scores)} +/- {np.std(kappa_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>[3, 3, 2, 0, 3, 1, 1, 1, 4, 1, 4, 0, 3, 3, 0, ...</td>\n",
       "      <td>[3, 3, 2, 0, 3, 1, 1, 1, 3, 1, 1, 0, 3, 3, 0, ...</td>\n",
       "      <td>0.911635</td>\n",
       "      <td>0.768821</td>\n",
       "      <td>0.911635</td>\n",
       "      <td>0.904341</td>\n",
       "      <td>0.869417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>[3, 3, 1, 2, 3, 3, 2, 3, 1, 5, 6, 0, 0, 6, 3, ...</td>\n",
       "      <td>[3, 3, 1, 2, 3, 3, 1, 3, 1, 1, 1, 0, 0, 6, 3, ...</td>\n",
       "      <td>0.904271</td>\n",
       "      <td>0.768452</td>\n",
       "      <td>0.904271</td>\n",
       "      <td>0.899641</td>\n",
       "      <td>0.857935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>[6, 3, 0, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 1, 3, ...</td>\n",
       "      <td>[1, 3, 0, 3, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.734787</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.888834</td>\n",
       "      <td>0.847666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0         600  [3, 3, 2, 0, 3, 1, 1, 1, 4, 1, 4, 0, 3, 3, 0, ...   \n",
       "1         600  [3, 3, 1, 2, 3, 3, 2, 3, 1, 5, 6, 0, 0, 6, 3, ...   \n",
       "2         600  [6, 3, 0, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 1, 3, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [3, 3, 2, 0, 3, 1, 1, 1, 3, 1, 1, 0, 3, 3, 0, ...  0.911635  0.768821   \n",
       "1  [3, 3, 1, 2, 3, 3, 1, 3, 1, 1, 1, 0, 0, 6, 3, ...  0.904271  0.768452   \n",
       "2  [1, 3, 0, 3, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, ...  0.896907  0.734787   \n",
       "\n",
       "   f1_micro  f1_weighted     kappa  \n",
       "0  0.911635     0.904341  0.869417  \n",
       "1  0.904271     0.899641  0.857935  \n",
       "2  0.896907     0.888834  0.847666  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_600 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_600.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "iterations = 10\n",
    "max_test_data = 2000\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "acc_scores = []\n",
    "f1macro_scores = []\n",
    "f1micro_scores = []\n",
    "f1weighted_scores = []\n",
    "kappa_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 1000\n",
      "validation: 478\n",
      "test: 479\n",
      "random_state = 42\n",
      "[0]\tvalidation_0-mlogloss:1.22157\tvalidation_1-mlogloss:1.32485\n",
      "[10]\tvalidation_0-mlogloss:0.12405\tvalidation_1-mlogloss:0.35202\n",
      "[20]\tvalidation_0-mlogloss:0.02913\tvalidation_1-mlogloss:0.25067\n",
      "[30]\tvalidation_0-mlogloss:0.01370\tvalidation_1-mlogloss:0.23164\n",
      "[40]\tvalidation_0-mlogloss:0.00929\tvalidation_1-mlogloss:0.22399\n",
      "[50]\tvalidation_0-mlogloss:0.00751\tvalidation_1-mlogloss:0.22201\n",
      "[60]\tvalidation_0-mlogloss:0.00653\tvalidation_1-mlogloss:0.21924\n",
      "[70]\tvalidation_0-mlogloss:0.00589\tvalidation_1-mlogloss:0.21737\n",
      "[80]\tvalidation_0-mlogloss:0.00544\tvalidation_1-mlogloss:0.21545\n",
      "[90]\tvalidation_0-mlogloss:0.00508\tvalidation_1-mlogloss:0.21565\n",
      "[98]\tvalidation_0-mlogloss:0.00489\tvalidation_1-mlogloss:0.21620\n",
      "Accuracy for structure type classification: 0.9331941544885177\n",
      "F1 macro for structure type classification: 0.8104362195636013\n",
      "F1 micro for structure type classification: 0.9331941544885177\n",
      "F1 weighted for structure type classification: 0.9298801425338127\n",
      "Kappa for structure type classification: 0.9016647955092221\n",
      "-------------Iteration 2/10\n",
      "train: 1000\n",
      "validation: 478\n",
      "test: 479\n",
      "random_state = 43\n",
      "[0]\tvalidation_0-mlogloss:1.21142\tvalidation_1-mlogloss:1.29872\n",
      "[10]\tvalidation_0-mlogloss:0.12583\tvalidation_1-mlogloss:0.33778\n",
      "[20]\tvalidation_0-mlogloss:0.03022\tvalidation_1-mlogloss:0.24770\n",
      "[30]\tvalidation_0-mlogloss:0.01384\tvalidation_1-mlogloss:0.22727\n",
      "[40]\tvalidation_0-mlogloss:0.00934\tvalidation_1-mlogloss:0.21988\n",
      "[50]\tvalidation_0-mlogloss:0.00747\tvalidation_1-mlogloss:0.21575\n",
      "[60]\tvalidation_0-mlogloss:0.00648\tvalidation_1-mlogloss:0.21598\n",
      "[70]\tvalidation_0-mlogloss:0.00584\tvalidation_1-mlogloss:0.21507\n",
      "[80]\tvalidation_0-mlogloss:0.00541\tvalidation_1-mlogloss:0.21393\n",
      "[85]\tvalidation_0-mlogloss:0.00525\tvalidation_1-mlogloss:0.21400\n",
      "Accuracy for structure type classification: 0.9081419624217119\n",
      "F1 macro for structure type classification: 0.7729829185266378\n",
      "F1 micro for structure type classification: 0.9081419624217119\n",
      "F1 weighted for structure type classification: 0.9026233841481924\n",
      "Kappa for structure type classification: 0.8648679840478053\n",
      "-------------Iteration 3/10\n",
      "train: 1000\n",
      "validation: 478\n",
      "test: 479\n",
      "random_state = 44\n",
      "[0]\tvalidation_0-mlogloss:1.20747\tvalidation_1-mlogloss:1.31581\n",
      "[10]\tvalidation_0-mlogloss:0.12404\tvalidation_1-mlogloss:0.41205\n",
      "[20]\tvalidation_0-mlogloss:0.02785\tvalidation_1-mlogloss:0.31944\n",
      "[30]\tvalidation_0-mlogloss:0.01305\tvalidation_1-mlogloss:0.30566\n",
      "[40]\tvalidation_0-mlogloss:0.00903\tvalidation_1-mlogloss:0.30738\n",
      "[46]\tvalidation_0-mlogloss:0.00790\tvalidation_1-mlogloss:0.30718\n",
      "Accuracy for structure type classification: 0.9164926931106472\n",
      "F1 macro for structure type classification: 0.8039296296876592\n",
      "F1 micro for structure type classification: 0.9164926931106472\n",
      "F1 weighted for structure type classification: 0.9112629372898446\n",
      "Kappa for structure type classification: 0.8766798826013078\n",
      "-------------Iteration 4/10\n",
      "train: 1000\n",
      "validation: 478\n",
      "test: 479\n",
      "random_state = 45\n",
      "[0]\tvalidation_0-mlogloss:1.20675\tvalidation_1-mlogloss:1.31694\n",
      "[10]\tvalidation_0-mlogloss:0.12373\tvalidation_1-mlogloss:0.37292\n",
      "[20]\tvalidation_0-mlogloss:0.02867\tvalidation_1-mlogloss:0.28416\n",
      "[30]\tvalidation_0-mlogloss:0.01377\tvalidation_1-mlogloss:0.26763\n",
      "[40]\tvalidation_0-mlogloss:0.00949\tvalidation_1-mlogloss:0.26265\n",
      "[50]\tvalidation_0-mlogloss:0.00763\tvalidation_1-mlogloss:0.26173\n",
      "[60]\tvalidation_0-mlogloss:0.00660\tvalidation_1-mlogloss:0.25789\n",
      "[70]\tvalidation_0-mlogloss:0.00596\tvalidation_1-mlogloss:0.25800\n",
      "[76]\tvalidation_0-mlogloss:0.00567\tvalidation_1-mlogloss:0.25728\n",
      "Accuracy for structure type classification: 0.9331941544885177\n",
      "F1 macro for structure type classification: 0.8059318538134075\n",
      "F1 micro for structure type classification: 0.9331941544885177\n",
      "F1 weighted for structure type classification: 0.9305617844018068\n",
      "Kappa for structure type classification: 0.9016155638426927\n",
      "-------------Iteration 5/10\n",
      "train: 1000\n",
      "validation: 478\n",
      "test: 479\n",
      "random_state = 46\n",
      "[0]\tvalidation_0-mlogloss:1.22677\tvalidation_1-mlogloss:1.30146\n",
      "[10]\tvalidation_0-mlogloss:0.13555\tvalidation_1-mlogloss:0.37722\n",
      "[20]\tvalidation_0-mlogloss:0.03076\tvalidation_1-mlogloss:0.27087\n",
      "[30]\tvalidation_0-mlogloss:0.01419\tvalidation_1-mlogloss:0.24029\n",
      "[40]\tvalidation_0-mlogloss:0.00972\tvalidation_1-mlogloss:0.23407\n",
      "[50]\tvalidation_0-mlogloss:0.00776\tvalidation_1-mlogloss:0.22985\n",
      "[60]\tvalidation_0-mlogloss:0.00670\tvalidation_1-mlogloss:0.22785\n",
      "[70]\tvalidation_0-mlogloss:0.00607\tvalidation_1-mlogloss:0.22773\n",
      "[78]\tvalidation_0-mlogloss:0.00571\tvalidation_1-mlogloss:0.22823\n",
      "Accuracy for structure type classification: 0.9248434237995825\n",
      "F1 macro for structure type classification: 0.8139826656830433\n",
      "F1 micro for structure type classification: 0.9248434237995825\n",
      "F1 weighted for structure type classification: 0.9214731937445179\n",
      "Kappa for structure type classification: 0.8890404612375167\n",
      "-------------Iteration 6/10\n",
      "train: 1000\n",
      "validation: 478\n",
      "test: 479\n",
      "random_state = 47\n",
      "[0]\tvalidation_0-mlogloss:1.22614\tvalidation_1-mlogloss:1.27459\n",
      "[10]\tvalidation_0-mlogloss:0.13492\tvalidation_1-mlogloss:0.35910\n",
      "[20]\tvalidation_0-mlogloss:0.03039\tvalidation_1-mlogloss:0.24900\n",
      "[30]\tvalidation_0-mlogloss:0.01431\tvalidation_1-mlogloss:0.22573\n",
      "[40]\tvalidation_0-mlogloss:0.00980\tvalidation_1-mlogloss:0.21487\n",
      "[50]\tvalidation_0-mlogloss:0.00779\tvalidation_1-mlogloss:0.20747\n",
      "[60]\tvalidation_0-mlogloss:0.00673\tvalidation_1-mlogloss:0.20265\n",
      "[70]\tvalidation_0-mlogloss:0.00608\tvalidation_1-mlogloss:0.20120\n",
      "[80]\tvalidation_0-mlogloss:0.00559\tvalidation_1-mlogloss:0.19960\n",
      "[90]\tvalidation_0-mlogloss:0.00523\tvalidation_1-mlogloss:0.19822\n",
      "[100]\tvalidation_0-mlogloss:0.00495\tvalidation_1-mlogloss:0.19674\n",
      "[106]\tvalidation_0-mlogloss:0.00483\tvalidation_1-mlogloss:0.19616\n",
      "Accuracy for structure type classification: 0.9290187891440501\n",
      "F1 macro for structure type classification: 0.7945558608552535\n",
      "F1 micro for structure type classification: 0.9290187891440501\n",
      "F1 weighted for structure type classification: 0.9264809204639992\n",
      "Kappa for structure type classification: 0.8953173710429053\n",
      "-------------Iteration 7/10\n",
      "train: 1000\n",
      "validation: 478\n",
      "test: 479\n",
      "random_state = 48\n",
      "[0]\tvalidation_0-mlogloss:1.22826\tvalidation_1-mlogloss:1.29552\n",
      "[10]\tvalidation_0-mlogloss:0.12807\tvalidation_1-mlogloss:0.36834\n",
      "[20]\tvalidation_0-mlogloss:0.02858\tvalidation_1-mlogloss:0.26131\n",
      "[30]\tvalidation_0-mlogloss:0.01381\tvalidation_1-mlogloss:0.24255\n",
      "[40]\tvalidation_0-mlogloss:0.00944\tvalidation_1-mlogloss:0.23561\n",
      "[50]\tvalidation_0-mlogloss:0.00760\tvalidation_1-mlogloss:0.23313\n",
      "[60]\tvalidation_0-mlogloss:0.00661\tvalidation_1-mlogloss:0.23139\n",
      "[70]\tvalidation_0-mlogloss:0.00593\tvalidation_1-mlogloss:0.23073\n",
      "[80]\tvalidation_0-mlogloss:0.00547\tvalidation_1-mlogloss:0.22780\n",
      "[90]\tvalidation_0-mlogloss:0.00514\tvalidation_1-mlogloss:0.22657\n",
      "[100]\tvalidation_0-mlogloss:0.00488\tvalidation_1-mlogloss:0.22550\n",
      "[110]\tvalidation_0-mlogloss:0.00470\tvalidation_1-mlogloss:0.22370\n",
      "[120]\tvalidation_0-mlogloss:0.00456\tvalidation_1-mlogloss:0.22289\n",
      "[130]\tvalidation_0-mlogloss:0.00444\tvalidation_1-mlogloss:0.22208\n",
      "[138]\tvalidation_0-mlogloss:0.00435\tvalidation_1-mlogloss:0.22228\n",
      "Accuracy for structure type classification: 0.9311064718162839\n",
      "F1 macro for structure type classification: 0.8379754701458436\n",
      "F1 micro for structure type classification: 0.9311064718162839\n",
      "F1 weighted for structure type classification: 0.9306796190264139\n",
      "Kappa for structure type classification: 0.8991630411207083\n",
      "-------------Iteration 8/10\n",
      "train: 1000\n",
      "validation: 478\n",
      "test: 479\n",
      "random_state = 49\n",
      "[0]\tvalidation_0-mlogloss:1.24017\tvalidation_1-mlogloss:1.31599\n",
      "[10]\tvalidation_0-mlogloss:0.14604\tvalidation_1-mlogloss:0.33213\n",
      "[20]\tvalidation_0-mlogloss:0.03222\tvalidation_1-mlogloss:0.23451\n",
      "[30]\tvalidation_0-mlogloss:0.01464\tvalidation_1-mlogloss:0.21494\n",
      "[40]\tvalidation_0-mlogloss:0.00988\tvalidation_1-mlogloss:0.20599\n",
      "[50]\tvalidation_0-mlogloss:0.00780\tvalidation_1-mlogloss:0.20223\n",
      "[60]\tvalidation_0-mlogloss:0.00671\tvalidation_1-mlogloss:0.20049\n",
      "[70]\tvalidation_0-mlogloss:0.00607\tvalidation_1-mlogloss:0.20036\n",
      "[75]\tvalidation_0-mlogloss:0.00582\tvalidation_1-mlogloss:0.19988\n",
      "Accuracy for structure type classification: 0.9164926931106472\n",
      "F1 macro for structure type classification: 0.8062044827753695\n",
      "F1 micro for structure type classification: 0.9164926931106472\n",
      "F1 weighted for structure type classification: 0.9128827501620638\n",
      "Kappa for structure type classification: 0.8765408233618784\n",
      "-------------Iteration 9/10\n",
      "train: 1000\n",
      "validation: 478\n",
      "test: 479\n",
      "random_state = 50\n",
      "[0]\tvalidation_0-mlogloss:1.21303\tvalidation_1-mlogloss:1.29751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-mlogloss:0.12726\tvalidation_1-mlogloss:0.32699\n",
      "[20]\tvalidation_0-mlogloss:0.02994\tvalidation_1-mlogloss:0.22988\n",
      "[30]\tvalidation_0-mlogloss:0.01401\tvalidation_1-mlogloss:0.20941\n",
      "[40]\tvalidation_0-mlogloss:0.00961\tvalidation_1-mlogloss:0.20073\n",
      "[50]\tvalidation_0-mlogloss:0.00775\tvalidation_1-mlogloss:0.19686\n",
      "[60]\tvalidation_0-mlogloss:0.00673\tvalidation_1-mlogloss:0.19777\n",
      "Accuracy for structure type classification: 0.9248434237995825\n",
      "F1 macro for structure type classification: 0.7985634535043558\n",
      "F1 micro for structure type classification: 0.9248434237995825\n",
      "F1 weighted for structure type classification: 0.9189491923488776\n",
      "Kappa for structure type classification: 0.8889897448772668\n",
      "-------------Iteration 10/10\n",
      "train: 1000\n",
      "validation: 478\n",
      "test: 479\n",
      "random_state = 51\n",
      "[0]\tvalidation_0-mlogloss:1.22175\tvalidation_1-mlogloss:1.29993\n",
      "[10]\tvalidation_0-mlogloss:0.13185\tvalidation_1-mlogloss:0.35974\n",
      "[20]\tvalidation_0-mlogloss:0.03028\tvalidation_1-mlogloss:0.27519\n",
      "[30]\tvalidation_0-mlogloss:0.01417\tvalidation_1-mlogloss:0.26114\n",
      "[40]\tvalidation_0-mlogloss:0.00976\tvalidation_1-mlogloss:0.25842\n",
      "[45]\tvalidation_0-mlogloss:0.00859\tvalidation_1-mlogloss:0.26065\n",
      "Accuracy for structure type classification: 0.9269311064718163\n",
      "F1 macro for structure type classification: 0.8277485641973364\n",
      "F1 micro for structure type classification: 0.9269311064718163\n",
      "F1 weighted for structure type classification: 0.9227450580346386\n",
      "Kappa for structure type classification: 0.8920928136967785\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for classification\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, le = prepare_dataset_classification(\n",
    "        scattering_patterns, \n",
    "        structure_types, \n",
    "        max_test_data=max_test_data, \n",
    "        train_size=train_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Classification of structure_type\n",
    "    y_test, y_pred, acc, f1_macro, f1_micro, f1_weighted, kappa = train_and_evaluate_classifier(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_val, \n",
    "        y_val, \n",
    "        X_test, \n",
    "        y_test, \n",
    "        le,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    acc_scores.append(acc)\n",
    "    f1macro_scores.append(f1_macro)\n",
    "    f1micro_scores.append(f1_micro)\n",
    "    f1weighted_scores.append(f1_weighted)\n",
    "    kappa_scores.append(kappa)\n",
    "    print(f\"Accuracy for structure type classification: {acc}\")\n",
    "    print(f\"F1 macro for structure type classification: {f1_macro}\")\n",
    "    print(f\"F1 micro for structure type classification: {f1_micro}\")\n",
    "    print(f\"F1 weighted for structure type classification: {f1_weighted}\")\n",
    "    print(f\"Kappa for structure type classification: {kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 1000\n",
      "mean accuracy for structure type classification: 0.9244258872651356 +/- 0.007855903015543547\n",
      "mean F1 macro for structure type classification: 0.8072311118752508 +/- 0.016865374204346927\n",
      "mean F1 micro for structure type classification: 0.9244258872651356 +/- 0.007855903015543547\n",
      "mean F1 weighted for structure type classification: 0.9207538982154168 +/- 0.008940299784217547\n",
      "mean Kappa for structure type classification: 0.8885972481338081 +/- 0.011662168732246677\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean accuracy for structure type classification: {np.mean(acc_scores)} +/- {np.std(acc_scores)}\")\n",
    "print(f\"mean F1 macro for structure type classification: {np.mean(f1macro_scores)} +/- {np.std(f1macro_scores)}\")\n",
    "print(f\"mean F1 micro for structure type classification: {np.mean(f1micro_scores)} +/- {np.std(f1micro_scores)}\")\n",
    "print(f\"mean F1 weighted for structure type classification: {np.mean(f1weighted_scores)} +/- {np.std(f1weighted_scores)}\")\n",
    "print(f\"mean Kappa for structure type classification: {np.mean(kappa_scores)} +/- {np.std(kappa_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>[5, 1, 6, 0, 3, 3, 6, 3, 0, 3, 3, 4, 3, 1, 6, ...</td>\n",
       "      <td>[5, 1, 6, 0, 3, 3, 6, 3, 0, 3, 3, 6, 3, 1, 6, ...</td>\n",
       "      <td>0.933194</td>\n",
       "      <td>0.810436</td>\n",
       "      <td>0.933194</td>\n",
       "      <td>0.929880</td>\n",
       "      <td>0.901665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>[3, 3, 3, 3, 1, 3, 1, 6, 3, 3, 3, 3, 1, 3, 6, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 1, 6, 3, 3, 3, 3, 1, 3, 6, ...</td>\n",
       "      <td>0.908142</td>\n",
       "      <td>0.772983</td>\n",
       "      <td>0.908142</td>\n",
       "      <td>0.902623</td>\n",
       "      <td>0.864868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>[3, 3, 3, 3, 6, 3, 3, 1, 0, 3, 3, 3, 3, 3, 1, ...</td>\n",
       "      <td>[3, 3, 3, 3, 6, 3, 3, 1, 0, 3, 3, 3, 3, 3, 1, ...</td>\n",
       "      <td>0.916493</td>\n",
       "      <td>0.803930</td>\n",
       "      <td>0.916493</td>\n",
       "      <td>0.911263</td>\n",
       "      <td>0.876680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0        1000  [5, 1, 6, 0, 3, 3, 6, 3, 0, 3, 3, 4, 3, 1, 6, ...   \n",
       "1        1000  [3, 3, 3, 3, 1, 3, 1, 6, 3, 3, 3, 3, 1, 3, 6, ...   \n",
       "2        1000  [3, 3, 3, 3, 6, 3, 3, 1, 0, 3, 3, 3, 3, 3, 1, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [5, 1, 6, 0, 3, 3, 6, 3, 0, 3, 3, 6, 3, 1, 6, ...  0.933194  0.810436   \n",
       "1  [3, 3, 3, 3, 3, 3, 1, 6, 3, 3, 3, 3, 1, 3, 6, ...  0.908142  0.772983   \n",
       "2  [3, 3, 3, 3, 6, 3, 3, 1, 0, 3, 3, 3, 3, 3, 1, ...  0.916493  0.803930   \n",
       "\n",
       "   f1_micro  f1_weighted     kappa  \n",
       "0  0.933194     0.929880  0.901665  \n",
       "1  0.908142     0.902623  0.864868  \n",
       "2  0.916493     0.911263  0.876680  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_1000 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_1000.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1400\n",
    "iterations = 10\n",
    "max_test_data = 2000\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "acc_scores = []\n",
    "f1macro_scores = []\n",
    "f1micro_scores = []\n",
    "f1weighted_scores = []\n",
    "kappa_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 1400\n",
      "validation: 278\n",
      "test: 279\n",
      "random_state = 42\n",
      "[0]\tvalidation_0-mlogloss:1.22433\tvalidation_1-mlogloss:1.28098\n",
      "[10]\tvalidation_0-mlogloss:0.13679\tvalidation_1-mlogloss:0.31628\n",
      "[20]\tvalidation_0-mlogloss:0.02984\tvalidation_1-mlogloss:0.22189\n",
      "[30]\tvalidation_0-mlogloss:0.01283\tvalidation_1-mlogloss:0.19522\n",
      "[40]\tvalidation_0-mlogloss:0.00822\tvalidation_1-mlogloss:0.18721\n",
      "[50]\tvalidation_0-mlogloss:0.00636\tvalidation_1-mlogloss:0.18313\n",
      "[60]\tvalidation_0-mlogloss:0.00542\tvalidation_1-mlogloss:0.17996\n",
      "[70]\tvalidation_0-mlogloss:0.00481\tvalidation_1-mlogloss:0.17745\n",
      "[80]\tvalidation_0-mlogloss:0.00439\tvalidation_1-mlogloss:0.17576\n",
      "[90]\tvalidation_0-mlogloss:0.00408\tvalidation_1-mlogloss:0.17487\n",
      "[100]\tvalidation_0-mlogloss:0.00384\tvalidation_1-mlogloss:0.17528\n",
      "[103]\tvalidation_0-mlogloss:0.00378\tvalidation_1-mlogloss:0.17520\n",
      "Accuracy for structure type classification: 0.942652329749104\n",
      "F1 macro for structure type classification: 0.8026542851529985\n",
      "F1 micro for structure type classification: 0.942652329749104\n",
      "F1 weighted for structure type classification: 0.9407850401890838\n",
      "Kappa for structure type classification: 0.9153214333137318\n",
      "-------------Iteration 2/10\n",
      "train: 1400\n",
      "validation: 278\n",
      "test: 279\n",
      "random_state = 43\n",
      "[0]\tvalidation_0-mlogloss:1.21541\tvalidation_1-mlogloss:1.26323\n",
      "[10]\tvalidation_0-mlogloss:0.13101\tvalidation_1-mlogloss:0.30211\n",
      "[20]\tvalidation_0-mlogloss:0.03004\tvalidation_1-mlogloss:0.22092\n",
      "[30]\tvalidation_0-mlogloss:0.01284\tvalidation_1-mlogloss:0.20281\n",
      "[40]\tvalidation_0-mlogloss:0.00829\tvalidation_1-mlogloss:0.19511\n",
      "[50]\tvalidation_0-mlogloss:0.00641\tvalidation_1-mlogloss:0.19295\n",
      "[60]\tvalidation_0-mlogloss:0.00545\tvalidation_1-mlogloss:0.18871\n",
      "[69]\tvalidation_0-mlogloss:0.00488\tvalidation_1-mlogloss:0.19095\n",
      "Accuracy for structure type classification: 0.953405017921147\n",
      "F1 macro for structure type classification: 0.872395865494881\n",
      "F1 micro for structure type classification: 0.953405017921147\n",
      "F1 weighted for structure type classification: 0.9510747728206821\n",
      "Kappa for structure type classification: 0.9311699402220325\n",
      "-------------Iteration 3/10\n",
      "train: 1400\n",
      "validation: 278\n",
      "test: 279\n",
      "random_state = 44\n",
      "[0]\tvalidation_0-mlogloss:1.20291\tvalidation_1-mlogloss:1.28326\n",
      "[10]\tvalidation_0-mlogloss:0.12475\tvalidation_1-mlogloss:0.37943\n",
      "[20]\tvalidation_0-mlogloss:0.02613\tvalidation_1-mlogloss:0.29899\n",
      "[30]\tvalidation_0-mlogloss:0.01147\tvalidation_1-mlogloss:0.29735\n",
      "[33]\tvalidation_0-mlogloss:0.00985\tvalidation_1-mlogloss:0.29639\n",
      "Accuracy for structure type classification: 0.942652329749104\n",
      "F1 macro for structure type classification: 0.8567511687409839\n",
      "F1 micro for structure type classification: 0.942652329749104\n",
      "F1 weighted for structure type classification: 0.9388648671576381\n",
      "Kappa for structure type classification: 0.9154849580643329\n",
      "-------------Iteration 4/10\n",
      "train: 1400\n",
      "validation: 278\n",
      "test: 279\n",
      "random_state = 45\n",
      "[0]\tvalidation_0-mlogloss:1.21090\tvalidation_1-mlogloss:1.28246\n",
      "[10]\tvalidation_0-mlogloss:0.12619\tvalidation_1-mlogloss:0.33397\n",
      "[20]\tvalidation_0-mlogloss:0.02692\tvalidation_1-mlogloss:0.22817\n",
      "[30]\tvalidation_0-mlogloss:0.01193\tvalidation_1-mlogloss:0.20889\n",
      "[40]\tvalidation_0-mlogloss:0.00789\tvalidation_1-mlogloss:0.20603\n",
      "[50]\tvalidation_0-mlogloss:0.00611\tvalidation_1-mlogloss:0.20629\n",
      "[60]\tvalidation_0-mlogloss:0.00520\tvalidation_1-mlogloss:0.20470\n",
      "[65]\tvalidation_0-mlogloss:0.00489\tvalidation_1-mlogloss:0.20453\n",
      "Accuracy for structure type classification: 0.931899641577061\n",
      "F1 macro for structure type classification: 0.8176078136029185\n",
      "F1 micro for structure type classification: 0.931899641577061\n",
      "F1 weighted for structure type classification: 0.9287016065978401\n",
      "Kappa for structure type classification: 0.8994480168440221\n",
      "-------------Iteration 5/10\n",
      "train: 1400\n",
      "validation: 278\n",
      "test: 279\n",
      "random_state = 46\n",
      "[0]\tvalidation_0-mlogloss:1.22333\tvalidation_1-mlogloss:1.27719\n",
      "[10]\tvalidation_0-mlogloss:0.14180\tvalidation_1-mlogloss:0.28039\n",
      "[20]\tvalidation_0-mlogloss:0.02924\tvalidation_1-mlogloss:0.16545\n",
      "[30]\tvalidation_0-mlogloss:0.01272\tvalidation_1-mlogloss:0.14000\n",
      "[40]\tvalidation_0-mlogloss:0.00833\tvalidation_1-mlogloss:0.13501\n",
      "[50]\tvalidation_0-mlogloss:0.00641\tvalidation_1-mlogloss:0.13183\n",
      "[60]\tvalidation_0-mlogloss:0.00543\tvalidation_1-mlogloss:0.13068\n",
      "[70]\tvalidation_0-mlogloss:0.00485\tvalidation_1-mlogloss:0.12855\n",
      "[80]\tvalidation_0-mlogloss:0.00443\tvalidation_1-mlogloss:0.12863\n",
      "[81]\tvalidation_0-mlogloss:0.00440\tvalidation_1-mlogloss:0.12906\n",
      "Accuracy for structure type classification: 0.9498207885304659\n",
      "F1 macro for structure type classification: 0.8281951667120585\n",
      "F1 micro for structure type classification: 0.9498207885304659\n",
      "F1 weighted for structure type classification: 0.9476427319265701\n",
      "Kappa for structure type classification: 0.9256707897240724\n",
      "-------------Iteration 6/10\n",
      "train: 1400\n",
      "validation: 278\n",
      "test: 279\n",
      "random_state = 47\n",
      "[0]\tvalidation_0-mlogloss:1.23238\tvalidation_1-mlogloss:1.26932\n",
      "[10]\tvalidation_0-mlogloss:0.13243\tvalidation_1-mlogloss:0.27271\n",
      "[20]\tvalidation_0-mlogloss:0.02951\tvalidation_1-mlogloss:0.15936\n",
      "[30]\tvalidation_0-mlogloss:0.01258\tvalidation_1-mlogloss:0.13353\n",
      "[40]\tvalidation_0-mlogloss:0.00817\tvalidation_1-mlogloss:0.12488\n",
      "[50]\tvalidation_0-mlogloss:0.00635\tvalidation_1-mlogloss:0.11978\n",
      "[60]\tvalidation_0-mlogloss:0.00542\tvalidation_1-mlogloss:0.11769\n",
      "[70]\tvalidation_0-mlogloss:0.00480\tvalidation_1-mlogloss:0.11486\n",
      "[80]\tvalidation_0-mlogloss:0.00441\tvalidation_1-mlogloss:0.11310\n",
      "[90]\tvalidation_0-mlogloss:0.00412\tvalidation_1-mlogloss:0.11306\n",
      "[100]\tvalidation_0-mlogloss:0.00388\tvalidation_1-mlogloss:0.11253\n",
      "[110]\tvalidation_0-mlogloss:0.00369\tvalidation_1-mlogloss:0.11196\n",
      "[120]\tvalidation_0-mlogloss:0.00354\tvalidation_1-mlogloss:0.11106\n",
      "[130]\tvalidation_0-mlogloss:0.00343\tvalidation_1-mlogloss:0.11064\n",
      "[140]\tvalidation_0-mlogloss:0.00334\tvalidation_1-mlogloss:0.11038\n",
      "[147]\tvalidation_0-mlogloss:0.00329\tvalidation_1-mlogloss:0.11051\n",
      "Accuracy for structure type classification: 0.9354838709677419\n",
      "F1 macro for structure type classification: 0.8414721071170858\n",
      "F1 micro for structure type classification: 0.9354838709677419\n",
      "F1 weighted for structure type classification: 0.9384873963830851\n",
      "Kappa for structure type classification: 0.9052363430512312\n",
      "-------------Iteration 7/10\n",
      "train: 1400\n",
      "validation: 278\n",
      "test: 279\n",
      "random_state = 48\n",
      "[0]\tvalidation_0-mlogloss:1.21869\tvalidation_1-mlogloss:1.26852\n",
      "[10]\tvalidation_0-mlogloss:0.13880\tvalidation_1-mlogloss:0.29326\n",
      "[20]\tvalidation_0-mlogloss:0.02986\tvalidation_1-mlogloss:0.18006\n",
      "[30]\tvalidation_0-mlogloss:0.01308\tvalidation_1-mlogloss:0.15955\n",
      "[40]\tvalidation_0-mlogloss:0.00842\tvalidation_1-mlogloss:0.15424\n",
      "[50]\tvalidation_0-mlogloss:0.00650\tvalidation_1-mlogloss:0.14711\n",
      "[60]\tvalidation_0-mlogloss:0.00549\tvalidation_1-mlogloss:0.14417\n",
      "[70]\tvalidation_0-mlogloss:0.00484\tvalidation_1-mlogloss:0.14151\n",
      "[80]\tvalidation_0-mlogloss:0.00443\tvalidation_1-mlogloss:0.14217\n",
      "Accuracy for structure type classification: 0.9713261648745519\n",
      "F1 macro for structure type classification: 0.9292403628117913\n",
      "F1 micro for structure type classification: 0.9713261648745519\n",
      "F1 weighted for structure type classification: 0.9705427547363032\n",
      "Kappa for structure type classification: 0.9576213260423787\n",
      "-------------Iteration 8/10\n",
      "train: 1400\n",
      "validation: 278\n",
      "test: 279\n",
      "random_state = 49\n",
      "[0]\tvalidation_0-mlogloss:1.22135\tvalidation_1-mlogloss:1.28208\n",
      "[10]\tvalidation_0-mlogloss:0.14178\tvalidation_1-mlogloss:0.28120\n",
      "[20]\tvalidation_0-mlogloss:0.03093\tvalidation_1-mlogloss:0.17768\n",
      "[30]\tvalidation_0-mlogloss:0.01319\tvalidation_1-mlogloss:0.15333\n",
      "[40]\tvalidation_0-mlogloss:0.00849\tvalidation_1-mlogloss:0.14208\n",
      "[50]\tvalidation_0-mlogloss:0.00646\tvalidation_1-mlogloss:0.13633\n",
      "[60]\tvalidation_0-mlogloss:0.00546\tvalidation_1-mlogloss:0.13467\n",
      "[70]\tvalidation_0-mlogloss:0.00483\tvalidation_1-mlogloss:0.13432\n",
      "[80]\tvalidation_0-mlogloss:0.00442\tvalidation_1-mlogloss:0.13410\n",
      "[90]\tvalidation_0-mlogloss:0.00412\tvalidation_1-mlogloss:0.13379\n",
      "[92]\tvalidation_0-mlogloss:0.00406\tvalidation_1-mlogloss:0.13371\n",
      "Accuracy for structure type classification: 0.9498207885304659\n",
      "F1 macro for structure type classification: 0.8764741368024086\n",
      "F1 micro for structure type classification: 0.9498207885304659\n",
      "F1 weighted for structure type classification: 0.9477558643909907\n",
      "Kappa for structure type classification: 0.9254352474037875\n",
      "-------------Iteration 9/10\n",
      "train: 1400\n",
      "validation: 278\n",
      "test: 279\n",
      "random_state = 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.21516\tvalidation_1-mlogloss:1.27528\n",
      "[10]\tvalidation_0-mlogloss:0.12916\tvalidation_1-mlogloss:0.30773\n",
      "[20]\tvalidation_0-mlogloss:0.02754\tvalidation_1-mlogloss:0.19029\n",
      "[30]\tvalidation_0-mlogloss:0.01220\tvalidation_1-mlogloss:0.16768\n",
      "[40]\tvalidation_0-mlogloss:0.00801\tvalidation_1-mlogloss:0.15730\n",
      "[50]\tvalidation_0-mlogloss:0.00631\tvalidation_1-mlogloss:0.15484\n",
      "[60]\tvalidation_0-mlogloss:0.00537\tvalidation_1-mlogloss:0.15445\n",
      "[70]\tvalidation_0-mlogloss:0.00478\tvalidation_1-mlogloss:0.15095\n",
      "[80]\tvalidation_0-mlogloss:0.00438\tvalidation_1-mlogloss:0.14908\n",
      "[88]\tvalidation_0-mlogloss:0.00413\tvalidation_1-mlogloss:0.14971\n",
      "Accuracy for structure type classification: 0.9354838709677419\n",
      "F1 macro for structure type classification: 0.8728100444347584\n",
      "F1 micro for structure type classification: 0.9354838709677419\n",
      "F1 weighted for structure type classification: 0.9335512607987858\n",
      "Kappa for structure type classification: 0.9048593350383631\n",
      "-------------Iteration 10/10\n",
      "train: 1400\n",
      "validation: 278\n",
      "test: 279\n",
      "random_state = 51\n",
      "[0]\tvalidation_0-mlogloss:1.21755\tvalidation_1-mlogloss:1.28748\n",
      "[10]\tvalidation_0-mlogloss:0.13444\tvalidation_1-mlogloss:0.30577\n",
      "[20]\tvalidation_0-mlogloss:0.02997\tvalidation_1-mlogloss:0.18534\n",
      "[30]\tvalidation_0-mlogloss:0.01261\tvalidation_1-mlogloss:0.15357\n",
      "[40]\tvalidation_0-mlogloss:0.00817\tvalidation_1-mlogloss:0.14338\n",
      "[50]\tvalidation_0-mlogloss:0.00635\tvalidation_1-mlogloss:0.13834\n",
      "[60]\tvalidation_0-mlogloss:0.00540\tvalidation_1-mlogloss:0.13689\n",
      "[70]\tvalidation_0-mlogloss:0.00479\tvalidation_1-mlogloss:0.13380\n",
      "[80]\tvalidation_0-mlogloss:0.00440\tvalidation_1-mlogloss:0.13228\n",
      "[90]\tvalidation_0-mlogloss:0.00410\tvalidation_1-mlogloss:0.13303\n",
      "[91]\tvalidation_0-mlogloss:0.00408\tvalidation_1-mlogloss:0.13335\n",
      "Accuracy for structure type classification: 0.956989247311828\n",
      "F1 macro for structure type classification: 0.8877525188403255\n",
      "F1 micro for structure type classification: 0.956989247311828\n",
      "F1 weighted for structure type classification: 0.9565300165938904\n",
      "Kappa for structure type classification: 0.9361714296608392\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for classification\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, le = prepare_dataset_classification(\n",
    "        scattering_patterns, \n",
    "        structure_types, \n",
    "        max_test_data=max_test_data, \n",
    "        train_size=train_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Classification of structure_type\n",
    "    y_test, y_pred, acc, f1_macro, f1_micro, f1_weighted, kappa = train_and_evaluate_classifier(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_val, \n",
    "        y_val, \n",
    "        X_test, \n",
    "        y_test, \n",
    "        le,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    acc_scores.append(acc)\n",
    "    f1macro_scores.append(f1_macro)\n",
    "    f1micro_scores.append(f1_micro)\n",
    "    f1weighted_scores.append(f1_weighted)\n",
    "    kappa_scores.append(kappa)\n",
    "    print(f\"Accuracy for structure type classification: {acc}\")\n",
    "    print(f\"F1 macro for structure type classification: {f1_macro}\")\n",
    "    print(f\"F1 micro for structure type classification: {f1_micro}\")\n",
    "    print(f\"F1 weighted for structure type classification: {f1_weighted}\")\n",
    "    print(f\"Kappa for structure type classification: {kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 1400\n",
      "mean accuracy for structure type classification: 0.9469534050179211 +/- 0.01131163715989928\n",
      "mean F1 macro for structure type classification: 0.858535346971021 +/- 0.03547272696178411\n",
      "mean F1 micro for structure type classification: 0.9469534050179211 +/- 0.01131163715989928\n",
      "mean F1 weighted for structure type classification: 0.9453936311594869 +/- 0.011531855169652404\n",
      "mean Kappa for structure type classification: 0.921641881936479 +/- 0.016577855066538694\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean accuracy for structure type classification: {np.mean(acc_scores)} +/- {np.std(acc_scores)}\")\n",
    "print(f\"mean F1 macro for structure type classification: {np.mean(f1macro_scores)} +/- {np.std(f1macro_scores)}\")\n",
    "print(f\"mean F1 micro for structure type classification: {np.mean(f1micro_scores)} +/- {np.std(f1micro_scores)}\")\n",
    "print(f\"mean F1 weighted for structure type classification: {np.mean(f1weighted_scores)} +/- {np.std(f1weighted_scores)}\")\n",
    "print(f\"mean Kappa for structure type classification: {np.mean(kappa_scores)} +/- {np.std(kappa_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>[1, 3, 0, 3, 1, 3, 3, 3, 1, 3, 2, 3, 3, 2, 6, ...</td>\n",
       "      <td>[1, 3, 0, 3, 1, 3, 3, 3, 1, 3, 2, 3, 3, 5, 6, ...</td>\n",
       "      <td>0.942652</td>\n",
       "      <td>0.802654</td>\n",
       "      <td>0.942652</td>\n",
       "      <td>0.940785</td>\n",
       "      <td>0.915321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400</td>\n",
       "      <td>[0, 0, 3, 6, 3, 2, 4, 0, 3, 6, 6, 3, 3, 6, 3, ...</td>\n",
       "      <td>[0, 0, 3, 6, 3, 1, 4, 0, 3, 6, 6, 3, 3, 6, 3, ...</td>\n",
       "      <td>0.953405</td>\n",
       "      <td>0.872396</td>\n",
       "      <td>0.953405</td>\n",
       "      <td>0.951075</td>\n",
       "      <td>0.931170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1400</td>\n",
       "      <td>[6, 1, 3, 3, 4, 5, 0, 3, 3, 0, 2, 2, 1, 5, 6, ...</td>\n",
       "      <td>[6, 1, 3, 1, 4, 2, 0, 3, 3, 0, 2, 2, 1, 1, 6, ...</td>\n",
       "      <td>0.942652</td>\n",
       "      <td>0.856751</td>\n",
       "      <td>0.942652</td>\n",
       "      <td>0.938865</td>\n",
       "      <td>0.915485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0        1400  [1, 3, 0, 3, 1, 3, 3, 3, 1, 3, 2, 3, 3, 2, 6, ...   \n",
       "1        1400  [0, 0, 3, 6, 3, 2, 4, 0, 3, 6, 6, 3, 3, 6, 3, ...   \n",
       "2        1400  [6, 1, 3, 3, 4, 5, 0, 3, 3, 0, 2, 2, 1, 5, 6, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [1, 3, 0, 3, 1, 3, 3, 3, 1, 3, 2, 3, 3, 5, 6, ...  0.942652  0.802654   \n",
       "1  [0, 0, 3, 6, 3, 1, 4, 0, 3, 6, 6, 3, 3, 6, 3, ...  0.953405  0.872396   \n",
       "2  [6, 1, 3, 1, 4, 2, 0, 3, 3, 0, 2, 2, 1, 1, 6, ...  0.942652  0.856751   \n",
       "\n",
       "   f1_micro  f1_weighted     kappa  \n",
       "0  0.942652     0.940785  0.915321  \n",
       "1  0.953405     0.951075  0.931170  \n",
       "2  0.942652     0.938865  0.915485  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_1400 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_1400.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1800\n",
    "iterations = 10\n",
    "max_test_data = 2000\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "acc_scores = []\n",
    "f1macro_scores = []\n",
    "f1micro_scores = []\n",
    "f1weighted_scores = []\n",
    "kappa_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 1800\n",
      "validation: 78\n",
      "test: 79\n",
      "random_state = 42\n",
      "[0]\tvalidation_0-mlogloss:1.20725\tvalidation_1-mlogloss:1.31050\n",
      "[10]\tvalidation_0-mlogloss:0.14166\tvalidation_1-mlogloss:0.37582\n",
      "[20]\tvalidation_0-mlogloss:0.02901\tvalidation_1-mlogloss:0.22536\n",
      "[30]\tvalidation_0-mlogloss:0.01175\tvalidation_1-mlogloss:0.18397\n",
      "[40]\tvalidation_0-mlogloss:0.00740\tvalidation_1-mlogloss:0.17395\n",
      "[50]\tvalidation_0-mlogloss:0.00559\tvalidation_1-mlogloss:0.16075\n",
      "[60]\tvalidation_0-mlogloss:0.00466\tvalidation_1-mlogloss:0.15582\n",
      "[70]\tvalidation_0-mlogloss:0.00408\tvalidation_1-mlogloss:0.15120\n",
      "[80]\tvalidation_0-mlogloss:0.00371\tvalidation_1-mlogloss:0.14892\n",
      "[90]\tvalidation_0-mlogloss:0.00344\tvalidation_1-mlogloss:0.14381\n",
      "[100]\tvalidation_0-mlogloss:0.00323\tvalidation_1-mlogloss:0.14248\n",
      "[110]\tvalidation_0-mlogloss:0.00306\tvalidation_1-mlogloss:0.14014\n",
      "[120]\tvalidation_0-mlogloss:0.00293\tvalidation_1-mlogloss:0.13850\n",
      "[130]\tvalidation_0-mlogloss:0.00283\tvalidation_1-mlogloss:0.13655\n",
      "[140]\tvalidation_0-mlogloss:0.00273\tvalidation_1-mlogloss:0.13502\n",
      "[150]\tvalidation_0-mlogloss:0.00265\tvalidation_1-mlogloss:0.13432\n",
      "[157]\tvalidation_0-mlogloss:0.00261\tvalidation_1-mlogloss:0.13432\n",
      "Accuracy for structure type classification: 0.9620253164556962\n",
      "F1 macro for structure type classification: 0.8786213786213787\n",
      "F1 micro for structure type classification: 0.9620253164556962\n",
      "F1 weighted for structure type classification: 0.9603877135522706\n",
      "Kappa for structure type classification: 0.9436920883820384\n",
      "-------------Iteration 2/10\n",
      "train: 1800\n",
      "validation: 78\n",
      "test: 79\n",
      "random_state = 43\n",
      "[0]\tvalidation_0-mlogloss:1.21502\tvalidation_1-mlogloss:1.25703\n",
      "[10]\tvalidation_0-mlogloss:0.13837\tvalidation_1-mlogloss:0.33981\n",
      "[20]\tvalidation_0-mlogloss:0.02879\tvalidation_1-mlogloss:0.25739\n",
      "[30]\tvalidation_0-mlogloss:0.01199\tvalidation_1-mlogloss:0.23476\n",
      "[40]\tvalidation_0-mlogloss:0.00739\tvalidation_1-mlogloss:0.22705\n",
      "[50]\tvalidation_0-mlogloss:0.00557\tvalidation_1-mlogloss:0.21907\n",
      "[60]\tvalidation_0-mlogloss:0.00467\tvalidation_1-mlogloss:0.21890\n",
      "[70]\tvalidation_0-mlogloss:0.00409\tvalidation_1-mlogloss:0.21750\n",
      "[80]\tvalidation_0-mlogloss:0.00372\tvalidation_1-mlogloss:0.21495\n",
      "[90]\tvalidation_0-mlogloss:0.00344\tvalidation_1-mlogloss:0.21769\n",
      "[92]\tvalidation_0-mlogloss:0.00339\tvalidation_1-mlogloss:0.21866\n",
      "Accuracy for structure type classification: 0.9620253164556962\n",
      "F1 macro for structure type classification: 0.9420092253425587\n",
      "F1 micro for structure type classification: 0.9620253164556962\n",
      "F1 weighted for structure type classification: 0.9623042061860627\n",
      "Kappa for structure type classification: 0.9439451277199622\n",
      "-------------Iteration 3/10\n",
      "train: 1800\n",
      "validation: 78\n",
      "test: 79\n",
      "random_state = 44\n",
      "[0]\tvalidation_0-mlogloss:1.21936\tvalidation_1-mlogloss:1.28637\n",
      "[10]\tvalidation_0-mlogloss:0.13326\tvalidation_1-mlogloss:0.34162\n",
      "[20]\tvalidation_0-mlogloss:0.02933\tvalidation_1-mlogloss:0.22767\n",
      "[30]\tvalidation_0-mlogloss:0.01187\tvalidation_1-mlogloss:0.18652\n",
      "[40]\tvalidation_0-mlogloss:0.00724\tvalidation_1-mlogloss:0.17146\n",
      "[50]\tvalidation_0-mlogloss:0.00551\tvalidation_1-mlogloss:0.15961\n",
      "[60]\tvalidation_0-mlogloss:0.00459\tvalidation_1-mlogloss:0.15626\n",
      "[70]\tvalidation_0-mlogloss:0.00403\tvalidation_1-mlogloss:0.15239\n",
      "[80]\tvalidation_0-mlogloss:0.00367\tvalidation_1-mlogloss:0.15077\n",
      "[83]\tvalidation_0-mlogloss:0.00358\tvalidation_1-mlogloss:0.15025\n",
      "Accuracy for structure type classification: 0.9493670886075949\n",
      "F1 macro for structure type classification: 0.8792312105565118\n",
      "F1 micro for structure type classification: 0.9493670886075949\n",
      "F1 weighted for structure type classification: 0.9467308655962002\n",
      "Kappa for structure type classification: 0.924238791656677\n",
      "-------------Iteration 4/10\n",
      "train: 1800\n",
      "validation: 78\n",
      "test: 79\n",
      "random_state = 45\n",
      "[0]\tvalidation_0-mlogloss:1.21221\tvalidation_1-mlogloss:1.24288\n",
      "[10]\tvalidation_0-mlogloss:0.13738\tvalidation_1-mlogloss:0.28317\n",
      "[20]\tvalidation_0-mlogloss:0.02902\tvalidation_1-mlogloss:0.15892\n",
      "[30]\tvalidation_0-mlogloss:0.01196\tvalidation_1-mlogloss:0.12924\n",
      "[40]\tvalidation_0-mlogloss:0.00729\tvalidation_1-mlogloss:0.11539\n",
      "[50]\tvalidation_0-mlogloss:0.00554\tvalidation_1-mlogloss:0.11398\n",
      "[60]\tvalidation_0-mlogloss:0.00463\tvalidation_1-mlogloss:0.10838\n",
      "[70]\tvalidation_0-mlogloss:0.00404\tvalidation_1-mlogloss:0.10620\n",
      "[80]\tvalidation_0-mlogloss:0.00367\tvalidation_1-mlogloss:0.10154\n",
      "[90]\tvalidation_0-mlogloss:0.00340\tvalidation_1-mlogloss:0.09859\n",
      "[100]\tvalidation_0-mlogloss:0.00320\tvalidation_1-mlogloss:0.09728\n",
      "[110]\tvalidation_0-mlogloss:0.00303\tvalidation_1-mlogloss:0.09624\n",
      "[120]\tvalidation_0-mlogloss:0.00290\tvalidation_1-mlogloss:0.09700\n",
      "[123]\tvalidation_0-mlogloss:0.00286\tvalidation_1-mlogloss:0.09750\n",
      "Accuracy for structure type classification: 0.9240506329113924\n",
      "F1 macro for structure type classification: 0.7572649572649574\n",
      "F1 micro for structure type classification: 0.9240506329113924\n",
      "F1 weighted for structure type classification: 0.915265606404847\n",
      "Kappa for structure type classification: 0.8868465027452853\n",
      "-------------Iteration 5/10\n",
      "train: 1800\n",
      "validation: 78\n",
      "test: 79\n",
      "random_state = 46\n",
      "[0]\tvalidation_0-mlogloss:1.21537\tvalidation_1-mlogloss:1.27170\n",
      "[10]\tvalidation_0-mlogloss:0.13034\tvalidation_1-mlogloss:0.22316\n",
      "[20]\tvalidation_0-mlogloss:0.02745\tvalidation_1-mlogloss:0.12975\n",
      "[30]\tvalidation_0-mlogloss:0.01167\tvalidation_1-mlogloss:0.11721\n",
      "[40]\tvalidation_0-mlogloss:0.00730\tvalidation_1-mlogloss:0.11304\n",
      "[43]\tvalidation_0-mlogloss:0.00660\tvalidation_1-mlogloss:0.11298\n",
      "Accuracy for structure type classification: 0.9620253164556962\n",
      "F1 macro for structure type classification: 0.9354318549403036\n",
      "F1 micro for structure type classification: 0.9620253164556962\n",
      "F1 weighted for structure type classification: 0.9616146820175675\n",
      "Kappa for structure type classification: 0.9437588989084006\n",
      "-------------Iteration 6/10\n",
      "train: 1800\n",
      "validation: 78\n",
      "test: 79\n",
      "random_state = 47\n",
      "[0]\tvalidation_0-mlogloss:1.22056\tvalidation_1-mlogloss:1.23382\n",
      "[10]\tvalidation_0-mlogloss:0.14065\tvalidation_1-mlogloss:0.23919\n",
      "[20]\tvalidation_0-mlogloss:0.02943\tvalidation_1-mlogloss:0.13451\n",
      "[30]\tvalidation_0-mlogloss:0.01179\tvalidation_1-mlogloss:0.10377\n",
      "[40]\tvalidation_0-mlogloss:0.00723\tvalidation_1-mlogloss:0.08795\n",
      "[50]\tvalidation_0-mlogloss:0.00548\tvalidation_1-mlogloss:0.08267\n",
      "[60]\tvalidation_0-mlogloss:0.00459\tvalidation_1-mlogloss:0.08117\n",
      "[70]\tvalidation_0-mlogloss:0.00406\tvalidation_1-mlogloss:0.07908\n",
      "[80]\tvalidation_0-mlogloss:0.00370\tvalidation_1-mlogloss:0.07732\n",
      "[90]\tvalidation_0-mlogloss:0.00345\tvalidation_1-mlogloss:0.07767\n",
      "[92]\tvalidation_0-mlogloss:0.00341\tvalidation_1-mlogloss:0.07791\n",
      "Accuracy for structure type classification: 0.9620253164556962\n",
      "F1 macro for structure type classification: 0.9119134833420547\n",
      "F1 micro for structure type classification: 0.9620253164556962\n",
      "F1 weighted for structure type classification: 0.9644673188976985\n",
      "Kappa for structure type classification: 0.9439583825963584\n",
      "-------------Iteration 7/10\n",
      "train: 1800\n",
      "validation: 78\n",
      "test: 79\n",
      "random_state = 48\n",
      "[0]\tvalidation_0-mlogloss:1.21745\tvalidation_1-mlogloss:1.26477\n",
      "[10]\tvalidation_0-mlogloss:0.13815\tvalidation_1-mlogloss:0.28285\n",
      "[20]\tvalidation_0-mlogloss:0.03080\tvalidation_1-mlogloss:0.16244\n",
      "[30]\tvalidation_0-mlogloss:0.01239\tvalidation_1-mlogloss:0.12498\n",
      "[40]\tvalidation_0-mlogloss:0.00760\tvalidation_1-mlogloss:0.10846\n",
      "[50]\tvalidation_0-mlogloss:0.00564\tvalidation_1-mlogloss:0.10306\n",
      "[60]\tvalidation_0-mlogloss:0.00472\tvalidation_1-mlogloss:0.09948\n",
      "[70]\tvalidation_0-mlogloss:0.00411\tvalidation_1-mlogloss:0.09600\n",
      "[80]\tvalidation_0-mlogloss:0.00372\tvalidation_1-mlogloss:0.09667\n",
      "Accuracy for structure type classification: 0.9873417721518988\n",
      "F1 macro for structure type classification: 0.9555555555555556\n",
      "F1 micro for structure type classification: 0.9873417721518988\n",
      "F1 weighted for structure type classification: 0.9867791842475387\n",
      "Kappa for structure type classification: 0.9812217732350844\n",
      "-------------Iteration 8/10\n",
      "train: 1800\n",
      "validation: 78\n",
      "test: 79\n",
      "random_state = 49\n",
      "[0]\tvalidation_0-mlogloss:1.21182\tvalidation_1-mlogloss:1.26370\n",
      "[10]\tvalidation_0-mlogloss:0.13998\tvalidation_1-mlogloss:0.31034\n",
      "[20]\tvalidation_0-mlogloss:0.03085\tvalidation_1-mlogloss:0.17339\n",
      "[30]\tvalidation_0-mlogloss:0.01228\tvalidation_1-mlogloss:0.13250\n",
      "[40]\tvalidation_0-mlogloss:0.00746\tvalidation_1-mlogloss:0.12270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalidation_0-mlogloss:0.00557\tvalidation_1-mlogloss:0.11517\n",
      "[60]\tvalidation_0-mlogloss:0.00463\tvalidation_1-mlogloss:0.11008\n",
      "[70]\tvalidation_0-mlogloss:0.00405\tvalidation_1-mlogloss:0.10690\n",
      "[80]\tvalidation_0-mlogloss:0.00367\tvalidation_1-mlogloss:0.10501\n",
      "[90]\tvalidation_0-mlogloss:0.00340\tvalidation_1-mlogloss:0.10181\n",
      "[100]\tvalidation_0-mlogloss:0.00319\tvalidation_1-mlogloss:0.09965\n",
      "[110]\tvalidation_0-mlogloss:0.00303\tvalidation_1-mlogloss:0.09819\n",
      "[120]\tvalidation_0-mlogloss:0.00291\tvalidation_1-mlogloss:0.09605\n",
      "[130]\tvalidation_0-mlogloss:0.00280\tvalidation_1-mlogloss:0.09610\n",
      "[140]\tvalidation_0-mlogloss:0.00271\tvalidation_1-mlogloss:0.09622\n",
      "[150]\tvalidation_0-mlogloss:0.00263\tvalidation_1-mlogloss:0.09554\n",
      "[160]\tvalidation_0-mlogloss:0.00256\tvalidation_1-mlogloss:0.09493\n",
      "[170]\tvalidation_0-mlogloss:0.00251\tvalidation_1-mlogloss:0.09456\n",
      "[180]\tvalidation_0-mlogloss:0.00246\tvalidation_1-mlogloss:0.09426\n",
      "[190]\tvalidation_0-mlogloss:0.00242\tvalidation_1-mlogloss:0.09394\n",
      "[200]\tvalidation_0-mlogloss:0.00238\tvalidation_1-mlogloss:0.09362\n",
      "[210]\tvalidation_0-mlogloss:0.00235\tvalidation_1-mlogloss:0.09377\n",
      "[213]\tvalidation_0-mlogloss:0.00234\tvalidation_1-mlogloss:0.09379\n",
      "Accuracy for structure type classification: 0.9746835443037974\n",
      "F1 macro for structure type classification: 0.9\n",
      "F1 micro for structure type classification: 0.9746835443037974\n",
      "F1 weighted for structure type classification: 0.9708860759493672\n",
      "Kappa for structure type classification: 0.9624346172135045\n",
      "-------------Iteration 9/10\n",
      "train: 1800\n",
      "validation: 78\n",
      "test: 79\n",
      "random_state = 50\n",
      "[0]\tvalidation_0-mlogloss:1.21662\tvalidation_1-mlogloss:1.27758\n",
      "[10]\tvalidation_0-mlogloss:0.13764\tvalidation_1-mlogloss:0.30980\n",
      "[20]\tvalidation_0-mlogloss:0.02974\tvalidation_1-mlogloss:0.21061\n",
      "[30]\tvalidation_0-mlogloss:0.01216\tvalidation_1-mlogloss:0.17444\n",
      "[40]\tvalidation_0-mlogloss:0.00744\tvalidation_1-mlogloss:0.15197\n",
      "[50]\tvalidation_0-mlogloss:0.00560\tvalidation_1-mlogloss:0.14716\n",
      "[60]\tvalidation_0-mlogloss:0.00466\tvalidation_1-mlogloss:0.14704\n",
      "[67]\tvalidation_0-mlogloss:0.00425\tvalidation_1-mlogloss:0.14848\n",
      "Accuracy for structure type classification: 0.9113924050632911\n",
      "F1 macro for structure type classification: 0.7337271272145223\n",
      "F1 micro for structure type classification: 0.9113924050632911\n",
      "F1 weighted for structure type classification: 0.911520131642991\n",
      "Kappa for structure type classification: 0.869452313503305\n",
      "-------------Iteration 10/10\n",
      "train: 1800\n",
      "validation: 78\n",
      "test: 79\n",
      "random_state = 51\n",
      "[0]\tvalidation_0-mlogloss:1.20262\tvalidation_1-mlogloss:1.29322\n",
      "[10]\tvalidation_0-mlogloss:0.13440\tvalidation_1-mlogloss:0.30990\n",
      "[20]\tvalidation_0-mlogloss:0.02836\tvalidation_1-mlogloss:0.16602\n",
      "[30]\tvalidation_0-mlogloss:0.01153\tvalidation_1-mlogloss:0.12869\n",
      "[40]\tvalidation_0-mlogloss:0.00716\tvalidation_1-mlogloss:0.11493\n",
      "[50]\tvalidation_0-mlogloss:0.00542\tvalidation_1-mlogloss:0.11047\n",
      "[60]\tvalidation_0-mlogloss:0.00454\tvalidation_1-mlogloss:0.10760\n",
      "[70]\tvalidation_0-mlogloss:0.00399\tvalidation_1-mlogloss:0.10448\n",
      "[80]\tvalidation_0-mlogloss:0.00363\tvalidation_1-mlogloss:0.10216\n",
      "[90]\tvalidation_0-mlogloss:0.00337\tvalidation_1-mlogloss:0.09820\n",
      "[100]\tvalidation_0-mlogloss:0.00317\tvalidation_1-mlogloss:0.09569\n",
      "[110]\tvalidation_0-mlogloss:0.00302\tvalidation_1-mlogloss:0.09449\n",
      "[120]\tvalidation_0-mlogloss:0.00289\tvalidation_1-mlogloss:0.09324\n",
      "[130]\tvalidation_0-mlogloss:0.00279\tvalidation_1-mlogloss:0.09282\n",
      "[140]\tvalidation_0-mlogloss:0.00270\tvalidation_1-mlogloss:0.09104\n",
      "[150]\tvalidation_0-mlogloss:0.00262\tvalidation_1-mlogloss:0.09030\n",
      "[160]\tvalidation_0-mlogloss:0.00257\tvalidation_1-mlogloss:0.09095\n",
      "Accuracy for structure type classification: 0.9873417721518988\n",
      "F1 macro for structure type classification: 0.9555555555555556\n",
      "F1 micro for structure type classification: 0.9873417721518988\n",
      "F1 weighted for structure type classification: 0.9867791842475387\n",
      "Kappa for structure type classification: 0.9812217732350844\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for classification\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, le = prepare_dataset_classification(\n",
    "        scattering_patterns, \n",
    "        structure_types, \n",
    "        max_test_data=max_test_data, \n",
    "        train_size=train_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Classification of structure_type\n",
    "    y_test, y_pred, acc, f1_macro, f1_micro, f1_weighted, kappa = train_and_evaluate_classifier(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_val, \n",
    "        y_val, \n",
    "        X_test, \n",
    "        y_test, \n",
    "        le,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    acc_scores.append(acc)\n",
    "    f1macro_scores.append(f1_macro)\n",
    "    f1micro_scores.append(f1_micro)\n",
    "    f1weighted_scores.append(f1_weighted)\n",
    "    kappa_scores.append(kappa)\n",
    "    print(f\"Accuracy for structure type classification: {acc}\")\n",
    "    print(f\"F1 macro for structure type classification: {f1_macro}\")\n",
    "    print(f\"F1 micro for structure type classification: {f1_micro}\")\n",
    "    print(f\"F1 weighted for structure type classification: {f1_weighted}\")\n",
    "    print(f\"Kappa for structure type classification: {kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 1800\n",
      "mean accuracy for structure type classification: 0.9582278481012658 +/- 0.023374918117239744\n",
      "mean F1 macro for structure type classification: 0.8849310348393399 +/- 0.07481482042729466\n",
      "mean F1 micro for structure type classification: 0.9582278481012658 +/- 0.023374918117239744\n",
      "mean F1 weighted for structure type classification: 0.9566734968742082 +/- 0.024490114730655734\n",
      "mean Kappa for structure type classification: 0.9380770269195701 +/- 0.03460416544888812\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean accuracy for structure type classification: {np.mean(acc_scores)} +/- {np.std(acc_scores)}\")\n",
    "print(f\"mean F1 macro for structure type classification: {np.mean(f1macro_scores)} +/- {np.std(f1macro_scores)}\")\n",
    "print(f\"mean F1 micro for structure type classification: {np.mean(f1micro_scores)} +/- {np.std(f1micro_scores)}\")\n",
    "print(f\"mean F1 weighted for structure type classification: {np.mean(f1weighted_scores)} +/- {np.std(f1weighted_scores)}\")\n",
    "print(f\"mean Kappa for structure type classification: {np.mean(kappa_scores)} +/- {np.std(kappa_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1800</td>\n",
       "      <td>[3, 3, 3, 3, 1, 1, 3, 1, 3, 3, 3, 2, 3, 1, 1, ...</td>\n",
       "      <td>[3, 3, 3, 3, 1, 1, 3, 1, 3, 3, 3, 2, 3, 1, 1, ...</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.878621</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.960388</td>\n",
       "      <td>0.943692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>[1, 3, 5, 0, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, ...</td>\n",
       "      <td>[1, 3, 5, 0, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, ...</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.942009</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.962304</td>\n",
       "      <td>0.943945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1800</td>\n",
       "      <td>[5, 2, 1, 3, 3, 1, 3, 6, 3, 3, 3, 3, 3, 6, 3, ...</td>\n",
       "      <td>[2, 5, 1, 3, 3, 1, 3, 6, 3, 3, 3, 3, 3, 6, 3, ...</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.879231</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.946731</td>\n",
       "      <td>0.924239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0        1800  [3, 3, 3, 3, 1, 1, 3, 1, 3, 3, 3, 2, 3, 1, 1, ...   \n",
       "1        1800  [1, 3, 5, 0, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, ...   \n",
       "2        1800  [5, 2, 1, 3, 3, 1, 3, 6, 3, 3, 3, 3, 3, 6, 3, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [3, 3, 3, 3, 1, 1, 3, 1, 3, 3, 3, 2, 3, 1, 1, ...  0.962025  0.878621   \n",
       "1  [1, 3, 5, 0, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, ...  0.962025  0.942009   \n",
       "2  [2, 5, 1, 3, 3, 1, 3, 6, 3, 3, 3, 3, 3, 6, 3, ...  0.949367  0.879231   \n",
       "\n",
       "   f1_micro  f1_weighted     kappa  \n",
       "0  0.962025     0.960388  0.943692  \n",
       "1  0.962025     0.962304  0.943945  \n",
       "2  0.949367     0.946731  0.924239  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_1800 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_1800.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>[3, 3, 2, 0, 3, 1, 1, 1, 4, 1, 4, 0, 3, 3, 0, ...</td>\n",
       "      <td>[3, 3, 2, 0, 3, 1, 1, 1, 3, 1, 1, 0, 3, 3, 0, ...</td>\n",
       "      <td>0.911635</td>\n",
       "      <td>0.768821</td>\n",
       "      <td>0.911635</td>\n",
       "      <td>0.904341</td>\n",
       "      <td>0.869417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>[3, 3, 1, 2, 3, 3, 2, 3, 1, 5, 6, 0, 0, 6, 3, ...</td>\n",
       "      <td>[3, 3, 1, 2, 3, 3, 1, 3, 1, 1, 1, 0, 0, 6, 3, ...</td>\n",
       "      <td>0.904271</td>\n",
       "      <td>0.768452</td>\n",
       "      <td>0.904271</td>\n",
       "      <td>0.899641</td>\n",
       "      <td>0.857935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>[6, 3, 0, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 1, 3, ...</td>\n",
       "      <td>[1, 3, 0, 3, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.734787</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.888834</td>\n",
       "      <td>0.847666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600</td>\n",
       "      <td>[3, 3, 6, 3, 3, 1, 1, 3, 1, 3, 3, 3, 1, 3, 4, ...</td>\n",
       "      <td>[3, 3, 6, 3, 3, 1, 1, 3, 1, 3, 3, 3, 1, 3, 4, ...</td>\n",
       "      <td>0.899853</td>\n",
       "      <td>0.769408</td>\n",
       "      <td>0.899853</td>\n",
       "      <td>0.894252</td>\n",
       "      <td>0.851786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600</td>\n",
       "      <td>[1, 6, 1, 6, 4, 3, 1, 2, 3, 3, 3, 3, 6, 3, 3, ...</td>\n",
       "      <td>[1, 0, 1, 6, 4, 3, 1, 2, 3, 3, 3, 3, 6, 3, 3, ...</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.790976</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.902648</td>\n",
       "      <td>0.863301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0         600  [3, 3, 2, 0, 3, 1, 1, 1, 4, 1, 4, 0, 3, 3, 0, ...   \n",
       "1         600  [3, 3, 1, 2, 3, 3, 2, 3, 1, 5, 6, 0, 0, 6, 3, ...   \n",
       "2         600  [6, 3, 0, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 1, 3, ...   \n",
       "3         600  [3, 3, 6, 3, 3, 1, 1, 3, 1, 3, 3, 3, 1, 3, 4, ...   \n",
       "4         600  [1, 6, 1, 6, 4, 3, 1, 2, 3, 3, 3, 3, 6, 3, 3, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [3, 3, 2, 0, 3, 1, 1, 1, 3, 1, 1, 0, 3, 3, 0, ...  0.911635  0.768821   \n",
       "1  [3, 3, 1, 2, 3, 3, 1, 3, 1, 1, 1, 0, 0, 6, 3, ...  0.904271  0.768452   \n",
       "2  [1, 3, 0, 3, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, ...  0.896907  0.734787   \n",
       "3  [3, 3, 6, 3, 3, 1, 1, 3, 1, 3, 3, 3, 1, 3, 4, ...  0.899853  0.769408   \n",
       "4  [1, 0, 1, 6, 4, 3, 1, 2, 3, 3, 3, 3, 6, 3, 3, ...  0.907216  0.790976   \n",
       "\n",
       "   f1_micro  f1_weighted     kappa  \n",
       "0  0.911635     0.904341  0.869417  \n",
       "1  0.904271     0.899641  0.857935  \n",
       "2  0.896907     0.888834  0.847666  \n",
       "3  0.899853     0.894252  0.851786  \n",
       "4  0.907216     0.902648  0.863301  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res = pd.concat([\n",
    "    compiled_res_600,\n",
    "    compiled_res_1000,\n",
    "    compiled_res_1400,\n",
    "    compiled_res_1800\n",
    "], ignore_index=True)\n",
    "print(len(compiled_res))\n",
    "compiled_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_res[\"y_true\"] = compiled_res[\"y_true\"].apply(lambda arr: list(arr))\n",
    "compiled_res[\"y_pred\"] = compiled_res[\"y_pred\"].apply(lambda arr: list(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_res.to_csv(\"XGBoost_results_structure_type_7cat_unbalanced.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   train_size   40 non-null     int64  \n",
      " 1   y_true       40 non-null     object \n",
      " 2   y_pred       40 non-null     object \n",
      " 3   accuracy     40 non-null     float64\n",
      " 4   f1_macro     40 non-null     float64\n",
      " 5   f1_micro     40 non-null     float64\n",
      " 6   f1_weighted  40 non-null     float64\n",
      " 7   kappa        40 non-null     float64\n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"XGBoost_results_structure_type_7cat_unbalanced.csv\", sep=',')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>[3, 3, 2, 0, 3, 1, 1, 1, 4, 1, 4, 0, 3, 3, 0, ...</td>\n",
       "      <td>[3, 3, 2, 0, 3, 1, 1, 1, 3, 1, 1, 0, 3, 3, 0, ...</td>\n",
       "      <td>0.911635</td>\n",
       "      <td>0.768821</td>\n",
       "      <td>0.911635</td>\n",
       "      <td>0.904341</td>\n",
       "      <td>0.869417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>[3, 3, 1, 2, 3, 3, 2, 3, 1, 5, 6, 0, 0, 6, 3, ...</td>\n",
       "      <td>[3, 3, 1, 2, 3, 3, 1, 3, 1, 1, 1, 0, 0, 6, 3, ...</td>\n",
       "      <td>0.904271</td>\n",
       "      <td>0.768452</td>\n",
       "      <td>0.904271</td>\n",
       "      <td>0.899641</td>\n",
       "      <td>0.857935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>[6, 3, 0, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 1, 3, ...</td>\n",
       "      <td>[1, 3, 0, 3, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.734787</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.888834</td>\n",
       "      <td>0.847666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0         600  [3, 3, 2, 0, 3, 1, 1, 1, 4, 1, 4, 0, 3, 3, 0, ...   \n",
       "1         600  [3, 3, 1, 2, 3, 3, 2, 3, 1, 5, 6, 0, 0, 6, 3, ...   \n",
       "2         600  [6, 3, 0, 3, 3, 2, 3, 3, 1, 1, 3, 3, 3, 1, 3, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [3, 3, 2, 0, 3, 1, 1, 1, 3, 1, 1, 0, 3, 3, 0, ...  0.911635  0.768821   \n",
       "1  [3, 3, 1, 2, 3, 3, 1, 3, 1, 1, 1, 0, 0, 6, 3, ...  0.904271  0.768452   \n",
       "2  [1, 3, 0, 3, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, ...  0.896907  0.734787   \n",
       "\n",
       "   f1_micro  f1_weighted     kappa  \n",
       "0  0.911635     0.904341  0.869417  \n",
       "1  0.904271     0.899641  0.857935  \n",
       "2  0.896907     0.888834  0.847666  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_weighted</th>\n",
       "      <th colspan=\"2\" halign=\"left\">kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.898380</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.757258</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>0.898380</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.892227</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.849724</td>\n",
       "      <td>0.004927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.924426</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.807231</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.924426</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.920754</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.888597</td>\n",
       "      <td>0.003887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>0.946953</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.858535</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>0.946953</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.945394</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.921642</td>\n",
       "      <td>0.005526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>0.958228</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.884931</td>\n",
       "      <td>0.024938</td>\n",
       "      <td>0.958228</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.956673</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>0.938077</td>\n",
       "      <td>0.011535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy            f1_macro            f1_micro            \\\n",
       "                mean       sem      mean       sem      mean       sem   \n",
       "train_size                                                               \n",
       "600         0.898380  0.003322  0.757258  0.006034  0.898380  0.003322   \n",
       "1000        0.924426  0.002619  0.807231  0.005622  0.924426  0.002619   \n",
       "1400        0.946953  0.003771  0.858535  0.011824  0.946953  0.003771   \n",
       "1800        0.958228  0.007792  0.884931  0.024938  0.958228  0.007792   \n",
       "\n",
       "           f1_weighted               kappa            \n",
       "                  mean       sem      mean       sem  \n",
       "train_size                                            \n",
       "600           0.892227  0.003298  0.849724  0.004927  \n",
       "1000          0.920754  0.002980  0.888597  0.003887  \n",
       "1400          0.945394  0.003844  0.921642  0.005526  \n",
       "1800          0.956673  0.008163  0.938077  0.011535  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_res = df.select_dtypes(include = [\"int\", \"float\"]).groupby(['train_size']).agg(['mean', 'sem'])\n",
    "grouped_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mats = []\n",
    "for i in np.arange(len(df)):\n",
    "    confusion_matrix = {\n",
    "        'all_y_true': literal_eval(df[\"y_true\"][i]),\n",
    "        'all_y_pred': literal_eval(df[\"y_pred\"][i])\n",
    "    }\n",
    "    conf_mats.append(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98888889 0.         0.         0.         0.01111111 0.\n",
      "  0.        ]\n",
      " [0.         0.97857143 0.         0.00714286 0.         0.01428571\n",
      "  0.        ]\n",
      " [0.         0.15       0.8        0.         0.         0.05\n",
      "  0.        ]\n",
      " [0.         0.0097561  0.         0.9902439  0.         0.\n",
      "  0.        ]\n",
      " [0.         0.1        0.         0.         0.9        0.\n",
      "  0.        ]\n",
      " [0.         0.06666667 0.36666667 0.         0.         0.56666667\n",
      "  0.        ]\n",
      " [0.         0.         0.04285714 0.         0.         0.\n",
      "  0.95714286]]\n",
      "accuracy: 0.9582278481012658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f24fe0e8640>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 330x250 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_maxsize = compiled_res[compiled_res[\"train_size\"]==max(compiled_res[\"train_size\"])].index\n",
    "conf_mats_max = [conf_mats[i] for i in index_maxsize]\n",
    "\n",
    "actual_all, predicted_all = [], []\n",
    "for index, _ in enumerate(conf_mats_max):\n",
    "    preds = conf_mats_max[index]\n",
    "    actual = preds[\"all_y_true\"]\n",
    "    predicted = preds[\"all_y_pred\"]\n",
    "    \n",
    "    for true, pred in zip(actual, predicted):\n",
    "        actual_all.append(true)\n",
    "        predicted_all.append(pred)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual_all, predicted_all)\n",
    "confusion_matrix_norm = confusion_matrix.astype(\"float\") / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "print(confusion_matrix_norm)\n",
    "\n",
    "cm = pycm.ConfusionMatrix(list(actual_all), list(predicted_all))\n",
    "acc = cm.Overall_ACC\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "cm_display = metrics.ConfusionMatrixDisplay(\n",
    "    confusion_matrix = confusion_matrix_norm, display_labels = [0, 1, 2, 3, 4, 5, 6])\n",
    "cm_display.plot(cmap=plt.cm.Blues, include_values=True, values_format=\".1f\")\n",
    "#plt.savefig('classif_struct_type_confusionMatrix_7cat_unbalanced_30ep_size1800_XGBoost.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debyecalculator_env]",
   "language": "python",
   "name": "conda-env-debyecalculator_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
