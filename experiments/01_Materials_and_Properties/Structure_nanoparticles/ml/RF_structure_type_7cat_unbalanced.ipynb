{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - pair distribution function (PDF) - structure type 7cat unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicky/anaconda3/envs/debyecalculator_env/lib/python3.9/site-packages/numpy/core/getlimits.py:542: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from debyecalculator import DebyeCalculator\n",
    "from ase.io import read\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import tiktoken\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, r2_score, mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import pycm\n",
    "from ast import literal_eval\n",
    "import sys\n",
    "sys.path.append(\"/mnt/c/Users/44907688G/Documents/home_vicky/LLMs_models/gptchem-gptj/plotutils/\")\n",
    "from plotutils import *\n",
    "plt.style.use(\"/mnt/c/Users/44907688G/Documents/home_vicky/LLMs_models/gptchem-gptj/plotutils/kevin.mplstyle\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xyz_files():\n",
    "    # Initialise DebyeCalculator object\n",
    "    calc = DebyeCalculator()\n",
    "    print(calc)\n",
    "    \n",
    "    # Load XYZ files\n",
    "    XYZ_files = sorted(glob.glob(\"../xyz_files/*.xyz\"))\n",
    "    random.shuffle(XYZ_files)\n",
    "\n",
    "    # Calculate Pair Distribution Function for all XYZ files\n",
    "    scattering_files = []\n",
    "    structure_types = []\n",
    "    num_atoms = []\n",
    "\n",
    "    for iter, xyz_file in enumerate(XYZ_files):\n",
    "        # Extract structure type\n",
    "        structure_type = os.path.basename(xyz_file).split('_')[0]\n",
    "\n",
    "        # Calculate the scattering pattern\n",
    "        scatt_x, scatt_Int = calc.gr(structure_source=xyz_file)\n",
    "\n",
    "        # Normalise the scattering files\n",
    "        scatt_Int /= max(scatt_Int)\n",
    "        scattering_files.append(scatt_Int)\n",
    "\n",
    "        # Increment the count for this structure type\n",
    "        structure_types.append(structure_type)\n",
    "\n",
    "        atoms = read(xyz_file)\n",
    "        num_atoms.append(len(atoms))\n",
    "\n",
    "    return scattering_files, structure_types, num_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5746/1612413307.py:3: UserWarning: Warning: Your system might have a CUDA-enabled GPU, but CUDA is not available. Computations will run on the CPU instead. For optimal performance, please install Pytorch with CUDA support. If you do not have a CUDA-enabled CPU, you can surpress this warning by specifying the 'device' argument as 'cpu'\n",
      "  calc = DebyeCalculator()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebyeCalculator{'qmin': 1.0, 'qmax': 30.0, 'qdamp': 0.04, 'qstep': 0.05, 'rmin': 0.0, 'rmax': 20.0, 'rstep': 0.01, 'rthres': 0.0, 'biso': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# Simulate scattering data\n",
    "scattering_files, structure_types, num_atoms = process_xyz_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scattering_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.24081259e-03, -2.43981788e-03, -3.55886901e-03,\n",
       "       -4.56686504e-03, -5.44242794e-03, -6.17583841e-03, -6.76981779e-03,\n",
       "       -7.23938225e-03, -7.61045050e-03, -7.91762862e-03, -8.20107665e-03,\n",
       "       -8.50310456e-03, -8.86432454e-03, -9.32015758e-03, -9.89775546e-03,\n",
       "       -1.06134415e-02, -1.14714708e-02, -1.24634868e-02, -1.35693504e-02,\n",
       "       -1.47587219e-02, -1.59940217e-02, -1.72333848e-02, -1.84345916e-02,\n",
       "       -1.95586290e-02, -2.05732044e-02, -2.14555021e-02, -2.21943278e-02,\n",
       "       -2.27909349e-02, -2.32591350e-02, -2.36239322e-02, -2.39193980e-02,\n",
       "       -2.41856966e-02, -2.44655330e-02, -2.48004626e-02, -2.52271071e-02,\n",
       "       -2.57741194e-02, -2.64594071e-02, -2.72887163e-02, -2.82550789e-02,\n",
       "       -2.93392893e-02, -3.05116437e-02, -3.17345411e-02, -3.29658240e-02,\n",
       "       -3.41622792e-02, -3.52836587e-02, -3.62959877e-02, -3.71749178e-02,\n",
       "       -3.79074812e-02, -3.84935588e-02, -3.89457569e-02, -3.92884202e-02,\n",
       "       -3.95554863e-02, -3.97875607e-02, -4.00282070e-02, -4.03202996e-02,\n",
       "       -4.07022499e-02, -4.12044451e-02, -4.18465957e-02, -4.26361896e-02,\n",
       "       -4.35675271e-02, -4.46221568e-02, -4.57707383e-02, -4.69754003e-02,\n",
       "       -4.81928736e-02, -4.93786745e-02, -5.04906923e-02, -5.14931269e-02,\n",
       "       -5.23593836e-02, -5.30747734e-02, -5.36375418e-02, -5.40593043e-02,\n",
       "       -5.43640181e-02, -5.45857698e-02, -5.47659956e-02, -5.49499206e-02,\n",
       "       -5.51821254e-02, -5.55032901e-02, -5.59460223e-02, -5.65323383e-02,\n",
       "       -5.72714172e-02, -5.81588969e-02, -5.91770783e-02, -6.02965169e-02,\n",
       "       -6.14784360e-02, -6.26783147e-02, -6.38495684e-02, -6.49476647e-02,\n",
       "       -6.59342259e-02, -6.67802244e-02, -6.74687549e-02, -6.79964572e-02,\n",
       "       -6.83739781e-02, -6.86250180e-02, -6.87843561e-02, -6.88948333e-02,\n",
       "       -6.90037310e-02, -6.91583306e-02, -6.94020987e-02, -6.97705969e-02,\n",
       "       -7.02883825e-02, -7.09666684e-02, -7.18025640e-02, -7.27788582e-02,\n",
       "       -7.38656372e-02, -7.50229061e-02, -7.62039125e-02, -7.73592591e-02,\n",
       "       -7.84413517e-02, -7.94084743e-02, -8.02284926e-02, -8.08819532e-02,\n",
       "       -8.13635513e-02, -8.16830397e-02, -8.18642676e-02, -8.19430798e-02,\n",
       "       -8.19645822e-02, -8.19788352e-02, -8.20367336e-02, -8.21854770e-02,\n",
       "       -8.24643001e-02, -8.29008371e-02, -8.35089758e-02, -8.42872784e-02,\n",
       "       -8.52187723e-02, -8.62727687e-02, -8.74072090e-02, -8.85722116e-02,\n",
       "       -8.97147134e-02, -9.07827765e-02, -9.17304903e-02, -9.25217271e-02,\n",
       "       -9.31337327e-02, -9.35592130e-02, -9.38067660e-02, -9.39007327e-02,\n",
       "       -9.38789546e-02, -9.37894955e-02, -9.36865881e-02, -9.36258808e-02,\n",
       "       -9.36595351e-02, -9.38315764e-02, -9.41738486e-02, -9.47033018e-02,\n",
       "       -9.54200551e-02, -9.63075086e-02, -9.73333120e-02, -9.84524116e-02,\n",
       "       -9.96107683e-02, -1.00749806e-01, -1.01811975e-01, -1.02745444e-01,\n",
       "       -1.03508934e-01, -1.04075611e-01, -1.04435302e-01, -1.04595780e-01,\n",
       "       -1.04582347e-01, -1.04435667e-01, -1.04208253e-01, -1.03960104e-01,\n",
       "       -1.03753559e-01, -1.03647873e-01, -1.03693344e-01, -1.03927419e-01,\n",
       "       -1.04371153e-01, -1.05026655e-01, -1.05877213e-01, -1.06888101e-01,\n",
       "       -1.08009689e-01, -1.09181575e-01, -1.10337690e-01, -1.11412108e-01,\n",
       "       -1.12344913e-01, -1.13087811e-01, -1.13607973e-01, -1.13891743e-01,\n",
       "       -1.13945991e-01, -1.13797531e-01, -1.13491528e-01, -1.13087215e-01,\n",
       "       -1.12653494e-01, -1.12262264e-01, -1.11982822e-01, -1.11875102e-01,\n",
       "       -1.11984521e-01, -1.12337641e-01, -1.12939358e-01, -1.13772236e-01,\n",
       "       -1.14797801e-01, -1.15959197e-01, -1.17186159e-01, -1.18400991e-01,\n",
       "       -1.19525231e-01, -1.20486595e-01, -1.21225700e-01, -1.21701375e-01,\n",
       "       -1.21894747e-01, -1.21811479e-01, -1.21481538e-01, -1.20957285e-01,\n",
       "       -1.20309383e-01, -1.19620435e-01, -1.18978389e-01, -1.18468747e-01,\n",
       "       -1.18166678e-01, -1.18130304e-01, -1.18395038e-01, -1.18969910e-01,\n",
       "       -1.19835876e-01, -1.20947212e-01, -1.22234344e-01, -1.23609908e-01,\n",
       "       -1.24975652e-01, -1.26231149e-01, -1.27282426e-01, -1.28050968e-01,\n",
       "       -1.28480569e-01, -1.28543690e-01, -1.28244370e-01, -1.27619013e-01,\n",
       "       -1.26734108e-01, -1.25681296e-01, -1.24569185e-01, -1.23514459e-01,\n",
       "       -1.22630849e-01, -1.22017518e-01, -1.21748522e-01, -1.21863000e-01,\n",
       "       -1.22357711e-01, -1.23182356e-01, -1.24237746e-01, -1.25376970e-01,\n",
       "       -1.26410887e-01, -1.27115145e-01, -1.27239615e-01, -1.26520097e-01,\n",
       "       -1.24690384e-01, -1.21492140e-01, -1.16686612e-01, -1.10061593e-01,\n",
       "       -1.01437114e-01, -9.06679109e-02, -7.76424929e-02, -6.22795448e-02,\n",
       "       -4.45220284e-02, -2.43305378e-02, -1.67425314e-03,  2.34756581e-02,\n",
       "        5.11520430e-02,  8.13953653e-02,  1.14253238e-01,  1.49776816e-01,\n",
       "        1.88011691e-01,  2.28986531e-01,  2.72697270e-01,  3.19088519e-01,\n",
       "        3.68034363e-01,  4.19318944e-01,  4.72618908e-01,  5.27489901e-01,\n",
       "        5.83356798e-01,  6.39512658e-01,  6.95123255e-01,  7.49239743e-01,\n",
       "        8.00822437e-01,  8.48763645e-01,  8.91932547e-01,  9.29210246e-01,\n",
       "        9.59535837e-01,  9.81951296e-01,  9.95646894e-01,  1.00000000e+00,\n",
       "        9.94609892e-01,  9.79322970e-01,  9.54249382e-01,  9.19767141e-01,\n",
       "        8.76514137e-01,  8.25371504e-01,  7.67431796e-01,  7.03961909e-01,\n",
       "        6.36354804e-01,  5.66078603e-01,  4.94622082e-01,  4.23439175e-01,\n",
       "        3.53898585e-01,  2.87236571e-01,  2.24518389e-01,  1.66608498e-01,\n",
       "        1.14149898e-01,  6.75610453e-02,  2.70300973e-02, -7.46678282e-03,\n",
       "       -3.61461975e-02, -5.93875051e-02, -7.76997060e-02, -9.16840583e-02,\n",
       "       -1.01995468e-01, -1.09306335e-01, -1.14272207e-01, -1.17503487e-01,\n",
       "       -1.19541764e-01, -1.20843709e-01, -1.21772148e-01, -1.22592770e-01,\n",
       "       -1.23478658e-01, -1.24518499e-01, -1.25730276e-01, -1.27076641e-01,\n",
       "       -1.28482103e-01, -1.29850566e-01, -1.31080806e-01, -1.32080585e-01,\n",
       "       -1.32776886e-01, -1.33123830e-01, -1.33106038e-01, -1.32738978e-01,\n",
       "       -1.32066220e-01, -1.31154224e-01, -1.30085588e-01, -1.28950164e-01,\n",
       "       -1.27837986e-01, -1.26831248e-01, -1.25997290e-01, -1.25384986e-01,\n",
       "       -1.25020549e-01, -1.24907702e-01, -1.25028372e-01, -1.25345528e-01,\n",
       "       -1.25807524e-01, -1.26353353e-01, -1.26918361e-01, -1.27439275e-01,\n",
       "       -1.27860054e-01, -1.28135338e-01, -1.28234401e-01, -1.28141522e-01,\n",
       "       -1.27857804e-01, -1.27398938e-01, -1.26793966e-01, -1.26081303e-01,\n",
       "       -1.25306278e-01, -1.24516211e-01, -1.23757429e-01, -1.23070620e-01,\n",
       "       -1.22489311e-01, -1.22036628e-01, -1.21724583e-01, -1.21553741e-01,\n",
       "       -1.21513776e-01, -1.21584624e-01, -1.21738642e-01, -1.21942893e-01,\n",
       "       -1.22162163e-01, -1.22360930e-01, -1.22506566e-01, -1.22571252e-01,\n",
       "       -1.22533515e-01, -1.22380078e-01, -1.22105613e-01, -1.21713839e-01,\n",
       "       -1.21215858e-01, -1.20630048e-01, -1.19980387e-01, -1.19294465e-01,\n",
       "       -1.18602142e-01, -1.17932908e-01, -1.17314681e-01, -1.16771221e-01,\n",
       "       -1.16321281e-01, -1.15976952e-01, -1.15742862e-01, -1.15616113e-01,\n",
       "       -1.15585864e-01, -1.15634382e-01, -1.15737215e-01, -1.15866177e-01,\n",
       "       -1.15989409e-01, -1.16074659e-01, -1.16091043e-01, -1.16011508e-01,\n",
       "       -1.15814924e-01, -1.15487598e-01, -1.15025260e-01, -1.14433378e-01,\n",
       "       -1.13727689e-01, -1.12933300e-01, -1.12083822e-01, -1.11217991e-01,\n",
       "       -1.10378720e-01, -1.09608710e-01, -1.08947307e-01, -1.08427033e-01,\n",
       "       -1.08070537e-01, -1.07887894e-01, -1.07875057e-01, -1.08012997e-01,\n",
       "       -1.08268403e-01, -1.08595483e-01, -1.08938880e-01, -1.09237820e-01,\n",
       "       -1.09431289e-01, -1.09462872e-01, -1.09286346e-01, -1.08870216e-01,\n",
       "       -1.08201519e-01, -1.07287593e-01, -1.06156781e-01, -1.04855560e-01,\n",
       "       -1.03445224e-01, -1.01993084e-01, -1.00566044e-01, -9.92180184e-02,\n",
       "       -9.79797170e-02, -9.68466327e-02, -9.57681015e-02, -9.46386009e-02,\n",
       "       -9.32912976e-02, -9.14949402e-02, -8.89564157e-02, -8.53257924e-02,\n",
       "       -8.02092254e-02, -7.31834546e-02, -6.38184920e-02, -5.16988039e-02,\n",
       "       -3.64536718e-02, -1.77797098e-02,  4.52678697e-03,  3.05519477e-02,\n",
       "        6.02355562e-02,  9.33667645e-02,  1.29564539e-01,  1.68289974e-01,\n",
       "        2.08843112e-01,  2.50387728e-01,  2.91972041e-01,  3.32569569e-01,\n",
       "        3.71104032e-01,  4.06507283e-01,  4.37749565e-01,  4.63896632e-01,\n",
       "        4.84140664e-01,  4.97845978e-01,  5.04572511e-01,  5.04100621e-01,\n",
       "        4.96441334e-01,  4.81836140e-01,  4.60749477e-01,  4.33843672e-01,\n",
       "        4.01957005e-01,  3.66056621e-01,  3.27207208e-01,  2.86512375e-01,\n",
       "        2.45081887e-01,  2.03970701e-01,  1.64154649e-01,  1.26477972e-01,\n",
       "        9.16424543e-02,  6.01722486e-02,  3.24205756e-02,  8.55571125e-03,\n",
       "       -1.14177056e-02, -2.76513454e-02, -4.04214934e-02, -5.01064658e-02,\n",
       "       -5.71505576e-02, -6.20356165e-02, -6.52473792e-02, -6.72493353e-02,\n",
       "       -6.84580877e-02, -6.92265183e-02, -6.98308572e-02, -7.04668313e-02,\n",
       "       -7.12497830e-02, -7.22213611e-02, -7.33604878e-02, -7.45985135e-02,\n",
       "       -7.58347660e-02, -7.69542381e-02, -7.78433159e-02, -7.84041807e-02,\n",
       "       -7.85658360e-02, -7.82920122e-02, -7.75841177e-02, -7.64807686e-02,\n",
       "       -7.50548393e-02, -7.34038800e-02, -7.16432258e-02, -6.98918030e-02,\n",
       "       -6.82637319e-02, -6.68554455e-02, -6.57372475e-02, -6.49458095e-02,\n",
       "       -6.44798651e-02, -6.42996728e-02, -6.43276498e-02, -6.44542873e-02,\n",
       "       -6.45441860e-02, -6.44467697e-02, -6.40051514e-02, -6.30676523e-02,\n",
       "       -6.14986904e-02, -5.91868982e-02, -5.60545176e-02, -5.20613007e-02,\n",
       "       -4.72091883e-02, -4.15415391e-02, -3.51426676e-02, -2.81321779e-02,\n",
       "       -2.06609294e-02, -1.29015287e-02, -5.04245516e-03,  2.72299210e-03,\n",
       "        1.02023892e-02,  1.72145814e-02,  2.35933661e-02,  2.91958489e-02,\n",
       "        3.39039490e-02,  3.76287065e-02,  4.03098464e-02,  4.19167653e-02,\n",
       "        4.24467325e-02,  4.19229344e-02,  4.03920971e-02,  3.79212163e-02,\n",
       "        3.45948339e-02,  3.05116028e-02,  2.57819630e-02,  2.05239784e-02,\n",
       "        1.48626408e-02,  8.92553199e-03,  2.84140045e-03, -3.26386979e-03,\n",
       "       -9.26731247e-03, -1.50547829e-02, -2.05204431e-02, -2.55720820e-02,\n",
       "       -3.01313624e-02, -3.41380052e-02, -3.75507064e-02, -4.03482914e-02,\n",
       "       -4.25302163e-02, -4.41167057e-02, -4.51469570e-02, -4.56771702e-02,\n",
       "       -4.57779057e-02, -4.55295779e-02, -4.50184532e-02, -4.43322659e-02,\n",
       "       -4.35553417e-02, -4.27644812e-02, -4.20244969e-02, -4.13859896e-02,\n",
       "       -4.08833139e-02, -4.05326113e-02, -4.03335877e-02, -4.02703732e-02,\n",
       "       -4.03138511e-02, -4.04255651e-02, -4.05610092e-02, -4.06745151e-02,\n",
       "       -4.07227091e-02, -4.06686328e-02, -4.04852331e-02, -4.01566550e-02,\n",
       "       -3.96794416e-02, -3.90638597e-02, -3.83312069e-02, -3.75128314e-02,\n",
       "       -3.66468541e-02, -3.57748270e-02, -3.49381790e-02, -3.41745876e-02,\n",
       "       -3.35152596e-02, -3.29814926e-02, -3.25839333e-02, -3.23213562e-02,\n",
       "       -3.21806930e-02, -3.21392864e-02, -3.21655758e-02, -3.22233066e-02,\n",
       "       -3.22741941e-02, -3.22805494e-02, -3.22100446e-02, -3.20368856e-02,\n",
       "       -3.17450836e-02, -3.13293524e-02, -3.07948105e-02, -3.01576145e-02,\n",
       "       -2.94422321e-02, -2.86800675e-02, -2.79061645e-02, -2.71565951e-02,\n",
       "       -2.64639072e-02, -2.58572940e-02, -2.53566597e-02, -2.49730870e-02,\n",
       "       -2.47073676e-02, -2.45506130e-02, -2.44838502e-02, -2.44811252e-02,\n",
       "       -2.45113242e-02, -2.45409068e-02, -2.45365854e-02, -2.44690441e-02,\n",
       "       -2.43144967e-02, -2.40575150e-02, -2.36918107e-02, -2.32204255e-02,\n",
       "       -2.26567797e-02, -2.20210496e-02, -2.13409457e-02, -2.06468161e-02,\n",
       "       -1.99707914e-02, -1.93428081e-02, -1.87888909e-02, -1.83280129e-02,\n",
       "       -1.79710984e-02, -1.77200101e-02, -1.75679289e-02, -1.74980909e-02,\n",
       "       -1.74890347e-02, -1.75123457e-02, -1.75382309e-02, -1.75368004e-02,\n",
       "       -1.74812526e-02, -1.73495244e-02, -1.71269719e-02, -1.68070421e-02,\n",
       "       -1.63918640e-02, -1.58924349e-02, -1.53265363e-02, -1.47186145e-02,\n",
       "       -1.40964575e-02, -1.34881688e-02, -1.29219079e-02, -1.24216285e-02,\n",
       "       -1.20044462e-02, -1.16813192e-02, -1.14547322e-02, -1.13185225e-02,\n",
       "       -1.12588629e-02, -1.12558166e-02, -1.12844771e-02, -1.13175577e-02,\n",
       "       -1.13278115e-02, -1.12905828e-02, -1.11853415e-02, -1.09979911e-02,\n",
       "       -1.07226586e-02, -1.03602437e-02, -9.92019475e-03, -9.41909850e-03,\n",
       "       -8.87799729e-03, -8.32258165e-03, -7.77878752e-03, -7.27242464e-03,\n",
       "       -6.82504149e-03, -6.45357044e-03, -6.16819086e-03, -5.97117376e-03,\n",
       "       -5.85787604e-03, -5.81597537e-03, -5.82679734e-03, -5.86894620e-03,\n",
       "       -5.91615075e-03, -5.94383338e-03, -5.92909707e-03, -5.85269881e-03,\n",
       "       -5.70190558e-03, -5.46988286e-03, -5.15802857e-03, -4.77443123e-03,\n",
       "       -4.33377596e-03, -3.85568151e-03, -3.36320116e-03, -2.88091158e-03,\n",
       "       -2.43221410e-03, -2.03743530e-03, -1.71197311e-03, -1.46603107e-03,\n",
       "       -1.30220712e-03, -1.21600262e-03, -1.19656033e-03, -1.22706231e-03,\n",
       "       -1.28679897e-03, -1.35284069e-03, -1.40178541e-03, -1.41224544e-03,\n",
       "       -1.36624579e-03, -1.25218637e-03, -1.06281915e-03, -7.99366098e-04,\n",
       "       -4.69260267e-04, -8.57363266e-05,  3.33085394e-04,  7.65886973e-04,\n",
       "        1.18980824e-03,  1.58350193e-03,  1.92749756e-03,  2.20688642e-03,\n",
       "        2.41268799e-03,  2.54217372e-03,  2.59903981e-03,  2.59338575e-03,\n",
       "        2.54058745e-03,  2.45940429e-03,  2.37222132e-03,  2.29994440e-03,\n",
       "        2.26307474e-03,  2.27785902e-03,  2.35653319e-03,  2.50458950e-03,\n",
       "        2.72193924e-03,  3.00184079e-03,  3.33177624e-03,  3.69518227e-03,\n",
       "        4.07196581e-03,  4.44132043e-03,  4.78237402e-03,  5.07793529e-03,\n",
       "        5.31322462e-03,  5.47985686e-03,  5.57490811e-03,  5.60196768e-03,\n",
       "        5.57033345e-03,  5.49395522e-03,  5.39090112e-03,  5.28115034e-03,\n",
       "        5.18511701e-03,  5.12162177e-03,  5.10609895e-03,  5.15041267e-03,\n",
       "        5.25951153e-03,  5.43360040e-03,  5.66638447e-03,  5.94670558e-03,\n",
       "        6.25833729e-03,  6.58325898e-03,  6.90148631e-03,  7.19377026e-03,\n",
       "        7.44329672e-03,  7.63671333e-03,  7.76566984e-03,  7.82776438e-03,\n",
       "        7.82540254e-03,  7.76809454e-03,  7.66813522e-03,  7.54281925e-03,\n",
       "        7.41084199e-03,  7.29148090e-03,  7.20231887e-03,  7.15830829e-03,\n",
       "        7.17005646e-03,  7.24304235e-03,  7.37702753e-03,  7.56653165e-03,\n",
       "        7.80093716e-03,  8.06580111e-03,  8.34284257e-03,  8.61413963e-03,\n",
       "        8.86138808e-03,  9.06848349e-03,  9.22319945e-03,  9.31733008e-03,\n",
       "        9.34817083e-03,  9.31843370e-03,  9.23634693e-03,  9.11426917e-03,\n",
       "        8.96803476e-03,  8.81527085e-03,  8.67405254e-03,  8.56089219e-03,\n",
       "        8.49050935e-03,  8.47282261e-03,  8.51289928e-03,  8.61065648e-03,\n",
       "        8.76117684e-03,  8.95416550e-03,  9.17611644e-03,  9.41017736e-03,\n",
       "        9.63910110e-03,  9.84548032e-03,  1.00144884e-02,  1.01338150e-02,\n",
       "        1.01960488e-02,  1.01986034e-02,  1.01439152e-02,  1.00396303e-02,\n",
       "        9.89741646e-03,  9.73215420e-03,  9.56043601e-03,  9.39967949e-03,\n",
       "        9.26577300e-03,  9.17199999e-03,  9.12780967e-03,  9.13875271e-03,\n",
       "        9.20452178e-03,  9.32046585e-03,  9.47694946e-03,  9.66099370e-03,\n",
       "        9.85706970e-03,  1.00484081e-02,  1.02187432e-02,  1.03537161e-02,\n",
       "        1.04419570e-02,  1.04760174e-02,  1.04537485e-02,  1.03771370e-02,\n",
       "        1.02533894e-02,  1.00934021e-02,  9.91185941e-03,  9.72432736e-03,\n",
       "        9.54675674e-03,  9.39492043e-03,  9.28097405e-03,  9.21441335e-03,\n",
       "        9.20020882e-03,  9.23820212e-03,  9.32418834e-03,  9.44884401e-03,\n",
       "        9.60003864e-03,  9.76297446e-03,  9.92167275e-03,  1.00605320e-02,\n",
       "        1.01660602e-02,  1.02274176e-02,  1.02375327e-02,  1.01940297e-02,\n",
       "        1.00990701e-02,  9.95929819e-03,  9.78515483e-03,  9.59046092e-03,\n",
       "        9.38993506e-03,  9.19923652e-03,  9.03271511e-03,  8.90254974e-03,\n",
       "        8.81771930e-03,  8.78272671e-03,  8.79763626e-03,  8.85829981e-03,\n",
       "        8.95647984e-03,  9.08005796e-03,  9.21483338e-03,  9.34529770e-03,\n",
       "        9.45826061e-03,  9.53909010e-03,  9.57794860e-03,  9.56830103e-03,\n",
       "        9.50750802e-03,  9.39785969e-03,  9.24552791e-03,  9.06066690e-03,\n",
       "        8.85603577e-03,  8.64589028e-03,  8.44552461e-03,  8.26826971e-03,\n",
       "        8.12568236e-03,  8.02640896e-03,  7.97487982e-03,  7.97174219e-03,\n",
       "        8.01206473e-03,  8.08819663e-03,  8.18887632e-03,  8.30098521e-03,\n",
       "        8.40930082e-03,  8.50034505e-03,  8.56128242e-03,  8.58222693e-03,\n",
       "        8.55719205e-03,  8.48323386e-03,  8.36319569e-03,  8.20191484e-03,\n",
       "        8.01000651e-03,  7.79933436e-03,  7.58372666e-03,  7.37712905e-03,\n",
       "        7.19282776e-03,  7.04204803e-03,  6.93296408e-03,  6.86949072e-03,\n",
       "        6.85211644e-03,  6.87724259e-03,  6.93616876e-03,  7.01945787e-03,\n",
       "        7.11324438e-03,  7.20381550e-03,  7.27792131e-03,  7.32356589e-03,\n",
       "        7.33135222e-03,  7.29477825e-03,  7.21205398e-03,  7.08485162e-03,\n",
       "        6.91885129e-03,  6.72327634e-03,  6.50973478e-03,  6.29172195e-03,\n",
       "        6.08241465e-03,  5.89511823e-03,  5.73959807e-03,  5.62446332e-03,\n",
       "        5.55333402e-03,  5.52638248e-03,  5.54034021e-03,  5.58719272e-03,\n",
       "        5.65685844e-03,  5.73709141e-03,  5.81471762e-03,  5.87666966e-03,\n",
       "        5.91132697e-03,  5.90997888e-03,  5.86621929e-03,  5.77831361e-03,\n",
       "        5.64749213e-03,  5.48040541e-03,  5.28455013e-03,  5.07202046e-03,\n",
       "        4.85535245e-03,  4.64733643e-03,  4.45985049e-03,  4.30379109e-03,\n",
       "        4.18630708e-03,  4.11129836e-03,  4.07894468e-03,  4.08571819e-03,\n",
       "        4.12456412e-03,  4.18564025e-03,  4.25674208e-03,  4.32570232e-03,\n",
       "        4.37949225e-03,  4.40753950e-03,  4.40069474e-03,  4.35357867e-03,\n",
       "        4.26402083e-03,  4.13374696e-03,  3.96841252e-03,  3.77602200e-03,\n",
       "        3.56749864e-03,  3.35511612e-03,  3.15107522e-03,  2.96776043e-03,\n",
       "        2.81411153e-03,  2.69780355e-03,  2.62268679e-03,  2.58851261e-03,\n",
       "        2.59232102e-03,  2.62695760e-03,  2.68287561e-03,  2.74886144e-03,\n",
       "        2.81266822e-03,  2.86242878e-03,  2.88707623e-03,  2.87836371e-03,\n",
       "        2.83131236e-03,  2.74379295e-03,  2.61645112e-03,  2.45619775e-03,\n",
       "        2.26970389e-03,  2.06799246e-03,  1.86292327e-03,  1.66594982e-03,\n",
       "        1.48901273e-03,  1.34092756e-03,  1.22890773e-03,  1.15649181e-03,\n",
       "        1.12411962e-03,  1.12812046e-03,  1.16194750e-03,  1.21674570e-03,\n",
       "        1.28085143e-03,  1.34309521e-03,  1.39185728e-03,  1.41660566e-03,\n",
       "        1.40946242e-03,  1.36506162e-03,  1.28198799e-03,  1.16118055e-03,\n",
       "        1.00785645e-03,  8.30108824e-04,  6.37691061e-04,  4.41919256e-04,\n",
       "        2.54813378e-04,  8.65015245e-05, -5.33981947e-05, -1.58499606e-04,\n",
       "       -2.25362717e-04, -2.53517937e-04, -2.46402691e-04, -2.10591126e-04,\n",
       "       -1.54639565e-04, -8.92751486e-05, -2.55326140e-05,  2.47886437e-05,\n",
       "        5.21381407e-05,  4.88838268e-05,  1.00533462e-05, -6.65884218e-05,\n",
       "       -1.78993141e-04, -3.22582840e-04, -4.89651167e-04, -6.70906797e-04,\n",
       "       -8.54867627e-04, -1.03079178e-03, -1.18806097e-03, -1.31799118e-03,\n",
       "       -1.41398574e-03, -1.47296069e-03, -1.49459776e-03, -1.48241920e-03,\n",
       "       -1.44188164e-03, -1.38212938e-03, -1.31329359e-03, -1.24620122e-03,\n",
       "       -1.19194854e-03, -1.15930277e-03, -1.15648890e-03, -1.18831417e-03,\n",
       "       -1.25644077e-03, -1.35871419e-03, -1.49122439e-03, -1.64631463e-03,\n",
       "       -1.81455840e-03, -1.98579719e-03, -2.14898959e-03, -2.29372573e-03,\n",
       "       -2.41222582e-03, -2.49749352e-03, -2.54701613e-03, -2.56036548e-03,\n",
       "       -2.54103006e-03, -2.49431003e-03, -2.42907321e-03, -2.35488103e-03,\n",
       "       -2.28260830e-03, -2.22227536e-03, -2.18362547e-03, -2.17362843e-03,\n",
       "       -2.19650241e-03, -2.25437712e-03, -2.34599411e-03, -2.46609631e-03,\n",
       "       -2.60802079e-03, -2.76253070e-03, -2.91993003e-03, -3.06925760e-03,\n",
       "       -3.20037617e-03, -3.30605358e-03, -3.37984180e-03, -3.41892499e-03,\n",
       "       -3.42308148e-03, -3.39508196e-03, -3.34124430e-03, -3.26912059e-03,\n",
       "       -3.18860705e-03, -3.10973544e-03, -3.04275798e-03, -2.99651898e-03,\n",
       "       -2.97777308e-03, -2.99116550e-03, -3.03875771e-03, -3.11823003e-03,\n",
       "       -3.22563667e-03, -3.35385371e-03, -3.49450135e-03, -3.63722933e-03,\n",
       "       -3.77207412e-03, -3.88973602e-03, -3.98228830e-03, -4.04405640e-03,\n",
       "       -4.07192577e-03, -4.06616321e-03, -4.02909564e-03, -3.96703556e-03,\n",
       "       -3.88751831e-03, -3.79986363e-03, -3.71390698e-03, -3.63941281e-03,\n",
       "       -3.58506851e-03, -3.55767016e-03, -3.56133445e-03, -3.59769096e-03,\n",
       "       -3.66538297e-03, -3.75965168e-03, -3.87442368e-03, -4.00065491e-03,\n",
       "       -4.12915694e-03, -4.24977858e-03, -4.35397401e-03, -4.43315785e-03,\n",
       "       -4.48283553e-03, -4.49954765e-03, -4.48349956e-03, -4.43739071e-03,\n",
       "       -4.36721835e-03, -4.27971035e-03, -4.18499159e-03, -4.09175502e-03,\n",
       "       -4.00974182e-03, -3.94721841e-03, -3.91075201e-03, -3.90482950e-03,\n",
       "       -3.93058546e-03, -3.98640241e-03, -4.06793458e-03, -4.16922709e-03,\n",
       "       -4.28204425e-03, -4.39627934e-03, -4.50315885e-03, -4.59355861e-03,\n",
       "       -4.66049416e-03, -4.69812099e-03, -4.70364559e-03, -4.67826426e-03,\n",
       "       -4.62325290e-03, -4.54486348e-03, -4.45020339e-03, -4.34822636e-03,\n",
       "       -4.24786797e-03, -4.15872410e-03, -4.08869190e-03, -4.04420495e-03,\n",
       "       -4.02877200e-03, -4.04453510e-03, -4.08917246e-03, -4.15919721e-03,\n",
       "       -4.24803933e-03, -4.34756093e-03, -4.44919569e-03, -4.54315869e-03,\n",
       "       -4.62125428e-03, -4.67599183e-03, -4.70297458e-03, -4.69869608e-03,\n",
       "       -4.66363179e-03, -4.60061524e-03, -4.51518828e-03, -4.41371836e-03,\n",
       "       -4.30511963e-03, -4.19862848e-03, -4.10321122e-03, -4.02627699e-03,\n",
       "       -3.97393992e-03, -3.95040028e-03, -3.95684596e-03, -3.99170909e-03,\n",
       "       -4.05084249e-03, -4.12847148e-03, -4.21598181e-03, -4.30561602e-03,\n",
       "       -4.38805623e-03, -4.45465883e-03, -4.49852971e-03, -4.51552868e-03,\n",
       "       -4.50224336e-03, -4.45891777e-03, -4.38904017e-03, -4.29651514e-03,\n",
       "       -4.18951362e-03, -4.07545315e-03, -3.96352913e-03, -3.86244268e-03,\n",
       "       -3.77960992e-03, -3.72097199e-03, -3.69021227e-03, -3.68848233e-03,\n",
       "       -3.71447508e-03, -3.76426568e-03, -3.83163989e-03, -3.90916597e-03,\n",
       "       -3.98824085e-03, -4.06030426e-03, -4.11686068e-03, -4.15176619e-03,\n",
       "       -4.15992504e-03, -4.13920311e-03, -4.08938061e-03, -4.01315745e-03,\n",
       "       -3.91588220e-03, -3.80423455e-03, -3.68607510e-03, -3.57023557e-03,\n",
       "       -3.46496492e-03, -3.37766367e-03, -3.31392582e-03, -3.27747338e-03,\n",
       "       -3.26901465e-03, -3.28792608e-03, -3.32929054e-03, -3.38862790e-03,\n",
       "       -3.45736556e-03, -3.52727971e-03, -3.59053980e-03, -3.63867753e-03,\n",
       "       -3.66581883e-03, -3.66719300e-03, -3.63972900e-03, -3.58472834e-03,\n",
       "       -3.50417173e-03, -3.40300030e-03, -3.28795286e-03, -3.16736032e-03,\n",
       "       -3.04866815e-03, -2.94076372e-03, -2.85009760e-03, -2.78287404e-03,\n",
       "       -2.74206139e-03, -2.72907177e-03, -2.74216221e-03, -2.77759763e-03,\n",
       "       -2.82986392e-03, -2.89155263e-03, -2.95464485e-03, -3.01056379e-03,\n",
       "       -3.05206887e-03, -3.07328464e-03, -3.06904665e-03, -3.03777470e-03,\n",
       "       -2.97850347e-03, -2.89488933e-03, -2.79197446e-03, -2.67521827e-03,\n",
       "       -2.55276007e-03, -2.43331539e-03, -2.32387544e-03, -2.23189429e-03,\n",
       "       -2.16251542e-03, -2.11916491e-03, -2.10240879e-03, -2.11155554e-03,\n",
       "       -2.14268640e-03, -2.18957965e-03, -2.24600406e-03, -2.30358914e-03,\n",
       "       -2.35429569e-03, -2.39087711e-03, -2.40721530e-03, -2.39935727e-03,\n",
       "       -2.36453116e-03, -2.30362546e-03, -2.21884460e-03, -2.11471645e-03,\n",
       "       -1.99780869e-03, -1.87584327e-03, -1.75637007e-03, -1.64723850e-03,\n",
       "       -1.55497272e-03, -1.48529105e-03, -1.44059490e-03, -1.42257370e-03,\n",
       "       -1.42937619e-03, -1.45770202e-03, -1.50156126e-03, -1.55390496e-03,\n",
       "       -1.60796172e-03, -1.65532285e-03, -1.68841542e-03, -1.70281564e-03,\n",
       "       -1.69231836e-03, -1.65632414e-03, -1.59469491e-03, -1.50999345e-03,\n",
       "       -1.40686170e-03, -1.29141274e-03, -1.17116142e-03, -1.05341210e-03,\n",
       "       -9.45973152e-04, -8.55266815e-04, -7.86556455e-04, -7.42648903e-04,\n",
       "       -7.24460580e-04, -7.30509637e-04, -7.56951398e-04, -7.98965048e-04,\n",
       "       -8.49718868e-04, -9.01517749e-04, -9.46427870e-04, -9.78306867e-04,\n",
       "       -9.90657136e-04, -9.79901291e-04, -9.43933788e-04, -8.82854278e-04,\n",
       "       -7.99861562e-04, -6.98797288e-04, -5.86160750e-04, -4.68533020e-04,\n",
       "       -3.54399905e-04, -2.49682955e-04, -1.62276017e-04, -9.61047190e-05,\n",
       "       -5.38434033e-05, -3.71347051e-05, -4.38953539e-05, -7.10718377e-05,\n",
       "       -1.12668007e-04, -1.62949116e-04, -2.14163854e-04, -2.58773856e-04,\n",
       "       -2.90252035e-04, -3.03299923e-04, -2.93638499e-04, -2.58784246e-04,\n",
       "       -2.00414506e-04, -1.20524317e-04, -2.26554748e-05,  8.57558334e-05,\n",
       "        1.98909300e-04,  3.09110677e-04,  4.08846681e-04,  4.92630003e-04,\n",
       "        5.55209932e-04,  5.93963428e-04,  6.08146656e-04,  5.99179417e-04,\n",
       "        5.70943928e-04,  5.27704484e-04,  4.76721616e-04,  4.25036298e-04,\n",
       "        3.79367557e-04,  3.46730463e-04,  3.32338706e-04,  3.40459344e-04,\n",
       "        3.72164155e-04,  4.27543360e-04,  5.03651041e-04,  5.96824626e-04,\n",
       "        7.00602017e-04,  8.08254350e-04,  9.13365162e-04,  1.00776285e-03,\n",
       "        1.08658965e-03,  1.14435959e-03,  1.17912062e-03,  1.18982128e-03,\n",
       "        1.17783085e-03,  1.14682072e-03,  1.10169279e-03,  1.04878657e-03,\n",
       "        9.95161245e-04,  9.47823573e-04,  9.13351658e-04,  8.96420039e-04,\n",
       "        9.01324849e-04,  9.29070229e-04,  9.79993842e-04,  1.05158449e-03,\n",
       "        1.13907235e-03,  1.23703433e-03,  1.33842381e-03,  1.43723062e-03,\n",
       "        1.52578647e-03,  1.59820146e-03,  1.65076554e-03,  1.68024295e-03,\n",
       "        1.68663159e-03,  1.67066976e-03,  1.63565867e-03,  1.58777216e-03,\n",
       "        1.53228187e-03,  1.47589704e-03,  1.42557442e-03,  1.38784479e-03,\n",
       "        1.36808888e-03,  1.36924104e-03,  1.39271747e-03,  1.43888302e-03,\n",
       "        1.50451635e-03,  1.58592290e-03,  1.67759974e-03,  1.77236367e-03,\n",
       "        1.86396122e-03,  1.94592623e-03,  2.01221695e-03,  2.05895794e-03,\n",
       "        2.08259467e-03,  2.08346220e-03,  2.06305785e-03,  2.02446338e-03,\n",
       "        1.97237334e-03,  1.91370677e-03,  1.85387291e-03,  1.80058694e-03,\n",
       "        1.75951701e-03,  1.73559599e-03,  1.73234195e-03,  1.75122090e-03,\n",
       "        1.79187616e-03,  1.85156683e-03,  1.92667579e-03,  2.01126025e-03,\n",
       "        2.09911377e-03,  2.18402292e-03,  2.25855014e-03,  2.31794477e-03,\n",
       "        2.35780491e-03,  2.37604859e-03,  2.37179617e-03,  2.34651193e-03,\n",
       "        2.30320147e-03,  2.24718498e-03,  2.18412955e-03,  2.12153839e-03,\n",
       "        2.06451770e-03,  2.01971387e-03,  1.99185242e-03,  1.98384328e-03,\n",
       "        1.99748785e-03,  2.03261292e-03,  2.08641449e-03,  2.15489091e-03,\n",
       "        2.23247055e-03,  2.31362786e-03,  2.39109341e-03,  2.45860568e-03,\n",
       "        2.51126569e-03,  2.54480680e-03,  2.55694380e-03,  2.54657865e-03,\n",
       "        2.51654186e-03,  2.46967911e-03,  2.40935083e-03,  2.34275474e-03,\n",
       "        2.27585481e-03,  2.21515656e-03,  2.16651079e-03,  2.13443767e-03,\n",
       "        2.12202454e-03,  2.13067210e-03,  2.16016034e-03,  2.20763660e-03,\n",
       "        2.26974930e-03,  2.34084716e-03,  2.41463259e-03,  2.48490227e-03,\n",
       "        2.54557352e-03,  2.59131915e-03,  2.61838944e-03,  2.62454082e-03,\n",
       "        2.60951929e-03,  2.57400027e-03,  2.52199289e-03,  2.45820126e-03,\n",
       "        2.38800747e-03,  2.31756107e-03,  2.25321669e-03,  2.20082072e-03,\n",
       "        2.16487562e-03,  2.14781146e-03,  2.15204363e-03,  2.17622123e-03,\n",
       "        2.21824367e-03,  2.27435399e-03,  2.33870652e-03,  2.40578828e-03,\n",
       "        2.46941531e-03,  2.52378546e-03,  2.56333081e-03,  2.58446345e-03,\n",
       "        2.58508348e-03,  2.56490079e-03,  2.52492749e-03,  2.46911193e-03,\n",
       "        2.40149582e-03,  2.32776930e-03,  2.25405116e-03,  2.18684948e-03,\n",
       "        2.13082344e-03,  2.09128740e-03,  2.07092613e-03,  2.07018014e-03,\n",
       "        2.08960706e-03,  2.12631910e-03,  2.17661844e-03,  2.23494857e-03,\n",
       "        2.29600538e-03,  2.35356879e-03,  2.40157242e-03,  2.43544276e-03,\n",
       "        2.45100050e-03,  2.44674226e-03,  2.42180168e-03,  2.37867981e-03,\n",
       "        2.31892755e-03,  2.24825321e-03,  2.17164401e-03,  2.09502969e-03,\n",
       "        2.02519703e-03,  1.96678308e-03,  1.92432769e-03,  1.90022669e-03,\n",
       "        1.89600361e-03,  1.91106112e-03,  1.94319920e-03,  1.98848592e-03,\n",
       "        2.04169215e-03,  2.09737592e-03,  2.14922545e-03,  2.19206698e-03,\n",
       "        2.22079433e-03,  2.23181630e-03,  2.22299853e-03,  2.19425326e-03,\n",
       "        2.14739027e-03,  2.08497536e-03,  2.01175618e-03,  1.93309493e-03,\n",
       "        1.85466302e-03,  1.78248214e-03,  1.72167784e-03,  1.67656504e-03,\n",
       "        1.64994074e-03,  1.64269016e-03,  1.65444368e-03,  1.68267742e-03,\n",
       "        1.72360858e-03,  1.77258346e-03,  1.82345940e-03,  1.87067944e-03,\n",
       "        1.90902082e-03,  1.93330029e-03,  1.94017251e-03,  1.92825869e-03,\n",
       "        1.89660804e-03,  1.84680789e-03,  1.78196444e-03,  1.70758599e-03,\n",
       "        1.62728271e-03,  1.54773390e-03,  1.47443532e-03,  1.41236442e-03,\n",
       "        1.36567105e-03,  1.33704324e-03,  1.32775214e-03,  1.33675954e-03,\n",
       "        1.36175100e-03,  1.39967469e-03,  1.44474627e-03,  1.49179180e-03,\n",
       "        1.53583463e-03,  1.57016120e-03,  1.59099663e-03,  1.59502053e-03,\n",
       "        1.58003869e-03,  1.54606323e-03,  1.49493397e-03,  1.42884860e-03,\n",
       "        1.35298993e-03,  1.27228443e-03,  1.19225134e-03,  1.11834286e-03,\n",
       "        1.05561165e-03,  1.00841175e-03,  9.78658907e-04,  9.67818778e-04,\n",
       "        9.75284260e-04,  9.98350792e-04,  1.03349041e-03,  1.07598992e-03,\n",
       "        1.12055033e-03,  1.16096414e-03,  1.19291176e-03,  1.21148839e-03,\n",
       "        1.21322344e-03,  1.19630352e-03,  1.16147811e-03,  1.10923487e-03,\n",
       "        1.04299199e-03,  9.66976164e-04,  8.86477355e-04,  8.06699623e-04,\n",
       "        7.33015535e-04,  6.70878566e-04,  6.23811735e-04,  5.93707839e-04,\n",
       "        5.82493609e-04,  5.88950119e-04,  6.10971299e-04,  6.44352112e-04,\n",
       "        6.85107778e-04,  7.27559847e-04,  7.65906589e-04,  7.96330860e-04,\n",
       "        8.13171908e-04,  8.13667430e-04,  7.96011300e-04,  7.60293624e-04,\n",
       "        7.08407839e-04,  6.42477185e-04,  5.67109440e-04,  4.87775251e-04,\n",
       "        4.09276981e-04,  3.37291625e-04,  2.76025996e-04,  2.29545985e-04,\n",
       "        2.00727329e-04,  1.89357932e-04,  1.95578716e-04,  2.17333727e-04,\n",
       "        2.49705539e-04,  2.90034252e-04,  3.31277522e-04,  3.68917041e-04,\n",
       "        3.98005504e-04,  4.14185459e-04,  4.13999805e-04,  3.96612624e-04,\n",
       "        3.61094979e-04,  3.10009142e-04,  2.45002651e-04,  1.71405933e-04,\n",
       "        9.37843797e-05,  1.69555587e-05, -5.34566971e-05, -1.12605725e-04,\n",
       "       -1.57066184e-04, -1.85095385e-04, -1.95041212e-04, -1.87616562e-04,\n",
       "       -1.65538033e-04, -1.33048336e-04, -9.30505921e-05, -5.18157540e-05,\n",
       "       -1.43522848e-05,  1.45530494e-05,  3.07103219e-05,  3.09146963e-05,\n",
       "        1.43791140e-05, -1.99043388e-05, -6.99414595e-05, -1.32402900e-04,\n",
       "       -2.03808013e-04, -2.79112806e-04, -3.52934730e-04, -4.20878670e-04,\n",
       "       -4.77802852e-04, -5.19708265e-04, -5.44994953e-04, -5.53468359e-04,\n",
       "       -5.44814218e-04, -5.21840993e-04, -4.87843587e-04, -4.47827886e-04,\n",
       "       -4.06071456e-04, -3.67906818e-04, -3.38542130e-04, -3.21741536e-04,\n",
       "       -3.20225576e-04, -3.35824589e-04, -3.68061126e-04, -4.16283234e-04,\n",
       "       -4.76070505e-04, -5.44639246e-04, -6.16699923e-04, -6.87173218e-04,\n",
       "       -7.51742919e-04, -8.05387390e-04, -8.44745431e-04, -8.67538911e-04,\n",
       "       -8.73297220e-04, -8.62787827e-04, -8.37925647e-04, -8.02498485e-04,\n",
       "       -7.61246250e-04, -7.18985451e-04, -6.79555931e-04, -6.48815650e-04,\n",
       "       -6.30899798e-04, -6.27553207e-04, -6.41302380e-04, -6.71075657e-04,\n",
       "       -7.16427283e-04, -7.73311069e-04, -8.38420237e-04, -9.07012320e-04,\n",
       "       -9.74401017e-04, -1.03497470e-03, -1.08472444e-03, -1.12074416e-03,\n",
       "       -1.14037981e-03, -1.14357763e-03, -1.13008602e-03, -1.10341050e-03,\n",
       "       -1.06600509e-03, -1.02288451e-03, -9.78909200e-04, -9.37977107e-04,\n",
       "       -9.06132860e-04, -8.86146561e-04, -8.81172018e-04, -8.92151147e-04,\n",
       "       -9.19404498e-04, -9.61348298e-04, -1.01525604e-03, -1.07673695e-03,\n",
       "       -1.14126375e-03, -1.20422314e-03, -1.26076839e-03, -1.30674907e-03,\n",
       "       -1.33881392e-03, -1.35515269e-03, -1.35464908e-03, -1.33900926e-03,\n",
       "       -1.30933174e-03, -1.26992690e-03, -1.22480455e-03, -1.17830141e-03,\n",
       "       -1.13620039e-03, -1.10190629e-03, -1.08022161e-03, -1.07271189e-03,\n",
       "       -1.08103163e-03, -1.10564171e-03, -1.14424212e-03, -1.19418697e-03,\n",
       "       -1.25181209e-03, -1.31245260e-03, -1.37110834e-03, -1.42366881e-03,\n",
       "       -1.46531791e-03, -1.49358623e-03, -1.50631845e-03, -1.50252692e-03,\n",
       "       -1.48378476e-03, -1.45148765e-03, -1.40944775e-03, -1.36185542e-03,\n",
       "       -1.31386181e-03, -1.26959872e-03, -1.23352301e-03, -1.20913517e-03,\n",
       "       -1.19947549e-03, -1.20502186e-03, -1.22674508e-03, -1.26147678e-03,\n",
       "       -1.30769110e-03, -1.36143330e-03, -1.41737028e-03, -1.47186464e-03,\n",
       "       -1.52048864e-03, -1.55794306e-03, -1.58201111e-03, -1.59103400e-03,\n",
       "       -1.58372649e-03, -1.56199711e-03, -1.52749266e-03, -1.48243667e-03,\n",
       "       -1.43299310e-03, -1.38286932e-03, -1.33643602e-03, -1.29848288e-03,\n",
       "       -1.27160084e-03, -1.25928130e-03, -1.26234151e-03, -1.28067832e-03,\n",
       "       -1.31219660e-03, -1.35508180e-03, -1.40469882e-03, -1.45684986e-03,\n",
       "       -1.50749949e-03, -1.55109598e-03, -1.58457283e-03, -1.60531129e-03,\n",
       "       -1.61081506e-03, -1.59980392e-03, -1.57486834e-03, -1.53750647e-03,\n",
       "       -1.49097003e-03, -1.43877720e-03, -1.38669461e-03, -1.33823906e-03,\n",
       "       -1.29790127e-03, -1.26960315e-03, -1.25520758e-03, -1.25512516e-03,\n",
       "       -1.27078767e-03, -1.29920465e-03, -1.33819703e-03, -1.38414826e-03,\n",
       "       -1.43263058e-03, -1.47892768e-03, -1.51913252e-03, -1.54885068e-03,\n",
       "       -1.56548340e-03, -1.56748050e-03, -1.55387970e-03, -1.52598729e-03,\n",
       "       -1.48603937e-03, -1.43732154e-03, -1.38378236e-03, -1.32941315e-03,\n",
       "       -1.27940427e-03, -1.23708544e-03, -1.20628008e-03, -1.18999381e-03,\n",
       "       -1.18790637e-03, -1.20041089e-03, -1.22602284e-03, -1.26225338e-03,\n",
       "       -1.30431820e-03, -1.34899700e-03, -1.39193179e-03, -1.42794161e-03,\n",
       "       -1.45437790e-03, -1.46767276e-03, -1.46647729e-03, -1.45029626e-03,\n",
       "       -1.42001570e-03, -1.37801503e-03, -1.32757192e-03, -1.27220212e-03,\n",
       "       -1.21635862e-03, -1.16518827e-03, -1.12138456e-03, -1.08979177e-03,\n",
       "       -1.07108359e-03, -1.06728077e-03, -1.07771042e-03, -1.10080268e-03,\n",
       "       -1.13367673e-03, -1.17368402e-03, -1.21505128e-03, -1.25482748e-03,\n",
       "       -1.28778722e-03, -1.31101022e-03, -1.32140412e-03, -1.31762656e-03,\n",
       "       -1.29913841e-03, -1.26695493e-03, -1.22350955e-03, -1.17086899e-03,\n",
       "       -1.11453119e-03, -1.05755718e-03, -1.00539310e-03, -9.60804755e-04,\n",
       "       -9.27402172e-04, -9.07602429e-04, -9.01833759e-04, -9.10615316e-04,\n",
       "       -9.31341259e-04, -9.61868907e-04, -9.98849981e-04, -1.03805738e-03,\n",
       "       -1.07457826e-03, -1.10486848e-03, -1.12541264e-03, -1.13346777e-03,\n",
       "       -1.12733117e-03, -1.10668561e-03, -1.07278826e-03, -1.02785171e-03,\n",
       "       -9.74678260e-04, -9.17620782e-04, -8.60057131e-04, -8.07069940e-04,\n",
       "       -7.61924079e-04, -7.28100771e-04, -7.07302126e-04, -7.01102952e-04,\n",
       "       -7.07591709e-04, -7.27072242e-04, -7.55798654e-04, -7.90447521e-04,\n",
       "       -8.27396521e-04, -8.61710694e-04, -8.89685354e-04, -9.08269372e-04,\n",
       "       -9.14460630e-04, -9.06823028e-04, -8.85162852e-04, -8.50305718e-04,\n",
       "       -8.04464449e-04, -7.51188491e-04, -6.93689741e-04, -6.36545999e-04,\n",
       "       -5.83215035e-04, -5.37951943e-04, -5.04134921e-04, -4.82994830e-04,\n",
       "       -4.75931127e-04, -4.82315314e-04, -5.00586524e-04, -5.28134988e-04,\n",
       "       -5.61385008e-04, -5.96419268e-04, -6.29089132e-04, -6.55930606e-04,\n",
       "       -6.72783703e-04, -6.77355507e-04, -6.68685418e-04, -6.46230124e-04,\n",
       "       -6.10807969e-04, -5.64474612e-04, -5.11273334e-04, -4.53873101e-04,\n",
       "       -3.97125958e-04, -3.44277243e-04, -2.99542211e-04, -2.65677663e-04,\n",
       "       -2.44873198e-04, -2.37604138e-04, -2.43245668e-04, -2.61204696e-04,\n",
       "       -2.87731586e-04, -3.19851591e-04, -3.53765528e-04, -3.85235122e-04,\n",
       "       -4.10869281e-04, -4.26479441e-04, -4.30394197e-04, -4.21115634e-04,\n",
       "       -3.97947588e-04, -3.62935185e-04, -3.17133177e-04, -2.64234695e-04,\n",
       "       -2.07750636e-04, -1.51861313e-04, -9.99414260e-05, -5.59956607e-05,\n",
       "       -2.29368034e-05, -2.90138928e-06,  3.78335812e-06, -2.37465429e-06,\n",
       "       -1.96592937e-05, -4.65019584e-05, -7.82900825e-05, -1.11856687e-04,\n",
       "       -1.42303281e-04, -1.67249091e-04, -1.82593270e-04, -1.86331294e-04,\n",
       "       -1.77109439e-04, -1.54539171e-04, -1.18926589e-04, -7.45900470e-05,\n",
       "       -2.29309862e-05,  3.29803479e-05,  8.73907848e-05,  1.37621086e-04,\n",
       "        1.80465970e-04,  2.12037892e-04,  2.31149592e-04,  2.36539694e-04,\n",
       "        2.29974175e-04,  2.12053783e-04,  1.85158977e-04,  1.53381741e-04,\n",
       "        1.20050034e-04,  8.89618459e-05,  6.46605695e-05,  4.88660480e-05,\n",
       "        4.51789201e-05,  5.40818619e-05,  7.60244511e-05,  1.09753200e-04,\n",
       "        1.53121291e-04,  2.03783216e-04,  2.57154024e-04,  3.10520001e-04,\n",
       "        3.59309866e-04,  3.99688754e-04,  4.29724751e-04,  4.47331986e-04,\n",
       "        4.51984029e-04,  4.44084581e-04,  4.25137056e-04,  3.98200849e-04,\n",
       "        3.65901971e-04,  3.32228810e-04,  3.00856133e-04,  2.76355946e-04,\n",
       "        2.60084315e-04,  2.55934981e-04,  2.64420902e-04,  2.84966663e-04,\n",
       "        3.17556580e-04,  3.59911646e-04,  4.08428226e-04,  4.59834730e-04,\n",
       "        5.10722806e-04,  5.57282532e-04,  5.95298188e-04,  6.23396889e-04,\n",
       "        6.39230886e-04,  6.42127707e-04,  6.32803189e-04,  6.12256583e-04,\n",
       "        5.83929592e-04,  5.51466539e-04,  5.16770291e-04,  4.85219003e-04,\n",
       "        4.59245231e-04,  4.42831777e-04,  4.37378767e-04,  4.44146746e-04,\n",
       "        4.63563163e-04,  4.95101616e-04,  5.34859020e-04,  5.81204251e-04,\n",
       "        6.30294904e-04,  6.78847544e-04,  7.22408935e-04,  7.58833950e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scattering_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19524"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "num_tokens = len(encoding.encode(str(scattering_files[0])))\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scattering_files[0].round(3)[::15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "num_tokens = len(encoding.encode(str(scattering_files[0].round(3)[::15])))\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering_patterns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(scattering_files)):\n",
    "    pattern = scattering_files[i].round(3)[::15]\n",
    "    scattering_patterns.append(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scattering_patterns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare clasification dataset for structure type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering_patterns = np.array(scattering_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "encoded_structure_types = le.fit_transform(structure_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = {i: np.where(encoded_structure_types == i)[0] for i in np.unique(encoded_structure_types)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([   5,   41,   50,   57,   68,   69,   77,   83,   86,   92,  104,\n",
       "         105,  115,  118,  120,  124,  128,  137,  141,  146,  155,  168,\n",
       "         179,  188,  193,  203,  222,  235,  253,  265,  268,  270,  275,\n",
       "         292,  317,  366,  378,  382,  390,  394,  395,  403,  413,  417,\n",
       "         463,  488,  502,  516,  526,  540,  548,  552,  581,  582,  601,\n",
       "         611,  612,  619,  635,  639,  643,  653,  656,  667,  677,  682,\n",
       "         697,  700,  711,  713,  717,  722,  724,  730,  732,  753,  755,\n",
       "         764,  776,  811,  816,  831,  837,  843,  849,  855,  868,  885,\n",
       "         898,  911,  917,  926,  934,  964,  971,  977,  989,  997, 1004,\n",
       "        1006, 1010, 1011, 1019, 1023, 1034, 1038, 1039, 1042, 1046, 1058,\n",
       "        1062, 1069, 1097, 1098, 1109, 1120, 1127, 1146, 1154, 1157, 1159,\n",
       "        1164, 1180, 1183, 1184, 1188, 1209, 1213, 1221, 1234, 1238, 1243,\n",
       "        1257, 1264, 1299, 1310, 1314, 1327, 1342, 1367, 1373, 1389, 1395,\n",
       "        1410, 1419, 1429, 1448, 1455, 1472, 1473, 1478, 1503, 1522, 1523,\n",
       "        1527, 1528, 1549, 1551, 1560, 1562, 1564, 1566, 1572, 1573, 1580,\n",
       "        1596, 1609, 1612, 1613, 1616, 1632, 1633, 1637, 1646, 1666, 1667,\n",
       "        1669, 1672, 1673, 1679, 1681, 1713, 1717, 1721, 1728, 1732, 1755,\n",
       "        1771, 1780, 1790, 1792, 1823, 1831, 1851, 1867, 1871, 1876, 1877,\n",
       "        1889, 1896, 1903, 1905, 1918, 1932, 1937, 1938, 1939, 1942, 1954]),\n",
       " 1: array([   4,    9,   25,   26,   27,   38,   39,   43,   45,   52,   56,\n",
       "          58,   59,   78,   80,   87,   91,   96,   99,  103,  121,  132,\n",
       "         163,  164,  165,  172,  174,  177,  178,  180,  184,  190,  191,\n",
       "         194,  197,  211,  213,  223,  225,  226,  236,  257,  258,  261,\n",
       "         274,  282,  287,  294,  295,  299,  304,  311,  326,  328,  337,\n",
       "         338,  344,  353,  354,  367,  373,  396,  398,  401,  402,  408,\n",
       "         415,  416,  434,  436,  439,  445,  452,  455,  465,  466,  468,\n",
       "         478,  480,  481,  483,  489,  493,  496,  497,  518,  521,  522,\n",
       "         535,  554,  556,  557,  563,  575,  587,  589,  593,  605,  610,\n",
       "         618,  621,  623,  633,  647,  648,  654,  655,  668,  685,  693,\n",
       "         705,  707,  708,  710,  715,  718,  723,  725,  729,  736,  740,\n",
       "         746,  752,  759,  761,  771,  777,  784,  786,  791,  792,  805,\n",
       "         806,  807,  810,  814,  820,  821,  822,  824,  825,  838,  851,\n",
       "         854,  866,  876,  877,  880,  889,  894,  900,  901,  906,  912,\n",
       "         913,  915,  935,  939,  947,  948,  949,  951,  953,  962,  969,\n",
       "         973,  987,  990,  993,  995,  996,  998, 1002, 1030, 1032, 1037,\n",
       "        1043, 1045, 1047, 1061, 1066, 1068, 1073, 1075, 1076, 1078, 1080,\n",
       "        1093, 1095, 1102, 1105, 1107, 1113, 1115, 1128, 1130, 1143, 1160,\n",
       "        1167, 1169, 1171, 1173, 1177, 1186, 1193, 1203, 1205, 1207, 1242,\n",
       "        1252, 1254, 1255, 1262, 1267, 1271, 1272, 1275, 1287, 1289, 1290,\n",
       "        1295, 1296, 1298, 1300, 1301, 1305, 1316, 1328, 1348, 1352, 1370,\n",
       "        1376, 1388, 1408, 1411, 1416, 1417, 1421, 1424, 1428, 1431, 1432,\n",
       "        1434, 1439, 1443, 1449, 1451, 1457, 1468, 1470, 1482, 1485, 1488,\n",
       "        1494, 1495, 1497, 1498, 1514, 1517, 1520, 1534, 1537, 1541, 1542,\n",
       "        1554, 1556, 1558, 1563, 1567, 1581, 1583, 1584, 1594, 1598, 1601,\n",
       "        1605, 1606, 1617, 1620, 1622, 1626, 1627, 1628, 1647, 1651, 1656,\n",
       "        1658, 1662, 1668, 1676, 1682, 1683, 1684, 1694, 1699, 1704, 1708,\n",
       "        1709, 1720, 1722, 1727, 1736, 1747, 1749, 1752, 1757, 1768, 1774,\n",
       "        1785, 1787, 1788, 1795, 1803, 1807, 1809, 1810, 1817, 1822, 1824,\n",
       "        1830, 1837, 1844, 1848, 1855, 1857, 1860, 1874, 1879, 1892, 1898,\n",
       "        1909, 1910, 1915, 1924, 1930, 1935, 1936, 1947, 1949, 1950, 1951,\n",
       "        1955]),\n",
       " 2: array([   6,   14,   63,   73,   89,   93,  123,  219,  361,  381,  443,\n",
       "         446,  456,  473,  485,  504,  577,  591,  616,  646,  650,  659,\n",
       "         679,  691,  694,  731,  735,  762,  793,  798,  841,  847,  848,\n",
       "         872,  910,  921,  928,  936,  942,  961,  981, 1015, 1022, 1026,\n",
       "        1052, 1057, 1060, 1067, 1070, 1083, 1092, 1096, 1110, 1111, 1135,\n",
       "        1156, 1166, 1224, 1261, 1263, 1266, 1270, 1319, 1326, 1340, 1341,\n",
       "        1345, 1354, 1358, 1360, 1403, 1413, 1447, 1474, 1490, 1491, 1500,\n",
       "        1507, 1512, 1531, 1538, 1574, 1582, 1592, 1661, 1692, 1723, 1745,\n",
       "        1759, 1818, 1841, 1872, 1887, 1921, 1952]),\n",
       " 3: array([   1,    7,    8,   10,   11,   12,   15,   19,   20,   22,   23,\n",
       "          28,   30,   31,   32,   33,   34,   35,   36,   37,   40,   44,\n",
       "          46,   47,   48,   49,   53,   54,   60,   61,   62,   64,   65,\n",
       "          67,   71,   72,   75,   79,   82,   85,   88,   90,   94,   95,\n",
       "          97,   98,  100,  101,  108,  109,  110,  111,  112,  113,  119,\n",
       "         122,  125,  126,  129,  131,  133,  134,  135,  136,  138,  139,\n",
       "         140,  142,  143,  144,  145,  147,  148,  149,  150,  151,  152,\n",
       "         153,  154,  156,  157,  158,  159,  160,  161,  162,  166,  167,\n",
       "         169,  173,  175,  181,  183,  186,  187,  189,  192,  195,  196,\n",
       "         198,  199,  201,  202,  204,  205,  206,  207,  208,  209,  210,\n",
       "         212,  214,  215,  216,  218,  220,  221,  224,  227,  228,  229,\n",
       "         230,  231,  232,  233,  237,  238,  241,  243,  245,  246,  247,\n",
       "         248,  249,  250,  251,  252,  254,  255,  259,  260,  262,  264,\n",
       "         266,  267,  269,  271,  272,  273,  278,  280,  281,  283,  284,\n",
       "         286,  288,  290,  291,  293,  296,  297,  298,  300,  305,  306,\n",
       "         307,  308,  310,  314,  315,  318,  319,  320,  321,  322,  324,\n",
       "         325,  329,  333,  336,  339,  340,  341,  342,  343,  345,  346,\n",
       "         347,  348,  349,  350,  351,  352,  355,  356,  357,  358,  359,\n",
       "         360,  362,  364,  365,  369,  374,  375,  376,  379,  380,  383,\n",
       "         384,  385,  387,  389,  391,  392,  393,  397,  399,  400,  407,\n",
       "         410,  411,  412,  414,  418,  419,  422,  423,  424,  425,  426,\n",
       "         428,  429,  430,  431,  432,  433,  435,  437,  440,  441,  442,\n",
       "         444,  447,  449,  450,  451,  453,  454,  457,  458,  459,  460,\n",
       "         461,  462,  464,  467,  469,  470,  471,  472,  474,  475,  476,\n",
       "         479,  484,  486,  487,  490,  492,  494,  495,  498,  499,  500,\n",
       "         501,  505,  506,  508,  509,  513,  514,  515,  519,  520,  523,\n",
       "         524,  525,  529,  530,  531,  532,  537,  538,  539,  541,  542,\n",
       "         544,  546,  549,  550,  551,  553,  555,  558,  559,  560,  561,\n",
       "         562,  564,  566,  567,  568,  570,  571,  572,  573,  576,  578,\n",
       "         580,  583,  584,  585,  586,  590,  592,  594,  595,  597,  598,\n",
       "         599,  600,  603,  604,  606,  607,  608,  609,  613,  614,  615,\n",
       "         620,  622,  624,  626,  627,  628,  630,  631,  632,  634,  636,\n",
       "         637,  640,  641,  642,  645,  649,  651,  652,  657,  660,  661,\n",
       "         662,  663,  664,  665,  669,  670,  671,  672,  673,  674,  675,\n",
       "         676,  680,  683,  684,  686,  687,  688,  689,  692,  695,  701,\n",
       "         702,  703,  704,  712,  714,  716,  719,  720,  721,  726,  727,\n",
       "         728,  733,  734,  737,  738,  739,  741,  742,  743,  744,  745,\n",
       "         747,  748,  749,  750,  751,  754,  756,  758,  763,  765,  766,\n",
       "         767,  768,  769,  770,  773,  774,  775,  778,  780,  781,  783,\n",
       "         787,  789,  790,  795,  796,  797,  799,  800,  802,  803,  804,\n",
       "         808,  809,  815,  817,  818,  823,  826,  827,  829,  830,  832,\n",
       "         833,  835,  839,  842,  844,  845,  846,  850,  852,  853,  858,\n",
       "         859,  860,  861,  862,  863,  864,  865,  869,  870,  873,  875,\n",
       "         878,  881,  882,  883,  884,  888,  891,  893,  895,  896,  899,\n",
       "         902,  903,  904,  905,  908,  909,  914,  918,  919,  920,  922,\n",
       "         923,  924,  925,  929,  930,  931,  932,  937,  938,  940,  941,\n",
       "         943,  944,  950,  952,  954,  955,  957,  959,  960,  963,  966,\n",
       "         968,  970,  974,  978,  979,  982,  983,  984,  985,  988,  991,\n",
       "         994,  999, 1000, 1001, 1003, 1007, 1008, 1009, 1014, 1018, 1020,\n",
       "        1021, 1024, 1025, 1027, 1028, 1031, 1033, 1035, 1036, 1040, 1041,\n",
       "        1044, 1048, 1049, 1050, 1051, 1054, 1055, 1056, 1063, 1064, 1065,\n",
       "        1071, 1072, 1079, 1081, 1082, 1085, 1087, 1090, 1091, 1099, 1100,\n",
       "        1101, 1103, 1108, 1112, 1114, 1116, 1118, 1119, 1121, 1122, 1123,\n",
       "        1125, 1126, 1129, 1131, 1132, 1133, 1134, 1136, 1137, 1138, 1140,\n",
       "        1142, 1144, 1145, 1147, 1148, 1151, 1152, 1153, 1158, 1161, 1162,\n",
       "        1165, 1168, 1170, 1172, 1174, 1176, 1179, 1181, 1182, 1185, 1187,\n",
       "        1191, 1192, 1194, 1196, 1197, 1198, 1199, 1201, 1202, 1206, 1210,\n",
       "        1211, 1212, 1216, 1218, 1219, 1220, 1222, 1223, 1226, 1228, 1229,\n",
       "        1230, 1231, 1233, 1235, 1236, 1237, 1239, 1240, 1241, 1244, 1245,\n",
       "        1246, 1247, 1248, 1249, 1253, 1258, 1259, 1260, 1265, 1268, 1269,\n",
       "        1273, 1274, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284,\n",
       "        1286, 1288, 1291, 1292, 1293, 1294, 1297, 1303, 1304, 1306, 1307,\n",
       "        1308, 1309, 1311, 1320, 1321, 1322, 1323, 1324, 1325, 1329, 1330,\n",
       "        1331, 1332, 1333, 1334, 1335, 1337, 1338, 1339, 1343, 1344, 1346,\n",
       "        1347, 1349, 1350, 1351, 1353, 1355, 1356, 1357, 1359, 1362, 1363,\n",
       "        1364, 1366, 1368, 1369, 1371, 1372, 1374, 1377, 1380, 1381, 1382,\n",
       "        1383, 1385, 1386, 1391, 1393, 1394, 1396, 1397, 1398, 1399, 1401,\n",
       "        1402, 1405, 1406, 1407, 1414, 1415, 1418, 1420, 1425, 1426, 1427,\n",
       "        1430, 1435, 1436, 1437, 1438, 1440, 1441, 1444, 1445, 1446, 1450,\n",
       "        1452, 1453, 1454, 1456, 1458, 1459, 1461, 1462, 1463, 1464, 1465,\n",
       "        1466, 1469, 1471, 1475, 1476, 1481, 1483, 1484, 1486, 1487, 1489,\n",
       "        1499, 1501, 1502, 1505, 1506, 1508, 1509, 1513, 1515, 1516, 1518,\n",
       "        1519, 1521, 1524, 1525, 1526, 1529, 1530, 1532, 1540, 1543, 1544,\n",
       "        1545, 1547, 1548, 1550, 1552, 1553, 1555, 1557, 1559, 1561, 1565,\n",
       "        1568, 1569, 1570, 1571, 1575, 1576, 1577, 1578, 1579, 1585, 1586,\n",
       "        1587, 1588, 1589, 1590, 1593, 1595, 1597, 1602, 1604, 1607, 1610,\n",
       "        1611, 1614, 1615, 1618, 1623, 1625, 1629, 1630, 1631, 1634, 1635,\n",
       "        1636, 1639, 1640, 1641, 1642, 1643, 1644, 1648, 1650, 1652, 1653,\n",
       "        1654, 1655, 1659, 1660, 1663, 1665, 1670, 1671, 1675, 1677, 1678,\n",
       "        1680, 1685, 1686, 1687, 1688, 1690, 1693, 1695, 1697, 1700, 1701,\n",
       "        1702, 1705, 1706, 1707, 1710, 1711, 1712, 1715, 1716, 1726, 1729,\n",
       "        1730, 1731, 1733, 1734, 1735, 1737, 1738, 1743, 1746, 1748, 1750,\n",
       "        1751, 1753, 1754, 1756, 1758, 1762, 1763, 1765, 1766, 1767, 1769,\n",
       "        1773, 1775, 1776, 1777, 1778, 1779, 1781, 1783, 1784, 1786, 1791,\n",
       "        1793, 1794, 1797, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1811,\n",
       "        1812, 1814, 1815, 1816, 1819, 1821, 1825, 1826, 1827, 1832, 1833,\n",
       "        1835, 1836, 1838, 1839, 1840, 1842, 1843, 1846, 1847, 1849, 1850,\n",
       "        1852, 1853, 1854, 1856, 1858, 1859, 1861, 1863, 1864, 1873, 1875,\n",
       "        1878, 1880, 1881, 1884, 1885, 1888, 1890, 1893, 1894, 1895, 1897,\n",
       "        1899, 1900, 1902, 1904, 1907, 1908, 1912, 1913, 1914, 1916, 1917,\n",
       "        1922, 1923, 1925, 1927, 1928, 1929, 1931, 1933, 1934, 1940, 1941,\n",
       "        1943, 1945, 1946, 1948, 1953, 1956]),\n",
       " 4: array([   0,    2,   51,   81,  130,  285,  302,  334,  406,  420,  511,\n",
       "         574,  588,  760,  813,  840,  933,  958,  967, 1013, 1117, 1155,\n",
       "        1204, 1227, 1250, 1251, 1318, 1365, 1378, 1510, 1533, 1599, 1603,\n",
       "        1619, 1664, 1714, 1829, 1920]),\n",
       " 5: array([  42,   74,  106,  200,  234,  256,  277,  289,  303,  332,  363,\n",
       "         372,  377,  404,  405,  477,  503,  510,  533,  545,  617,  678,\n",
       "         698,  772,  779,  785,  812,  819,  834,  871,  874,  879,  916,\n",
       "         927,  956,  972,  980, 1016, 1084, 1086, 1094, 1106, 1139, 1149,\n",
       "        1163, 1178, 1190, 1200, 1215, 1217, 1232, 1285, 1312, 1317, 1336,\n",
       "        1375, 1392, 1409, 1460, 1467, 1480, 1511, 1536, 1591, 1649, 1725,\n",
       "        1742, 1744, 1772, 1789, 1834, 1862, 1870, 1882, 1886, 1901]),\n",
       " 6: array([   3,   13,   16,   17,   18,   21,   24,   29,   55,   66,   70,\n",
       "          76,   84,  102,  107,  114,  116,  117,  127,  170,  171,  176,\n",
       "         182,  185,  217,  239,  240,  242,  244,  263,  276,  279,  301,\n",
       "         309,  312,  313,  316,  323,  327,  330,  331,  335,  368,  370,\n",
       "         371,  386,  388,  409,  421,  427,  438,  448,  482,  491,  507,\n",
       "         512,  517,  527,  528,  534,  536,  543,  547,  565,  569,  579,\n",
       "         596,  602,  625,  629,  638,  644,  658,  666,  681,  690,  696,\n",
       "         699,  706,  709,  757,  782,  788,  794,  801,  828,  836,  856,\n",
       "         857,  867,  886,  887,  890,  892,  897,  907,  945,  946,  965,\n",
       "         975,  976,  986,  992, 1005, 1012, 1017, 1029, 1053, 1059, 1074,\n",
       "        1077, 1088, 1089, 1104, 1124, 1141, 1150, 1175, 1189, 1195, 1208,\n",
       "        1214, 1225, 1256, 1302, 1313, 1315, 1361, 1379, 1384, 1387, 1390,\n",
       "        1400, 1404, 1412, 1422, 1423, 1433, 1442, 1477, 1479, 1492, 1493,\n",
       "        1496, 1504, 1535, 1539, 1546, 1600, 1608, 1621, 1624, 1638, 1645,\n",
       "        1657, 1674, 1689, 1691, 1696, 1698, 1703, 1718, 1719, 1724, 1739,\n",
       "        1740, 1741, 1760, 1761, 1764, 1770, 1782, 1796, 1805, 1808, 1813,\n",
       "        1820, 1828, 1845, 1865, 1866, 1868, 1869, 1883, 1891, 1906, 1911,\n",
       "        1919, 1926, 1944])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for cat in class_indices:\n",
    "    print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n",
      "342\n",
      "95\n",
      "1007\n",
      "38\n",
      "76\n",
      "190\n"
     ]
    }
   ],
   "source": [
    "for indices in class_indices.values():\n",
    "    print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
       "         11,   12,   13,   14,   15,   16,   17,   18,   19,   20,   21,\n",
       "         22,   23,   24,   25,   26,   27,   28,   29,   30,   31,   32,\n",
       "         33,   34,   35,   36,   37,   38,   39,   40,   41,   42,   43,\n",
       "         44,   45,   46,   47,   48,   49,   50,   51,   52,   53,   54,\n",
       "         55,   56,   57,   58,   59,   60,   61,   62,   63,   64,   65,\n",
       "         66,   67,   68,   69,   70,   71,   72,   73,   74,   75,   76,\n",
       "         77,   78,   79,   80,   81,   82,   83,   84,   85,   86,   87,\n",
       "         88,   89,   90,   91,   92,   93,   94,   95,   96,   97,   98,\n",
       "         99,  100,  101,  102,  103,  104,  105,  106,  107,  108,  109,\n",
       "        110,  111,  112,  113,  114,  115,  116,  117,  118,  119,  120,\n",
       "        121,  122,  123,  124,  125,  126,  127,  128,  129,  130,  131,\n",
       "        132,  133,  134,  135,  136,  137,  138,  139,  140,  141,  142,\n",
       "        143,  144,  145,  146,  147,  148,  149,  150,  151,  152,  153,\n",
       "        154,  155,  156,  157,  158,  159,  160,  161,  162,  163,  164,\n",
       "        165,  166,  167,  168,  169,  170,  171,  172,  173,  174,  175,\n",
       "        176,  177,  178,  179,  180,  181,  182,  183,  184,  185,  186,\n",
       "        187,  188,  189,  190,  191,  192,  193,  194,  195,  196,  197,\n",
       "        198,  199,  200,  201,  202,  203,  204,  205,  206,  207,  208,\n",
       "        209,  210,  211,  212,  213,  214,  215,  216,  217,  218,  219,\n",
       "        220,  221,  222,  223,  224,  225,  226,  227,  228,  229,  230,\n",
       "        231,  232,  233,  234,  235,  236,  237,  238,  239,  240,  241,\n",
       "        242,  243,  244,  245,  246,  247,  248,  249,  250,  251,  252,\n",
       "        253,  254,  255,  256,  257,  258,  259,  260,  261,  262,  263,\n",
       "        264,  265,  266,  267,  268,  269,  270,  271,  272,  273,  274,\n",
       "        275,  276,  277,  278,  279,  280,  281,  282,  283,  284,  285,\n",
       "        286,  287,  288,  289,  290,  291,  292,  293,  294,  295,  296,\n",
       "        297,  298,  299,  300,  301,  302,  303,  304,  305,  306,  307,\n",
       "        308,  309,  310,  311,  312,  313,  314,  315,  316,  317,  318,\n",
       "        319,  320,  321,  322,  323,  324,  325,  326,  327,  328,  329,\n",
       "        330,  331,  332,  333,  334,  335,  336,  337,  338,  339,  340,\n",
       "        341,  342,  343,  344,  345,  346,  347,  348,  349,  350,  351,\n",
       "        352,  353,  354,  355,  356,  357,  358,  359,  360,  361,  362,\n",
       "        363,  364,  365,  366,  367,  368,  369,  370,  371,  372,  373,\n",
       "        374,  375,  376,  377,  378,  379,  380,  381,  382,  383,  384,\n",
       "        385,  386,  387,  388,  389,  390,  391,  392,  393,  394,  395,\n",
       "        396,  397,  398,  399,  400,  401,  402,  403,  404,  405,  406,\n",
       "        407,  408,  409,  410,  411,  412,  413,  414,  415,  416,  417,\n",
       "        418,  419,  420,  421,  422,  423,  424,  425,  426,  427,  428,\n",
       "        429,  430,  431,  432,  433,  434,  435,  436,  437,  438,  439,\n",
       "        440,  441,  442,  443,  444,  445,  446,  447,  448,  449,  450,\n",
       "        451,  452,  453,  454,  455,  456,  457,  458,  459,  460,  461,\n",
       "        462,  463,  464,  465,  466,  467,  468,  469,  470,  471,  472,\n",
       "        473,  474,  475,  476,  477,  478,  479,  480,  481,  482,  483,\n",
       "        484,  485,  486,  487,  488,  489,  490,  491,  492,  493,  494,\n",
       "        495,  496,  497,  498,  499,  500,  501,  502,  503,  504,  505,\n",
       "        506,  507,  508,  509,  510,  511,  512,  513,  514,  515,  516,\n",
       "        517,  518,  519,  520,  521,  522,  523,  524,  525,  526,  527,\n",
       "        528,  529,  530,  531,  532,  533,  534,  535,  536,  537,  538,\n",
       "        539,  540,  541,  542,  543,  544,  545,  546,  547,  548,  549,\n",
       "        550,  551,  552,  553,  554,  555,  556,  557,  558,  559,  560,\n",
       "        561,  562,  563,  564,  565,  566,  567,  568,  569,  570,  571,\n",
       "        572,  573,  574,  575,  576,  577,  578,  579,  580,  581,  582,\n",
       "        583,  584,  585,  586,  587,  588,  589,  590,  591,  592,  593,\n",
       "        594,  595,  596,  597,  598,  599,  600,  601,  602,  603,  604,\n",
       "        605,  606,  607,  608,  609,  610,  611,  612,  613,  614,  615,\n",
       "        616,  617,  618,  619,  620,  621,  622,  623,  624,  625,  626,\n",
       "        627,  628,  629,  630,  631,  632,  633,  634,  635,  636,  637,\n",
       "        638,  639,  640,  641,  642,  643,  644,  645,  646,  647,  648,\n",
       "        649,  650,  651,  652,  653,  654,  655,  656,  657,  658,  659,\n",
       "        660,  661,  662,  663,  664,  665,  666,  667,  668,  669,  670,\n",
       "        671,  672,  673,  674,  675,  676,  677,  678,  679,  680,  681,\n",
       "        682,  683,  684,  685,  686,  687,  688,  689,  690,  691,  692,\n",
       "        693,  694,  695,  696,  697,  698,  699,  700,  701,  702,  703,\n",
       "        704,  705,  706,  707,  708,  709,  710,  711,  712,  713,  714,\n",
       "        715,  716,  717,  718,  719,  720,  721,  722,  723,  724,  725,\n",
       "        726,  727,  728,  729,  730,  731,  732,  733,  734,  735,  736,\n",
       "        737,  738,  739,  740,  741,  742,  743,  744,  745,  746,  747,\n",
       "        748,  749,  750,  751,  752,  753,  754,  755,  756,  757,  758,\n",
       "        759,  760,  761,  762,  763,  764,  765,  766,  767,  768,  769,\n",
       "        770,  771,  772,  773,  774,  775,  776,  777,  778,  779,  780,\n",
       "        781,  782,  783,  784,  785,  786,  787,  788,  789,  790,  791,\n",
       "        792,  793,  794,  795,  796,  797,  798,  799,  800,  801,  802,\n",
       "        803,  804,  805,  806,  807,  808,  809,  810,  811,  812,  813,\n",
       "        814,  815,  816,  817,  818,  819,  820,  821,  822,  823,  824,\n",
       "        825,  826,  827,  828,  829,  830,  831,  832,  833,  834,  835,\n",
       "        836,  837,  838,  839,  840,  841,  842,  843,  844,  845,  846,\n",
       "        847,  848,  849,  850,  851,  852,  853,  854,  855,  856,  857,\n",
       "        858,  859,  860,  861,  862,  863,  864,  865,  866,  867,  868,\n",
       "        869,  870,  871,  872,  873,  874,  875,  876,  877,  878,  879,\n",
       "        880,  881,  882,  883,  884,  885,  886,  887,  888,  889,  890,\n",
       "        891,  892,  893,  894,  895,  896,  897,  898,  899,  900,  901,\n",
       "        902,  903,  904,  905,  906,  907,  908,  909,  910,  911,  912,\n",
       "        913,  914,  915,  916,  917,  918,  919,  920,  921,  922,  923,\n",
       "        924,  925,  926,  927,  928,  929,  930,  931,  932,  933,  934,\n",
       "        935,  936,  937,  938,  939,  940,  941,  942,  943,  944,  945,\n",
       "        946,  947,  948,  949,  950,  951,  952,  953,  954,  955,  956,\n",
       "        957,  958,  959,  960,  961,  962,  963,  964,  965,  966,  967,\n",
       "        968,  969,  970,  971,  972,  973,  974,  975,  976,  977,  978,\n",
       "        979,  980,  981,  982,  983,  984,  985,  986,  987,  988,  989,\n",
       "        990,  991,  992,  993,  994,  995,  996,  997,  998,  999, 1000,\n",
       "       1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011,\n",
       "       1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022,\n",
       "       1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033,\n",
       "       1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044,\n",
       "       1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055,\n",
       "       1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066,\n",
       "       1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077,\n",
       "       1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088,\n",
       "       1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099,\n",
       "       1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110,\n",
       "       1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121,\n",
       "       1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132,\n",
       "       1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143,\n",
       "       1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154,\n",
       "       1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165,\n",
       "       1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176,\n",
       "       1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,\n",
       "       1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198,\n",
       "       1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209,\n",
       "       1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220,\n",
       "       1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231,\n",
       "       1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242,\n",
       "       1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253,\n",
       "       1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264,\n",
       "       1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275,\n",
       "       1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286,\n",
       "       1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297,\n",
       "       1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308,\n",
       "       1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319,\n",
       "       1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330,\n",
       "       1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341,\n",
       "       1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352,\n",
       "       1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363,\n",
       "       1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374,\n",
       "       1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385,\n",
       "       1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396,\n",
       "       1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407,\n",
       "       1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418,\n",
       "       1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429,\n",
       "       1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440,\n",
       "       1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451,\n",
       "       1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462,\n",
       "       1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473,\n",
       "       1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484,\n",
       "       1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495,\n",
       "       1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506,\n",
       "       1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517,\n",
       "       1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528,\n",
       "       1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539,\n",
       "       1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550,\n",
       "       1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561,\n",
       "       1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572,\n",
       "       1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583,\n",
       "       1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594,\n",
       "       1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605,\n",
       "       1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616,\n",
       "       1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627,\n",
       "       1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638,\n",
       "       1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649,\n",
       "       1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660,\n",
       "       1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671,\n",
       "       1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682,\n",
       "       1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693,\n",
       "       1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704,\n",
       "       1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715,\n",
       "       1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726,\n",
       "       1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737,\n",
       "       1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748,\n",
       "       1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759,\n",
       "       1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770,\n",
       "       1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781,\n",
       "       1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792,\n",
       "       1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803,\n",
       "       1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814,\n",
       "       1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825,\n",
       "       1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836,\n",
       "       1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847,\n",
       "       1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858,\n",
       "       1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869,\n",
       "       1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880,\n",
       "       1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891,\n",
       "       1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902,\n",
       "       1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913,\n",
       "       1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924,\n",
       "       1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935,\n",
       "       1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946,\n",
       "       1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(len(scattering_patterns))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TEST_DATA = 2000\n",
    "train_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split(\n",
    "    indices, \n",
    "    train_size=train_size,\n",
    "    test_size=min(len(indices)-train_size, MAX_TEST_DATA),\n",
    "    random_state=42,\n",
    "    stratify=encoded_structure_types,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1757"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = scattering_patterns[train_indices], encoded_structure_types[train_indices]\n",
    "X_test, y_test = scattering_patterns[test_indices], encoded_structure_types[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6]), array([ 21,  35,  10, 103,   4,   8,  19]))\n",
      "0: 10.5\n",
      "1: 17.5\n",
      "2: 5.0\n",
      "3: 51.5\n",
      "4: 2.0\n",
      "5: 4.0\n",
      "6: 9.5\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))\n",
    "for n in np.unique(y_train):\n",
    "    print(f'{n}: {np.unique(y_train, return_counts=True)[1][n]/len(y_train)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6]), array([188, 307,  85, 904,  34,  68, 171]))\n",
      "0: 10.700056915196358\n",
      "1: 17.47296528173022\n",
      "2: 4.837791690381332\n",
      "3: 51.4513375071144\n",
      "4: 1.935116676152533\n",
      "5: 3.870233352305066\n",
      "6: 9.732498577120092\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_test, return_counts=True))\n",
    "for n in np.unique(y_test):\n",
    "    print(f'{n}: {np.unique(y_test, return_counts=True)[1][n]/len(y_test)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.   , -0.008, -0.016, -0.024, -0.031, -0.039, -0.047, -0.053,\n",
       "       -0.06 , -0.068, -0.073, -0.077, -0.085, -0.091, -0.091, -0.097,\n",
       "       -0.107, -0.073,  0.635,  0.708, -0.07 , -0.119, -0.111, -0.11 ,\n",
       "       -0.116, -0.089,  0.112, -0.015, -0.108, -0.104, -0.098, -0.016,\n",
       "        0.403,  0.064, -0.08 , -0.082, -0.05 ,  0.092, -0.021, -0.063,\n",
       "       -0.049,  0.096,  0.077, -0.037, -0.038, -0.032, -0.028, -0.024,\n",
       "       -0.019, -0.016, -0.012, -0.008,  0.009,  0.009,  0.   ,  0.002,\n",
       "        0.003,  0.005,  0.006,  0.007,  0.007,  0.008,  0.008,  0.008,\n",
       "        0.008,  0.008,  0.007,  0.006,  0.005,  0.005,  0.003,  0.002,\n",
       "        0.002,  0.001, -0.   , -0.001, -0.002, -0.003, -0.003, -0.004,\n",
       "       -0.004, -0.005, -0.005, -0.005, -0.005, -0.005, -0.004, -0.004,\n",
       "       -0.004, -0.003, -0.003, -0.002, -0.002, -0.001, -0.001, -0.   ,\n",
       "        0.001,  0.001,  0.001,  0.002,  0.002,  0.003,  0.003,  0.003,\n",
       "        0.003,  0.003,  0.003,  0.003,  0.003,  0.003,  0.002,  0.002,\n",
       "        0.002,  0.001,  0.001,  0.001,  0.   , -0.   , -0.   , -0.001,\n",
       "       -0.001, -0.001, -0.002, -0.002, -0.002, -0.002, -0.002, -0.002,\n",
       "       -0.002, -0.002, -0.002, -0.002, -0.002, -0.002], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators=500, \n",
    "    random_state=42, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500, random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=500, random_state=42, verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=42, verbose=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 4, 1, 3, 3, 1, 6, 3, 1, 2, 1, 3, 4,\n",
       "       0, 3, 3, 6, 6, 3, 1, 3, 3, 1, 3, 0, 3, 3, 2, 1, 3, 3, 3, 6, 3, 1,\n",
       "       2, 1, 1, 3, 6, 3, 0, 0, 3, 3, 6, 3, 3, 3, 3, 3, 0, 3, 6, 5, 6, 6,\n",
       "       0, 3, 3, 3, 3, 0, 6, 3, 1, 0, 3, 1, 1, 3, 3, 0, 3, 0, 1, 1, 3, 3,\n",
       "       3, 1, 6, 4, 3, 3, 3, 3, 0, 5, 3, 3, 1, 3, 1, 0, 3, 1, 3, 2, 0, 3,\n",
       "       0, 6, 1, 3, 6, 3, 0, 3, 3, 3, 3, 1, 1, 6, 0, 1, 3, 3, 1, 1, 6, 1,\n",
       "       6, 3, 1, 1, 3, 3, 1, 3, 3, 3, 3, 6, 1, 3, 3, 1, 1, 3, 1, 3, 3, 1,\n",
       "       3, 3, 3, 3, 3, 3, 3, 1, 1, 0, 1, 3, 3, 0, 0, 6, 3, 1, 6, 3, 1, 3,\n",
       "       3, 3, 1, 0, 6, 3, 3, 1, 3, 2, 3, 3, 1, 3, 6, 6, 1, 3, 3, 3, 3, 1,\n",
       "       1, 0, 3, 3, 3, 3, 3, 0, 6, 3, 6, 3, 0, 2, 0, 3, 6, 3, 0, 3, 3, 1,\n",
       "       1, 3, 1, 1, 3, 3, 3, 2, 3, 3, 0, 3, 1, 3, 3, 0, 3, 3, 3, 1, 6, 1,\n",
       "       3, 1, 0, 3, 3, 1, 3, 3, 5, 3, 3, 0, 1, 3, 0, 6, 3, 1, 0, 1, 1, 3,\n",
       "       1, 3, 1, 1, 6, 3, 3, 1, 4, 3, 1, 6, 3, 3, 3, 3, 0, 3, 3, 0, 3, 2,\n",
       "       0, 3, 3, 3, 3, 3, 2, 6, 3, 1, 3, 0, 3, 6, 0, 3, 1, 3, 0, 6, 3, 2,\n",
       "       1, 6, 3, 1, 3, 3, 0, 3, 5, 3, 3, 3, 0, 3, 0, 0, 3, 3, 3, 3, 3, 3,\n",
       "       3, 2, 3, 3, 1, 3, 3, 3, 6, 1, 6, 3, 3, 3, 3, 3, 6, 3, 3, 0, 0, 1,\n",
       "       3, 0, 0, 1, 3, 3, 1, 1, 3, 3, 1, 1, 0, 3, 3, 6, 3, 3, 3, 3, 3, 3,\n",
       "       3, 6, 0, 3, 6, 1, 1, 3, 6, 6, 3, 1, 0, 3, 1, 3, 3, 3, 3, 6, 1, 6,\n",
       "       3, 5, 6, 3, 3, 0, 6, 3, 3, 6, 1, 0, 5, 0, 3, 3, 3, 1, 3, 3, 1, 3,\n",
       "       3, 3, 3, 1, 3, 1, 1, 3, 3, 3, 6, 3, 6, 3, 3, 3, 3, 3, 0, 1, 0, 6,\n",
       "       0, 0, 1, 3, 1, 3, 3, 0, 3, 3, 1, 1, 3, 0, 0, 0, 0, 6, 3, 3, 4, 6,\n",
       "       3, 3, 3, 1, 3, 3, 6, 1, 3, 3, 3, 1, 0, 3, 5, 2, 3, 0, 2, 3, 1, 3,\n",
       "       3, 1, 1, 1, 0, 1, 3, 1, 3, 3, 3, 0, 3, 3, 3, 1, 3, 3, 3, 1, 1, 5,\n",
       "       1, 3, 6, 1, 3, 3, 3, 3, 3, 6, 3, 6, 6, 0, 3, 3, 3, 3, 3, 0, 6, 3,\n",
       "       3, 1, 0, 3, 3, 1, 3, 1, 3, 1, 3, 3, 3, 3, 1, 0, 1, 1, 1, 1, 3, 3,\n",
       "       0, 1, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 0, 1, 5, 3, 3, 1, 3, 3, 3, 6,\n",
       "       3, 6, 3, 1, 1, 3, 3, 0, 3, 3, 1, 3, 0, 3, 3, 1, 3, 3, 3, 1, 3, 1,\n",
       "       5, 3, 1, 2, 1, 6, 3, 0, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 6, 0, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 3, 3, 3, 3, 3, 3, 0, 3, 6, 3, 0,\n",
       "       3, 3, 1, 1, 3, 3, 5, 3, 3, 3, 3, 0, 3, 1, 3, 3, 3, 3, 6, 3, 3, 3,\n",
       "       3, 3, 1, 1, 3, 1, 6, 1, 3, 1, 5, 3, 2, 5, 3, 3, 6, 3, 3, 3, 3, 3,\n",
       "       3, 2, 0, 6, 3, 3, 1, 3, 6, 3, 3, 3, 3, 3, 1, 3, 6, 1, 1, 3, 3, 3,\n",
       "       3, 6, 3, 3, 6, 3, 3, 0, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3,\n",
       "       1, 6, 1, 1, 1, 3, 3, 1, 3, 4, 3, 1, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3,\n",
       "       1, 6, 5, 3, 3, 0, 3, 3, 3, 1, 3, 3, 3, 3, 3, 2, 0, 6, 1, 1, 5, 3,\n",
       "       3, 3, 0, 1, 6, 1, 3, 1, 3, 3, 3, 0, 1, 6, 6, 1, 3, 3, 1, 0, 3, 3,\n",
       "       3, 1, 3, 1, 1, 3, 6, 3, 6, 6, 0, 0, 1, 1, 3, 3, 3, 3, 6, 3, 1, 3,\n",
       "       3, 2, 2, 6, 3, 1, 3, 1, 1, 1, 3, 0, 3, 1, 3, 3, 3, 3, 1, 3, 3, 3,\n",
       "       1, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 3, 3, 0, 3, 3, 1, 3, 0, 3, 3, 3,\n",
       "       3, 2, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3,\n",
       "       1, 3, 1, 1, 0, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 6, 1, 6, 1, 3, 3, 3,\n",
       "       1, 3, 1, 3, 1, 3, 3, 6, 3, 3, 3, 3, 2, 6, 0, 1, 3, 3, 3, 1, 3, 3,\n",
       "       1, 0, 3, 3, 3, 1, 6, 1, 3, 0, 3, 3, 0, 3, 3, 3, 2, 3, 1, 3, 1, 5,\n",
       "       1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 0, 1, 3, 3, 1, 3, 1, 3, 3, 3,\n",
       "       3, 1, 1, 6, 3, 3, 0, 3, 3, 3, 6, 3, 2, 0, 3, 1, 3, 1, 3, 1, 3, 0,\n",
       "       3, 1, 1, 3, 1, 3, 3, 1, 0, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 6, 1,\n",
       "       3, 3, 0, 6, 3, 0, 3, 6, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1,\n",
       "       3, 3, 1, 0, 3, 3, 1, 3, 1, 1, 3, 6, 3, 0, 1, 0, 3, 3, 3, 3, 3, 2,\n",
       "       0, 5, 3, 3, 0, 1, 3, 1, 6, 1, 3, 3, 5, 3, 3, 3, 3, 6, 1, 3, 1, 1,\n",
       "       6, 3, 3, 0, 0, 3, 1, 1, 1, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 3, 1,\n",
       "       6, 3, 6, 6, 3, 3, 3, 2, 1, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 1, 3,\n",
       "       3, 1, 0, 3, 3, 1, 3, 3, 3, 3, 3, 0, 6, 3, 3, 3, 0, 6, 3, 6, 3, 3,\n",
       "       3, 1, 1, 0, 6, 3, 3, 2, 1, 3, 3, 3, 1, 6, 3, 3, 1, 1, 3, 3, 1, 3,\n",
       "       1, 3, 3, 3, 1, 1, 6, 0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 6, 1, 2, 3, 3,\n",
       "       3, 1, 3, 3, 0, 3, 0, 1, 3, 3, 6, 6, 1, 6, 1, 3, 3, 0, 3, 5, 6, 3,\n",
       "       3, 3, 3, 1, 3, 3, 5, 1, 1, 6, 3, 3, 3, 0, 3, 1, 3, 1, 3, 3, 1, 3,\n",
       "       1, 3, 3, 3, 3, 1, 0, 3, 3, 0, 3, 1, 0, 0, 3, 2, 3, 3, 3, 3, 3, 0,\n",
       "       1, 3, 3, 3, 2, 3, 1, 1, 1, 6, 3, 5, 1, 1, 3, 3, 4, 6, 3, 3, 3, 3,\n",
       "       3, 3, 3, 0, 3, 0, 3, 0, 3, 6, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 2, 1,\n",
       "       3, 3, 3, 6, 3, 2, 1, 3, 3, 3, 3, 3, 0, 6, 1, 0, 3, 3, 3, 1, 3, 3,\n",
       "       6, 1, 3, 6, 1, 3, 0, 5, 6, 3, 3, 1, 3, 3, 3, 3, 6, 1, 3, 1, 3, 1,\n",
       "       0, 3, 6, 1, 3, 1, 3, 3, 3, 3, 0, 3, 3, 6, 3, 6, 3, 6, 0, 3, 1, 0,\n",
       "       6, 3, 3, 3, 3, 1, 1, 3, 3, 3, 0, 1, 3, 6, 6, 1, 3, 0, 1, 3, 3, 1,\n",
       "       3, 0, 6, 3, 6, 1, 3, 2, 3, 3, 0, 3, 3, 1, 6, 3, 3, 1, 1, 3, 6, 3,\n",
       "       3, 1, 6, 3, 3, 6, 3, 6, 3, 3, 1, 1, 1, 3, 1, 3, 1, 3, 3, 0, 1, 4,\n",
       "       3, 3, 3, 1, 0, 1, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 1, 3, 6, 3, 3, 3,\n",
       "       3, 1, 3, 0, 3, 1, 3, 3, 3, 1, 3, 1, 3, 3, 6, 1, 3, 6, 6, 1, 0, 3,\n",
       "       1, 1, 3, 3, 1, 0, 0, 6, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3,\n",
       "       6, 1, 1, 1, 3, 3, 0, 6, 3, 3, 1, 3, 1, 3, 1, 1, 0, 6, 1, 3, 1, 6,\n",
       "       3, 3, 3, 0, 1, 3, 3, 3, 3, 3, 0, 3, 3, 0, 1, 1, 3, 3, 6, 0, 2, 3,\n",
       "       1, 6, 1, 3, 3, 3, 3, 3, 6, 3, 6, 1, 1, 3, 0, 1, 3, 3, 1, 3, 3, 3,\n",
       "       3, 3, 5, 3, 1, 6, 6, 1, 1, 1, 3, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3,\n",
       "       3, 3, 3, 0, 3, 6, 1, 3, 1, 5, 3, 3, 1, 1, 1, 2, 3, 3, 3, 0, 4, 3,\n",
       "       3, 3, 6, 6, 3, 3, 1, 3, 0, 1, 1, 0, 2, 3, 3, 0, 6, 1, 1, 2, 1, 3,\n",
       "       1, 3, 6, 1, 3, 3, 3, 0, 1, 3, 6, 3, 3, 6, 1, 2, 3, 3, 3, 1, 1, 3,\n",
       "       3, 3, 1, 3, 3, 3, 1, 6, 1, 3, 3, 3, 3, 1, 6, 3, 3, 3, 3, 1, 3, 3,\n",
       "       3, 1, 3, 3, 3, 3, 3, 3, 3, 6, 1, 1, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3,\n",
       "       3, 6, 3, 3, 0, 6, 3, 3, 3, 3, 3, 0, 3, 3, 3, 6, 1, 3, 0, 5, 3, 3,\n",
       "       3, 3, 3, 3, 6, 3, 1, 3, 6, 3, 3, 3, 3, 3, 0, 3, 1, 1, 1, 1, 3, 6,\n",
       "       0, 3, 3, 6, 3, 3, 3, 3, 3, 3, 0, 3, 3, 6, 6, 3, 3, 0, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "kappa = cohen_kappa_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8366533864541833,\n",
       " 0.6209309616315203,\n",
       " 0.8366533864541833,\n",
       " 0.8199232207205036,\n",
       " 0.7511289684165225)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, f1_macro, f1_micro, f1_weighted, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_classification(scattering_patterns, structure_types, max_test_data=2000, train_size=200, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepares the dataset for classification by splitting it into training and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    scattering_patterns (list or numpy.ndarray): The scattering patterns for each structure.\n",
    "    structure_types (list of str): The structure type for each scattering pattern.\n",
    "    num_data_per_class (int): Number of data in the less represented class.\n",
    "    train_size (int): The number of samples used for training.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - X_train (numpy.ndarray): The training set features.\n",
    "        - y_train (numpy.ndarray): The training set labels.\n",
    "        - X_test (numpy.ndarray): The test set features.\n",
    "        - y_test (numpy.ndarray): The test set labels.\n",
    "        - le (LabelEncoder): The label encoder used to encode the structure types.\n",
    "    \"\"\"\n",
    "    # Convert scattering_files to a NumPy array\n",
    "    scattering_patterns = np.array(scattering_patterns)\n",
    "    \n",
    "    # Encode the structure types into integers\n",
    "    le = LabelEncoder()\n",
    "    encoded_structure_types = le.fit_transform(structure_types)\n",
    "    \n",
    "    # Create a dictionary to store indices of each class\n",
    "    class_indices = {i: np.where(encoded_structure_types == i)[0] for i in np.unique(encoded_structure_types)}\n",
    "    \n",
    "    # Split the samples into train and test sets\n",
    "    indices = np.arange(len(num_atoms))\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        indices, \n",
    "        train_size=train_size,\n",
    "        test_size=min(len(indices)-train_size, max_test_data),\n",
    "        random_state=random_state,\n",
    "        stratify=encoded_structure_types,\n",
    "    )\n",
    "    \n",
    "    print(f\"train: {len(train_indices)}\")\n",
    "    print(f\"test: {len(test_indices)}\")\n",
    "    \n",
    "    # Create the training, validation, and test sets\n",
    "    X_train, y_train = scattering_patterns[train_indices], encoded_structure_types[train_indices]\n",
    "    X_test, y_test = scattering_patterns[test_indices], encoded_structure_types[test_indices]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_classifier(X_train, y_train, X_test, y_test, le, random_state=42):\n",
    "    # Create a classifier\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=500, \n",
    "        random_state=42, \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test set results\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Convert the predictions back to the original classes\n",
    "    #y_pred = le.inverse_transform(y_pred)\n",
    "    \n",
    "    # Convert the test labels back to the original classes\n",
    "    #y_test = le.inverse_transform(y_test)\n",
    "    \n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Calculate classification metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    \n",
    "    return y_test, y_pred, acc, f1_macro, f1_micro, f1_weighted, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_dict():\n",
    "    metrics_dict = {\n",
    "        \"train_size\": train_size,\n",
    "        \"y_true\": y_test_all,\n",
    "        \"y_pred\": y_pred_all,\n",
    "        \"accuracy\": acc_scores,\n",
    "        \"f1_macro\": f1macro_scores,\n",
    "        \"f1_micro\": f1micro_scores,\n",
    "        \"f1_weighted\": f1weighted_scores,\n",
    "        \"kappa\": kappa_scores\n",
    "    }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 600\n",
    "iterations = 10\n",
    "max_test_data = 2000\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "acc_scores = []\n",
    "f1macro_scores = []\n",
    "f1micro_scores = []\n",
    "f1weighted_scores = []\n",
    "kappa_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 600\n",
      "test: 1357\n",
      "random_state = 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.8909358879882093\n",
      "F1 macro for structure type classification: 0.7323489552815293\n",
      "F1 micro for structure type classification: 0.8909358879882093\n",
      "F1 weighted for structure type classification: 0.8835627301772506\n",
      "Kappa for structure type classification: 0.8392104148636456\n",
      "-------------Iteration 2/10\n",
      "train: 600\n",
      "test: 1357\n",
      "random_state = 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.8916728076639646\n",
      "F1 macro for structure type classification: 0.7312137834275783\n",
      "F1 micro for structure type classification: 0.8916728076639646\n",
      "F1 weighted for structure type classification: 0.8857689606296585\n",
      "Kappa for structure type classification: 0.8402202069426222\n",
      "-------------Iteration 3/10\n",
      "train: 600\n",
      "test: 1357\n",
      "random_state = 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.8769344141488578\n",
      "F1 macro for structure type classification: 0.7145084477321333\n",
      "F1 micro for structure type classification: 0.8769344141488578\n",
      "F1 weighted for structure type classification: 0.8693175165975668\n",
      "Kappa for structure type classification: 0.8183902519163191\n",
      "-------------Iteration 4/10\n",
      "train: 600\n",
      "test: 1357\n",
      "random_state = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9027266028002948\n",
      "F1 macro for structure type classification: 0.7751481589319722\n",
      "F1 micro for structure type classification: 0.9027266028002948\n",
      "F1 weighted for structure type classification: 0.8953918757753125\n",
      "Kappa for structure type classification: 0.8567881019730372\n",
      "-------------Iteration 5/10\n",
      "train: 600\n",
      "test: 1357\n",
      "random_state = 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.8997789240972734\n",
      "F1 macro for structure type classification: 0.7597902853273374\n",
      "F1 micro for structure type classification: 0.8997789240972734\n",
      "F1 weighted for structure type classification: 0.8922287695770917\n",
      "Kappa for structure type classification: 0.851241761155941\n",
      "-------------Iteration 6/10\n",
      "train: 600\n",
      "test: 1357\n",
      "random_state = 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.899042004421518\n",
      "F1 macro for structure type classification: 0.7353856611847723\n",
      "F1 micro for structure type classification: 0.899042004421518\n",
      "F1 weighted for structure type classification: 0.8877674227085719\n",
      "Kappa for structure type classification: 0.8496451181914938\n",
      "-------------Iteration 7/10\n",
      "train: 600\n",
      "test: 1357\n",
      "random_state = 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.8835666912306559\n",
      "F1 macro for structure type classification: 0.7432579232076965\n",
      "F1 micro for structure type classification: 0.8835666912306559\n",
      "F1 weighted for structure type classification: 0.8754920725502896\n",
      "Kappa for structure type classification: 0.8266738560511686\n",
      "-------------Iteration 8/10\n",
      "train: 600\n",
      "test: 1357\n",
      "random_state = 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.8872512896094326\n",
      "F1 macro for structure type classification: 0.7253612027664751\n",
      "F1 micro for structure type classification: 0.8872512896094326\n",
      "F1 weighted for structure type classification: 0.8768652699747098\n",
      "Kappa for structure type classification: 0.832269640482588\n",
      "-------------Iteration 9/10\n",
      "train: 600\n",
      "test: 1357\n",
      "random_state = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.8997789240972734\n",
      "F1 macro for structure type classification: 0.7656048652410916\n",
      "F1 micro for structure type classification: 0.8997789240972734\n",
      "F1 weighted for structure type classification: 0.8965876476056578\n",
      "Kappa for structure type classification: 0.8525309977202682\n",
      "-------------Iteration 10/10\n",
      "train: 600\n",
      "test: 1357\n",
      "random_state = 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.8784082535003684\n",
      "F1 macro for structure type classification: 0.718571399388945\n",
      "F1 micro for structure type classification: 0.8784082535003684\n",
      "F1 weighted for structure type classification: 0.870711612302038\n",
      "Kappa for structure type classification: 0.8196223028537548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for classification\n",
    "    X_train, y_train, X_test, y_test, le = prepare_dataset_classification(\n",
    "        scattering_patterns, \n",
    "        structure_types, \n",
    "        max_test_data=max_test_data, \n",
    "        train_size=train_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Classification of structure_type\n",
    "    y_test, y_pred, acc, f1_macro, f1_micro, f1_weighted, kappa = train_and_evaluate_classifier(\n",
    "        X_train, \n",
    "        y_train,  \n",
    "        X_test, \n",
    "        y_test, \n",
    "        le,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    acc_scores.append(acc)\n",
    "    f1macro_scores.append(f1_macro)\n",
    "    f1micro_scores.append(f1_micro)\n",
    "    f1weighted_scores.append(f1_weighted)\n",
    "    kappa_scores.append(kappa)\n",
    "    print(f\"Accuracy for structure type classification: {acc}\")\n",
    "    print(f\"F1 macro for structure type classification: {f1_macro}\")\n",
    "    print(f\"F1 micro for structure type classification: {f1_micro}\")\n",
    "    print(f\"F1 weighted for structure type classification: {f1_weighted}\")\n",
    "    print(f\"Kappa for structure type classification: {kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 600\n",
      "mean accuracy for structure type classification: 0.8910095799557848 +/- 0.008845799126194223\n",
      "mean F1 macro for structure type classification: 0.7401190682489531 +/- 0.019425387100565645\n",
      "mean F1 micro for structure type classification: 0.8910095799557848 +/- 0.008845799126194223\n",
      "mean F1 weighted for structure type classification: 0.8833693877898148 +/- 0.009407014967833935\n",
      "mean Kappa for structure type classification: 0.8386592652150838 +/- 0.013268550533971366\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean accuracy for structure type classification: {np.mean(acc_scores)} +/- {np.std(acc_scores)}\")\n",
    "print(f\"mean F1 macro for structure type classification: {np.mean(f1macro_scores)} +/- {np.std(f1macro_scores)}\")\n",
    "print(f\"mean F1 micro for structure type classification: {np.mean(f1micro_scores)} +/- {np.std(f1micro_scores)}\")\n",
    "print(f\"mean F1 weighted for structure type classification: {np.mean(f1weighted_scores)} +/- {np.std(f1weighted_scores)}\")\n",
    "print(f\"mean Kappa for structure type classification: {np.mean(kappa_scores)} +/- {np.std(kappa_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>[1, 2, 3, 3, 5, 3, 1, 3, 4, 3, 3, 3, 3, 2, 3, ...</td>\n",
       "      <td>[1, 2, 3, 3, 1, 3, 1, 1, 4, 3, 3, 3, 3, 1, 3, ...</td>\n",
       "      <td>0.890936</td>\n",
       "      <td>0.732349</td>\n",
       "      <td>0.890936</td>\n",
       "      <td>0.883563</td>\n",
       "      <td>0.83921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>[3, 1, 5, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...</td>\n",
       "      <td>[3, 1, 1, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...</td>\n",
       "      <td>0.891673</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.891673</td>\n",
       "      <td>0.885769</td>\n",
       "      <td>0.84022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>[1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 4, 1, 3, 3, ...</td>\n",
       "      <td>[1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 1, 1, 3, 3, ...</td>\n",
       "      <td>0.876934</td>\n",
       "      <td>0.714508</td>\n",
       "      <td>0.876934</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.81839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0         600  [1, 2, 3, 3, 5, 3, 1, 3, 4, 3, 3, 3, 3, 2, 3, ...   \n",
       "1         600  [3, 1, 5, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...   \n",
       "2         600  [1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 4, 1, 3, 3, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [1, 2, 3, 3, 1, 3, 1, 1, 4, 3, 3, 3, 3, 1, 3, ...  0.890936  0.732349   \n",
       "1  [3, 1, 1, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...  0.891673  0.731214   \n",
       "2  [1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 1, 1, 3, 3, ...  0.876934  0.714508   \n",
       "\n",
       "   f1_micro  f1_weighted    kappa  \n",
       "0  0.890936     0.883563  0.83921  \n",
       "1  0.891673     0.885769  0.84022  \n",
       "2  0.876934     0.869318  0.81839  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_600 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_600.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "iterations = 10\n",
    "max_test_data = 2000\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "acc_scores = []\n",
    "f1macro_scores = []\n",
    "f1micro_scores = []\n",
    "f1weighted_scores = []\n",
    "kappa_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 1000\n",
      "test: 957\n",
      "random_state = 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9299895506792059\n",
      "F1 macro for structure type classification: 0.8063833044284214\n",
      "F1 micro for structure type classification: 0.9299895506792059\n",
      "F1 weighted for structure type classification: 0.9254142152310778\n",
      "Kappa for structure type classification: 0.8970151267414705\n",
      "-------------Iteration 2/10\n",
      "train: 1000\n",
      "test: 957\n",
      "random_state = 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9164054336468129\n",
      "F1 macro for structure type classification: 0.7775279467406749\n",
      "F1 micro for structure type classification: 0.9164054336468129\n",
      "F1 weighted for structure type classification: 0.9077959347755326\n",
      "Kappa for structure type classification: 0.876770538243626\n",
      "-------------Iteration 3/10\n",
      "train: 1000\n",
      "test: 957\n",
      "random_state = 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9059561128526645\n",
      "F1 macro for structure type classification: 0.7749046522827332\n",
      "F1 micro for structure type classification: 0.9059561128526645\n",
      "F1 weighted for structure type classification: 0.8990328032927148\n",
      "Kappa for structure type classification: 0.8613411895390114\n",
      "-------------Iteration 4/10\n",
      "train: 1000\n",
      "test: 957\n",
      "random_state = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9122257053291536\n",
      "F1 macro for structure type classification: 0.7920909874559989\n",
      "F1 micro for structure type classification: 0.9122257053291536\n",
      "F1 weighted for structure type classification: 0.9069114044906117\n",
      "Kappa for structure type classification: 0.8710530157085363\n",
      "-------------Iteration 5/10\n",
      "train: 1000\n",
      "test: 957\n",
      "random_state = 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9247648902821317\n",
      "F1 macro for structure type classification: 0.8108045356096177\n",
      "F1 micro for structure type classification: 0.9247648902821317\n",
      "F1 weighted for structure type classification: 0.9186103249924505\n",
      "Kappa for structure type classification: 0.888598229962588\n",
      "-------------Iteration 6/10\n",
      "train: 1000\n",
      "test: 957\n",
      "random_state = 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9205851619644723\n",
      "F1 macro for structure type classification: 0.7787781024945827\n",
      "F1 micro for structure type classification: 0.9205851619644723\n",
      "F1 weighted for structure type classification: 0.9165436692603729\n",
      "Kappa for structure type classification: 0.8831783356623139\n",
      "-------------Iteration 7/10\n",
      "train: 1000\n",
      "test: 957\n",
      "random_state = 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9216300940438872\n",
      "F1 macro for structure type classification: 0.8136767380848695\n",
      "F1 micro for structure type classification: 0.9216300940438872\n",
      "F1 weighted for structure type classification: 0.9176052976594847\n",
      "Kappa for structure type classification: 0.8847413806946831\n",
      "-------------Iteration 8/10\n",
      "train: 1000\n",
      "test: 957\n",
      "random_state = 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9143155694879833\n",
      "F1 macro for structure type classification: 0.7904915283499638\n",
      "F1 micro for structure type classification: 0.9143155694879833\n",
      "F1 weighted for structure type classification: 0.9076909088913941\n",
      "Kappa for structure type classification: 0.873591731932126\n",
      "-------------Iteration 9/10\n",
      "train: 1000\n",
      "test: 957\n",
      "random_state = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9237199582027168\n",
      "F1 macro for structure type classification: 0.8164718599305241\n",
      "F1 micro for structure type classification: 0.9237199582027168\n",
      "F1 weighted for structure type classification: 0.9195705257853937\n",
      "Kappa for structure type classification: 0.8876368531692356\n",
      "-------------Iteration 10/10\n",
      "train: 1000\n",
      "test: 957\n",
      "random_state = 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.928944618599791\n",
      "F1 macro for structure type classification: 0.8178163595227758\n",
      "F1 micro for structure type classification: 0.928944618599791\n",
      "F1 weighted for structure type classification: 0.9234743095532694\n",
      "Kappa for structure type classification: 0.8950392175521731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for classification\n",
    "    X_train, y_train, X_test, y_test, le = prepare_dataset_classification(\n",
    "        scattering_patterns, \n",
    "        structure_types, \n",
    "        max_test_data=max_test_data, \n",
    "        train_size=train_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Classification of structure_type\n",
    "    y_test, y_pred, acc, f1_macro, f1_micro, f1_weighted, kappa = train_and_evaluate_classifier(\n",
    "        X_train, \n",
    "        y_train,  \n",
    "        X_test, \n",
    "        y_test, \n",
    "        le,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    acc_scores.append(acc)\n",
    "    f1macro_scores.append(f1_macro)\n",
    "    f1micro_scores.append(f1_micro)\n",
    "    f1weighted_scores.append(f1_weighted)\n",
    "    kappa_scores.append(kappa)\n",
    "    print(f\"Accuracy for structure type classification: {acc}\")\n",
    "    print(f\"F1 macro for structure type classification: {f1_macro}\")\n",
    "    print(f\"F1 micro for structure type classification: {f1_micro}\")\n",
    "    print(f\"F1 weighted for structure type classification: {f1_weighted}\")\n",
    "    print(f\"Kappa for structure type classification: {kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 1000\n",
      "mean accuracy for structure type classification: 0.919853709508882 +/- 0.007225159420297834\n",
      "mean F1 macro for structure type classification: 0.7978946014900161 +/- 0.016208200511396462\n",
      "mean F1 micro for structure type classification: 0.919853709508882 +/- 0.007225159420297834\n",
      "mean F1 weighted for structure type classification: 0.9142649393932303 +/- 0.008022838775081507\n",
      "mean Kappa for structure type classification: 0.8818965619205763 +/- 0.010603074003857382\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean accuracy for structure type classification: {np.mean(acc_scores)} +/- {np.std(acc_scores)}\")\n",
    "print(f\"mean F1 macro for structure type classification: {np.mean(f1macro_scores)} +/- {np.std(f1macro_scores)}\")\n",
    "print(f\"mean F1 micro for structure type classification: {np.mean(f1micro_scores)} +/- {np.std(f1micro_scores)}\")\n",
    "print(f\"mean F1 weighted for structure type classification: {np.mean(f1weighted_scores)} +/- {np.std(f1weighted_scores)}\")\n",
    "print(f\"mean Kappa for structure type classification: {np.mean(kappa_scores)} +/- {np.std(kappa_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>[4, 3, 0, 3, 3, 1, 3, 3, 3, 2, 1, 3, 1, 3, 3, ...</td>\n",
       "      <td>[1, 3, 0, 3, 3, 1, 3, 3, 3, 2, 1, 3, 5, 3, 3, ...</td>\n",
       "      <td>0.929990</td>\n",
       "      <td>0.806383</td>\n",
       "      <td>0.929990</td>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.897015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>[5, 3, 3, 6, 6, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[2, 3, 3, 6, 6, 0, 3, 3, 3, 3, 3, 3, 1, 3, 3, ...</td>\n",
       "      <td>0.916405</td>\n",
       "      <td>0.777528</td>\n",
       "      <td>0.916405</td>\n",
       "      <td>0.907796</td>\n",
       "      <td>0.876771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>[3, 1, 1, 1, 3, 3, 5, 3, 3, 3, 6, 3, 3, 3, 3, ...</td>\n",
       "      <td>[3, 1, 1, 1, 3, 1, 2, 3, 3, 3, 6, 3, 3, 3, 3, ...</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.774905</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.899033</td>\n",
       "      <td>0.861341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0        1000  [4, 3, 0, 3, 3, 1, 3, 3, 3, 2, 1, 3, 1, 3, 3, ...   \n",
       "1        1000  [5, 3, 3, 6, 6, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "2        1000  [3, 1, 1, 1, 3, 3, 5, 3, 3, 3, 6, 3, 3, 3, 3, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [1, 3, 0, 3, 3, 1, 3, 3, 3, 2, 1, 3, 5, 3, 3, ...  0.929990  0.806383   \n",
       "1  [2, 3, 3, 6, 6, 0, 3, 3, 3, 3, 3, 3, 1, 3, 3, ...  0.916405  0.777528   \n",
       "2  [3, 1, 1, 1, 3, 1, 2, 3, 3, 3, 6, 3, 3, 3, 3, ...  0.905956  0.774905   \n",
       "\n",
       "   f1_micro  f1_weighted     kappa  \n",
       "0  0.929990     0.925414  0.897015  \n",
       "1  0.916405     0.907796  0.876771  \n",
       "2  0.905956     0.899033  0.861341  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_1000 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_1000.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1400\n",
    "iterations = 10\n",
    "max_test_data = 2000\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "acc_scores = []\n",
    "f1macro_scores = []\n",
    "f1micro_scores = []\n",
    "f1weighted_scores = []\n",
    "kappa_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 1400\n",
      "test: 557\n",
      "random_state = 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9353680430879713\n",
      "F1 macro for structure type classification: 0.8331619010452594\n",
      "F1 micro for structure type classification: 0.9353680430879713\n",
      "F1 weighted for structure type classification: 0.9327243289358773\n",
      "Kappa for structure type classification: 0.904617389773911\n",
      "-------------Iteration 2/10\n",
      "train: 1400\n",
      "test: 557\n",
      "random_state = 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9389587073608617\n",
      "F1 macro for structure type classification: 0.8314472475235213\n",
      "F1 micro for structure type classification: 0.9389587073608617\n",
      "F1 weighted for structure type classification: 0.9312070565737546\n",
      "Kappa for structure type classification: 0.9096822807870967\n",
      "-------------Iteration 3/10\n",
      "train: 1400\n",
      "test: 557\n",
      "random_state = 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9084380610412927\n",
      "F1 macro for structure type classification: 0.7676989738055621\n",
      "F1 micro for structure type classification: 0.9084380610412927\n",
      "F1 weighted for structure type classification: 0.9019704370039872\n",
      "Kappa for structure type classification: 0.8652949739903169\n",
      "-------------Iteration 4/10\n",
      "train: 1400\n",
      "test: 557\n",
      "random_state = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.933572710951526\n",
      "F1 macro for structure type classification: 0.8280250551334681\n",
      "F1 micro for structure type classification: 0.933572710951526\n",
      "F1 weighted for structure type classification: 0.9265823437442018\n",
      "Kappa for structure type classification: 0.9017889479804044\n",
      "-------------Iteration 5/10\n",
      "train: 1400\n",
      "test: 557\n",
      "random_state = 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.940754039497307\n",
      "F1 macro for structure type classification: 0.8232673231516346\n",
      "F1 micro for structure type classification: 0.940754039497307\n",
      "F1 weighted for structure type classification: 0.9344627576258274\n",
      "Kappa for structure type classification: 0.9121371312756631\n",
      "-------------Iteration 6/10\n",
      "train: 1400\n",
      "test: 557\n",
      "random_state = 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.940754039497307\n",
      "F1 macro for structure type classification: 0.83909269488972\n",
      "F1 micro for structure type classification: 0.940754039497307\n",
      "F1 weighted for structure type classification: 0.9364280312237313\n",
      "Kappa for structure type classification: 0.9125368177124721\n",
      "-------------Iteration 7/10\n",
      "train: 1400\n",
      "test: 557\n",
      "random_state = 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9371633752244165\n",
      "F1 macro for structure type classification: 0.8446492358945425\n",
      "F1 micro for structure type classification: 0.9371633752244165\n",
      "F1 weighted for structure type classification: 0.9316664526024099\n",
      "Kappa for structure type classification: 0.9071073923360621\n",
      "-------------Iteration 8/10\n",
      "train: 1400\n",
      "test: 557\n",
      "random_state = 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9461400359066428\n",
      "F1 macro for structure type classification: 0.8687791185630152\n",
      "F1 micro for structure type classification: 0.9461400359066428\n",
      "F1 weighted for structure type classification: 0.9423961583207703\n",
      "Kappa for structure type classification: 0.9203238542083881\n",
      "-------------Iteration 9/10\n",
      "train: 1400\n",
      "test: 557\n",
      "random_state = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9281867145421903\n",
      "F1 macro for structure type classification: 0.8470935432029376\n",
      "F1 micro for structure type classification: 0.9281867145421903\n",
      "F1 weighted for structure type classification: 0.9264374635249787\n",
      "Kappa for structure type classification: 0.8947612052392672\n",
      "-------------Iteration 10/10\n",
      "train: 1400\n",
      "test: 557\n",
      "random_state = 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9515260323159784\n",
      "F1 macro for structure type classification: 0.873853157292358\n",
      "F1 micro for structure type classification: 0.9515260323159784\n",
      "F1 weighted for structure type classification: 0.9488663715663689\n",
      "Kappa for structure type classification: 0.9283164201585342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for classification\n",
    "    X_train, y_train, X_test, y_test, le = prepare_dataset_classification(\n",
    "        scattering_patterns, \n",
    "        structure_types, \n",
    "        max_test_data=max_test_data, \n",
    "        train_size=train_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Classification of structure_type\n",
    "    y_test, y_pred, acc, f1_macro, f1_micro, f1_weighted, kappa = train_and_evaluate_classifier(\n",
    "        X_train, \n",
    "        y_train,  \n",
    "        X_test, \n",
    "        y_test, \n",
    "        le,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    acc_scores.append(acc)\n",
    "    f1macro_scores.append(f1_macro)\n",
    "    f1micro_scores.append(f1_micro)\n",
    "    f1weighted_scores.append(f1_weighted)\n",
    "    kappa_scores.append(kappa)\n",
    "    print(f\"Accuracy for structure type classification: {acc}\")\n",
    "    print(f\"F1 macro for structure type classification: {f1_macro}\")\n",
    "    print(f\"F1 micro for structure type classification: {f1_micro}\")\n",
    "    print(f\"F1 weighted for structure type classification: {f1_weighted}\")\n",
    "    print(f\"Kappa for structure type classification: {kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 1400\n",
      "mean accuracy for structure type classification: 0.9360861759425495 +/- 0.011072993856451895\n",
      "mean F1 macro for structure type classification: 0.8357068250502019 +/- 0.02762869288374587\n",
      "mean F1 micro for structure type classification: 0.9360861759425495 +/- 0.011072993856451895\n",
      "mean F1 weighted for structure type classification: 0.9312741401121908 +/- 0.011731541408290701\n",
      "mean Kappa for structure type classification: 0.9056566413462116 +/- 0.016124672252104105\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean accuracy for structure type classification: {np.mean(acc_scores)} +/- {np.std(acc_scores)}\")\n",
    "print(f\"mean F1 macro for structure type classification: {np.mean(f1macro_scores)} +/- {np.std(f1macro_scores)}\")\n",
    "print(f\"mean F1 micro for structure type classification: {np.mean(f1micro_scores)} +/- {np.std(f1micro_scores)}\")\n",
    "print(f\"mean F1 weighted for structure type classification: {np.mean(f1weighted_scores)} +/- {np.std(f1weighted_scores)}\")\n",
    "print(f\"mean Kappa for structure type classification: {np.mean(kappa_scores)} +/- {np.std(kappa_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400</td>\n",
       "      <td>[1, 2, 6, 3, 3, 3, 3, 0, 3, 1, 1, 0, 0, 3, 3, ...</td>\n",
       "      <td>[1, 2, 6, 3, 3, 3, 3, 0, 3, 1, 1, 0, 0, 3, 3, ...</td>\n",
       "      <td>0.935368</td>\n",
       "      <td>0.833162</td>\n",
       "      <td>0.935368</td>\n",
       "      <td>0.932724</td>\n",
       "      <td>0.904617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400</td>\n",
       "      <td>[3, 3, 0, 3, 3, 6, 6, 6, 3, 6, 6, 3, 1, 0, 3, ...</td>\n",
       "      <td>[3, 3, 0, 3, 3, 6, 6, 6, 3, 6, 6, 3, 1, 0, 3, ...</td>\n",
       "      <td>0.938959</td>\n",
       "      <td>0.831447</td>\n",
       "      <td>0.938959</td>\n",
       "      <td>0.931207</td>\n",
       "      <td>0.909682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1400</td>\n",
       "      <td>[3, 3, 1, 1, 1, 3, 0, 3, 3, 6, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[3, 3, 1, 1, 1, 3, 0, 3, 3, 6, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>0.908438</td>\n",
       "      <td>0.767699</td>\n",
       "      <td>0.908438</td>\n",
       "      <td>0.901970</td>\n",
       "      <td>0.865295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0        1400  [1, 2, 6, 3, 3, 3, 3, 0, 3, 1, 1, 0, 0, 3, 3, ...   \n",
       "1        1400  [3, 3, 0, 3, 3, 6, 6, 6, 3, 6, 6, 3, 1, 0, 3, ...   \n",
       "2        1400  [3, 3, 1, 1, 1, 3, 0, 3, 3, 6, 3, 3, 3, 3, 3, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [1, 2, 6, 3, 3, 3, 3, 0, 3, 1, 1, 0, 0, 3, 3, ...  0.935368  0.833162   \n",
       "1  [3, 3, 0, 3, 3, 6, 6, 6, 3, 6, 6, 3, 1, 0, 3, ...  0.938959  0.831447   \n",
       "2  [3, 3, 1, 1, 1, 3, 0, 3, 3, 6, 3, 3, 3, 3, 3, ...  0.908438  0.767699   \n",
       "\n",
       "   f1_micro  f1_weighted     kappa  \n",
       "0  0.935368     0.932724  0.904617  \n",
       "1  0.938959     0.931207  0.909682  \n",
       "2  0.908438     0.901970  0.865295  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_1400 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_1400.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training size = 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1800\n",
    "iterations = 10\n",
    "max_test_data = 2000\n",
    "y_test_all = []\n",
    "y_pred_all = []\n",
    "acc_scores = []\n",
    "f1macro_scores = []\n",
    "f1micro_scores = []\n",
    "f1weighted_scores = []\n",
    "kappa_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Iteration 1/10\n",
      "train: 1800\n",
      "test: 157\n",
      "random_state = 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9235668789808917\n",
      "F1 macro for structure type classification: 0.8086149567039291\n",
      "F1 micro for structure type classification: 0.9235668789808917\n",
      "F1 weighted for structure type classification: 0.9209335041425218\n",
      "Kappa for structure type classification: 0.887111270896998\n",
      "-------------Iteration 2/10\n",
      "train: 1800\n",
      "test: 157\n",
      "random_state = 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9363057324840764\n",
      "F1 macro for structure type classification: 0.8396978994611092\n",
      "F1 micro for structure type classification: 0.9363057324840764\n",
      "F1 weighted for structure type classification: 0.9308787200099139\n",
      "Kappa for structure type classification: 0.9058470764617691\n",
      "-------------Iteration 3/10\n",
      "train: 1800\n",
      "test: 157\n",
      "random_state = 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9363057324840764\n",
      "F1 macro for structure type classification: 0.8402168292340944\n",
      "F1 micro for structure type classification: 0.9363057324840764\n",
      "F1 weighted for structure type classification: 0.9322310443836477\n",
      "Kappa for structure type classification: 0.9060836274451157\n",
      "-------------Iteration 4/10\n",
      "train: 1800\n",
      "test: 157\n",
      "random_state = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9299363057324841\n",
      "F1 macro for structure type classification: 0.773325172095664\n",
      "F1 micro for structure type classification: 0.9299363057324841\n",
      "F1 weighted for structure type classification: 0.91328973139561\n",
      "Kappa for structure type classification: 0.8959638554216868\n",
      "-------------Iteration 5/10\n",
      "train: 1800\n",
      "test: 157\n",
      "random_state = 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9426751592356688\n",
      "F1 macro for structure type classification: 0.8224803252611929\n",
      "F1 micro for structure type classification: 0.9426751592356688\n",
      "F1 weighted for structure type classification: 0.9350673580780635\n",
      "Kappa for structure type classification: 0.9151657060518732\n",
      "-------------Iteration 6/10\n",
      "train: 1800\n",
      "test: 157\n",
      "random_state = 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9426751592356688\n",
      "F1 macro for structure type classification: 0.8474489795918368\n",
      "F1 micro for structure type classification: 0.9426751592356688\n",
      "F1 weighted for structure type classification: 0.9384895359417651\n",
      "Kappa for structure type classification: 0.9153588115490595\n",
      "-------------Iteration 7/10\n",
      "train: 1800\n",
      "test: 157\n",
      "random_state = 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9490445859872612\n",
      "F1 macro for structure type classification: 0.8192682512658118\n",
      "F1 micro for structure type classification: 0.9490445859872612\n",
      "F1 weighted for structure type classification: 0.9319548679159491\n",
      "Kappa for structure type classification: 0.9247904191616767\n",
      "-------------Iteration 8/10\n",
      "train: 1800\n",
      "test: 157\n",
      "random_state = 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9554140127388535\n",
      "F1 macro for structure type classification: 0.8458049886621316\n",
      "F1 micro for structure type classification: 0.9554140127388535\n",
      "F1 weighted for structure type classification: 0.9477302598321706\n",
      "Kappa for structure type classification: 0.9342781963879918\n",
      "-------------Iteration 9/10\n",
      "train: 1800\n",
      "test: 157\n",
      "random_state = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9299363057324841\n",
      "F1 macro for structure type classification: 0.8630146398181914\n",
      "F1 micro for structure type classification: 0.9299363057324841\n",
      "F1 weighted for structure type classification: 0.9267508854280806\n",
      "Kappa for structure type classification: 0.8974039089882968\n",
      "-------------Iteration 10/10\n",
      "train: 1800\n",
      "test: 157\n",
      "random_state = 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for structure type classification: 0.9490445859872612\n",
      "F1 macro for structure type classification: 0.8152644108490854\n",
      "F1 micro for structure type classification: 0.9490445859872612\n",
      "F1 weighted for structure type classification: 0.9393198021948713\n",
      "Kappa for structure type classification: 0.9244556718392879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "for n in range(iterations):\n",
    "    print(f\"-------------Iteration {n + 1}/{iterations}\")\n",
    "    random_state=42+n\n",
    "\n",
    "    # Prepare dataset for classification\n",
    "    X_train, y_train, X_test, y_test, le = prepare_dataset_classification(\n",
    "        scattering_patterns, \n",
    "        structure_types, \n",
    "        max_test_data=max_test_data, \n",
    "        train_size=train_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    print(f\"random_state = {random_state}\")\n",
    "\n",
    "    # Classification of structure_type\n",
    "    y_test, y_pred, acc, f1_macro, f1_micro, f1_weighted, kappa = train_and_evaluate_classifier(\n",
    "        X_train, \n",
    "        y_train,  \n",
    "        X_test, \n",
    "        y_test, \n",
    "        le,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    y_test_all.append(y_test)\n",
    "    y_pred_all.append(y_pred)\n",
    "    acc_scores.append(acc)\n",
    "    f1macro_scores.append(f1_macro)\n",
    "    f1micro_scores.append(f1_micro)\n",
    "    f1weighted_scores.append(f1_weighted)\n",
    "    kappa_scores.append(kappa)\n",
    "    print(f\"Accuracy for structure type classification: {acc}\")\n",
    "    print(f\"F1 macro for structure type classification: {f1_macro}\")\n",
    "    print(f\"F1 micro for structure type classification: {f1_micro}\")\n",
    "    print(f\"F1 weighted for structure type classification: {f1_weighted}\")\n",
    "    print(f\"Kappa for structure type classification: {kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------PDF dataset-----------\n",
      "FINAL REPORT for training size = 1800\n",
      "mean accuracy for structure type classification: 0.9394904458598725 +/- 0.009554140127388533\n",
      "mean F1 macro for structure type classification: 0.8275136452943046 +/- 0.02416413452933735\n",
      "mean F1 micro for structure type classification: 0.9394904458598725 +/- 0.009554140127388533\n",
      "mean F1 weighted for structure type classification: 0.9316645709322595 +/- 0.009234855641063628\n",
      "mean Kappa for structure type classification: 0.9106458544203756 +/- 0.014073156715246064\n"
     ]
    }
   ],
   "source": [
    "print(f\"-----------PDF dataset-----------\")\n",
    "print(f\"FINAL REPORT for training size = {train_size}\")\n",
    "\n",
    "print(f\"mean accuracy for structure type classification: {np.mean(acc_scores)} +/- {np.std(acc_scores)}\")\n",
    "print(f\"mean F1 macro for structure type classification: {np.mean(f1macro_scores)} +/- {np.std(f1macro_scores)}\")\n",
    "print(f\"mean F1 micro for structure type classification: {np.mean(f1micro_scores)} +/- {np.std(f1micro_scores)}\")\n",
    "print(f\"mean F1 weighted for structure type classification: {np.mean(f1weighted_scores)} +/- {np.std(f1weighted_scores)}\")\n",
    "print(f\"mean Kappa for structure type classification: {np.mean(kappa_scores)} +/- {np.std(kappa_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1800</td>\n",
       "      <td>[1, 3, 5, 0, 3, 3, 1, 3, 3, 1, 3, 1, 1, 1, 6, ...</td>\n",
       "      <td>[1, 3, 2, 6, 3, 3, 1, 3, 3, 1, 3, 1, 1, 1, 6, ...</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.808615</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.920934</td>\n",
       "      <td>0.887111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>[1, 3, 3, 3, 3, 2, 0, 1, 3, 6, 2, 3, 3, 3, 5, ...</td>\n",
       "      <td>[1, 3, 3, 3, 3, 1, 0, 1, 3, 2, 2, 3, 3, 3, 5, ...</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.839698</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.930879</td>\n",
       "      <td>0.905847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1800</td>\n",
       "      <td>[3, 0, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 6, 0, 2, ...</td>\n",
       "      <td>[3, 0, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 6, 0, 1, ...</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.840217</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>0.932231</td>\n",
       "      <td>0.906084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0        1800  [1, 3, 5, 0, 3, 3, 1, 3, 3, 1, 3, 1, 1, 1, 6, ...   \n",
       "1        1800  [1, 3, 3, 3, 3, 2, 0, 1, 3, 6, 2, 3, 3, 3, 5, ...   \n",
       "2        1800  [3, 0, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 6, 0, 2, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [1, 3, 2, 6, 3, 3, 1, 3, 3, 1, 3, 1, 1, 1, 6, ...  0.923567  0.808615   \n",
       "1  [1, 3, 3, 3, 3, 1, 0, 1, 3, 2, 2, 3, 3, 3, 5, ...  0.936306  0.839698   \n",
       "2  [3, 0, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 6, 0, 1, ...  0.936306  0.840217   \n",
       "\n",
       "   f1_micro  f1_weighted     kappa  \n",
       "0  0.923567     0.920934  0.887111  \n",
       "1  0.936306     0.930879  0.905847  \n",
       "2  0.936306     0.932231  0.906084  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res_1800 = pd.DataFrame(metrics_dict())\n",
    "compiled_res_1800.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>[1, 2, 3, 3, 5, 3, 1, 3, 4, 3, 3, 3, 3, 2, 3, ...</td>\n",
       "      <td>[1, 2, 3, 3, 1, 3, 1, 1, 4, 3, 3, 3, 3, 1, 3, ...</td>\n",
       "      <td>0.890936</td>\n",
       "      <td>0.732349</td>\n",
       "      <td>0.890936</td>\n",
       "      <td>0.883563</td>\n",
       "      <td>0.839210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>[3, 1, 5, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...</td>\n",
       "      <td>[3, 1, 1, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...</td>\n",
       "      <td>0.891673</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.891673</td>\n",
       "      <td>0.885769</td>\n",
       "      <td>0.840220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>[1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 4, 1, 3, 3, ...</td>\n",
       "      <td>[1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 1, 1, 3, 3, ...</td>\n",
       "      <td>0.876934</td>\n",
       "      <td>0.714508</td>\n",
       "      <td>0.876934</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.818390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600</td>\n",
       "      <td>[1, 1, 3, 3, 1, 0, 3, 1, 3, 0, 1, 3, 2, 1, 3, ...</td>\n",
       "      <td>[1, 1, 3, 3, 1, 6, 3, 1, 3, 0, 1, 3, 2, 1, 3, ...</td>\n",
       "      <td>0.902727</td>\n",
       "      <td>0.775148</td>\n",
       "      <td>0.902727</td>\n",
       "      <td>0.895392</td>\n",
       "      <td>0.856788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600</td>\n",
       "      <td>[3, 6, 3, 3, 3, 2, 3, 5, 0, 3, 3, 4, 2, 3, 3, ...</td>\n",
       "      <td>[3, 6, 3, 3, 3, 2, 3, 5, 0, 3, 3, 1, 2, 3, 3, ...</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.759790</td>\n",
       "      <td>0.899779</td>\n",
       "      <td>0.892229</td>\n",
       "      <td>0.851242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0         600  [1, 2, 3, 3, 5, 3, 1, 3, 4, 3, 3, 3, 3, 2, 3, ...   \n",
       "1         600  [3, 1, 5, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...   \n",
       "2         600  [1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 4, 1, 3, 3, ...   \n",
       "3         600  [1, 1, 3, 3, 1, 0, 3, 1, 3, 0, 1, 3, 2, 1, 3, ...   \n",
       "4         600  [3, 6, 3, 3, 3, 2, 3, 5, 0, 3, 3, 4, 2, 3, 3, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [1, 2, 3, 3, 1, 3, 1, 1, 4, 3, 3, 3, 3, 1, 3, ...  0.890936  0.732349   \n",
       "1  [3, 1, 1, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...  0.891673  0.731214   \n",
       "2  [1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 1, 1, 3, 3, ...  0.876934  0.714508   \n",
       "3  [1, 1, 3, 3, 1, 6, 3, 1, 3, 0, 1, 3, 2, 1, 3, ...  0.902727  0.775148   \n",
       "4  [3, 6, 3, 3, 3, 2, 3, 5, 0, 3, 3, 1, 2, 3, 3, ...  0.899779  0.759790   \n",
       "\n",
       "   f1_micro  f1_weighted     kappa  \n",
       "0  0.890936     0.883563  0.839210  \n",
       "1  0.891673     0.885769  0.840220  \n",
       "2  0.876934     0.869318  0.818390  \n",
       "3  0.902727     0.895392  0.856788  \n",
       "4  0.899779     0.892229  0.851242  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_res = pd.concat([\n",
    "    compiled_res_600,\n",
    "    compiled_res_1000,\n",
    "    compiled_res_1400,\n",
    "    compiled_res_1800\n",
    "], ignore_index=True)\n",
    "print(len(compiled_res))\n",
    "compiled_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_res[\"y_true\"] = compiled_res[\"y_true\"].apply(lambda arr: list(arr))\n",
    "compiled_res[\"y_pred\"] = compiled_res[\"y_pred\"].apply(lambda arr: list(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_res.to_csv(\"RF_results_structure_type_7cat_unbalanced.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   train_size   40 non-null     int64  \n",
      " 1   y_true       40 non-null     object \n",
      " 2   y_pred       40 non-null     object \n",
      " 3   accuracy     40 non-null     float64\n",
      " 4   f1_macro     40 non-null     float64\n",
      " 5   f1_micro     40 non-null     float64\n",
      " 6   f1_weighted  40 non-null     float64\n",
      " 7   kappa        40 non-null     float64\n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"RF_results_structure_type_7cat_unbalanced.csv\", sep=',')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>[1, 2, 3, 3, 5, 3, 1, 3, 4, 3, 3, 3, 3, 2, 3, ...</td>\n",
       "      <td>[1, 2, 3, 3, 1, 3, 1, 1, 4, 3, 3, 3, 3, 1, 3, ...</td>\n",
       "      <td>0.890936</td>\n",
       "      <td>0.732349</td>\n",
       "      <td>0.890936</td>\n",
       "      <td>0.883563</td>\n",
       "      <td>0.83921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>[3, 1, 5, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...</td>\n",
       "      <td>[3, 1, 1, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...</td>\n",
       "      <td>0.891673</td>\n",
       "      <td>0.731214</td>\n",
       "      <td>0.891673</td>\n",
       "      <td>0.885769</td>\n",
       "      <td>0.84022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>[1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 4, 1, 3, 3, ...</td>\n",
       "      <td>[1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 1, 1, 3, 3, ...</td>\n",
       "      <td>0.876934</td>\n",
       "      <td>0.714508</td>\n",
       "      <td>0.876934</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.81839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size                                             y_true  \\\n",
       "0         600  [1, 2, 3, 3, 5, 3, 1, 3, 4, 3, 3, 3, 3, 2, 3, ...   \n",
       "1         600  [3, 1, 5, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...   \n",
       "2         600  [1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 4, 1, 3, 3, ...   \n",
       "\n",
       "                                              y_pred  accuracy  f1_macro  \\\n",
       "0  [1, 2, 3, 3, 1, 3, 1, 1, 4, 3, 3, 3, 3, 1, 3, ...  0.890936  0.732349   \n",
       "1  [3, 1, 1, 3, 3, 6, 3, 1, 1, 3, 3, 3, 3, 6, 5, ...  0.891673  0.731214   \n",
       "2  [1, 3, 1, 0, 6, 1, 2, 3, 3, 3, 1, 1, 1, 3, 3, ...  0.876934  0.714508   \n",
       "\n",
       "   f1_micro  f1_weighted    kappa  \n",
       "0  0.890936     0.883563  0.83921  \n",
       "1  0.891673     0.885769  0.84022  \n",
       "2  0.876934     0.869318  0.81839  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_macro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_micro</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_weighted</th>\n",
       "      <th colspan=\"2\" halign=\"left\">kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.891010</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.740119</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.891010</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.883369</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.838659</td>\n",
       "      <td>0.004423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.919854</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.797895</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.919854</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.914265</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.881897</td>\n",
       "      <td>0.003534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>0.936086</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.835707</td>\n",
       "      <td>0.009210</td>\n",
       "      <td>0.936086</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.931274</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.905657</td>\n",
       "      <td>0.005375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>0.939490</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.827514</td>\n",
       "      <td>0.008055</td>\n",
       "      <td>0.939490</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.931665</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.910646</td>\n",
       "      <td>0.004691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy            f1_macro            f1_micro            \\\n",
       "                mean       sem      mean       sem      mean       sem   \n",
       "train_size                                                               \n",
       "600         0.891010  0.002949  0.740119  0.006475  0.891010  0.002949   \n",
       "1000        0.919854  0.002408  0.797895  0.005403  0.919854  0.002408   \n",
       "1400        0.936086  0.003691  0.835707  0.009210  0.936086  0.003691   \n",
       "1800        0.939490  0.003185  0.827514  0.008055  0.939490  0.003185   \n",
       "\n",
       "           f1_weighted               kappa            \n",
       "                  mean       sem      mean       sem  \n",
       "train_size                                            \n",
       "600           0.883369  0.003136  0.838659  0.004423  \n",
       "1000          0.914265  0.002674  0.881897  0.003534  \n",
       "1400          0.931274  0.003911  0.905657  0.005375  \n",
       "1800          0.931665  0.003078  0.910646  0.004691  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_res = df.select_dtypes(include = [\"int\", \"float\"]).groupby(['train_size']).agg(['mean', 'sem'])\n",
    "grouped_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mats = []\n",
    "for i in np.arange(len(df)):\n",
    "    confusion_matrix = {\n",
    "        'all_y_true': literal_eval(df[\"y_true\"][i]),\n",
    "        'all_y_pred': literal_eval(df[\"y_pred\"][i])\n",
    "    }\n",
    "    conf_mats.append(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97058824 0.         0.         0.         0.         0.\n",
      "  0.02941176]\n",
      " [0.         0.98148148 0.0037037  0.0037037  0.         0.01111111\n",
      "  0.        ]\n",
      " [0.         0.2125     0.75       0.         0.         0.0375\n",
      "  0.        ]\n",
      " [0.         0.00987654 0.         0.99012346 0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.03333333 0.         0.93333333 0.\n",
      "  0.03333333]\n",
      " [0.         0.38333333 0.4        0.01666667 0.         0.2\n",
      "  0.        ]\n",
      " [0.02       0.         0.02666667 0.         0.         0.\n",
      "  0.95333333]]\n",
      "accuracy: 0.9394904458598726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f7cd819c910>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 330x250 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_maxsize = compiled_res[compiled_res[\"train_size\"]==max(compiled_res[\"train_size\"])].index\n",
    "conf_mats_max = [conf_mats[i] for i in index_maxsize]\n",
    "\n",
    "actual_all, predicted_all = [], []\n",
    "for index, _ in enumerate(conf_mats_max):\n",
    "    preds = conf_mats_max[index]\n",
    "    actual = preds[\"all_y_true\"]\n",
    "    predicted = preds[\"all_y_pred\"]\n",
    "    \n",
    "    for true, pred in zip(actual, predicted):\n",
    "        actual_all.append(true)\n",
    "        predicted_all.append(pred)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual_all, predicted_all)\n",
    "confusion_matrix_norm = confusion_matrix.astype(\"float\") / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "print(confusion_matrix_norm)\n",
    "\n",
    "cm = pycm.ConfusionMatrix(list(actual_all), list(predicted_all))\n",
    "acc = cm.Overall_ACC\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "cm_display = metrics.ConfusionMatrixDisplay(\n",
    "    confusion_matrix = confusion_matrix_norm, display_labels = [0, 1, 2, 3, 4, 5, 6])\n",
    "cm_display.plot(cmap=plt.cm.Blues, include_values=True, values_format=\".1f\")\n",
    "#plt.savefig('classif_struct_type_confusionMatrix_7cat_uunbalanced_30ep_size1800_RF.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97058824 0.         0.         0.         0.         0.\n",
      "  0.02941176]\n",
      " [0.         0.98148148 0.0037037  0.0037037  0.         0.01111111\n",
      "  0.        ]\n",
      " [0.         0.2125     0.75       0.         0.         0.0375\n",
      "  0.        ]\n",
      " [0.         0.00987654 0.         0.99012346 0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.03333333 0.         0.93333333 0.\n",
      "  0.03333333]\n",
      " [0.         0.38333333 0.4        0.01666667 0.         0.2\n",
      "  0.        ]\n",
      " [0.02       0.         0.02666667 0.         0.         0.\n",
      "  0.95333333]]\n",
      "accuracy: 0.9394904458598726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f7cd8117ee0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 330x250 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_maxsize = compiled_res[compiled_res[\"train_size\"]==max(compiled_res[\"train_size\"])].index\n",
    "conf_mats_max = [conf_mats[i] for i in index_maxsize]\n",
    "\n",
    "actual_all, predicted_all = [], []\n",
    "for index, _ in enumerate(conf_mats_max):\n",
    "    preds = conf_mats_max[index]\n",
    "    actual = preds[\"all_y_true\"]\n",
    "    predicted = preds[\"all_y_pred\"]\n",
    "    \n",
    "    for true, pred in zip(actual, predicted):\n",
    "        actual_all.append(true)\n",
    "        predicted_all.append(pred)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual_all, predicted_all)\n",
    "confusion_matrix_norm = confusion_matrix.astype(\"float\") / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "print(confusion_matrix_norm)\n",
    "\n",
    "cm = pycm.ConfusionMatrix(list(actual_all), list(predicted_all))\n",
    "acc = cm.Overall_ACC\n",
    "\n",
    "print(f'accuracy: {acc}')\n",
    "\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "cm_display = metrics.ConfusionMatrixDisplay(\n",
    "    confusion_matrix = confusion_matrix_norm, display_labels = ['BCC', 'Dec', 'FCC', 'HCP', 'Ico', 'Oct', 'SC'])\n",
    "cm_display.plot(cmap=plt.cm.Blues, include_values=True, values_format=\".1f\")\n",
    "#plt.savefig('classif_struct_type_confusionMatrix_7cat_unbalanced_30ep_size1800_RF.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debyecalculator_env]",
   "language": "python",
   "name": "conda-env-debyecalculator_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
