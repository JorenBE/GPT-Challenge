{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional machine learning\n",
    "Feature(s): 'SMILES' column\n",
    "    translate to morgan fingerprint\n",
    "\n",
    "target: mp_bin\n",
    "    binary class of melting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Append the parent directory of your package to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..', '..')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset from the zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique smiles: 273237\n",
      "Count of all of the smiles: 273237\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "path_to_dataset = 'train_meltingPoint_noDuplicates.zip'\n",
    "csv_filename = 'train_meltingPoint_noDuplicates.csv'\n",
    "\n",
    "# Open the file, Correct the encoding and sep if necessary\n",
    "if path_to_dataset.endswith('.zip'):\n",
    "    with zipfile.ZipFile(path_to_dataset, 'r') as z:\n",
    "        # Open the CSV file within the ZIP file\n",
    "        with z.open(csv_filename) as f:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(f, sep=',', on_bad_lines='warn')\n",
    "else:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(path_to_dataset, sep=',', on_bad_lines='warn')\n",
    "\n",
    "\n",
    "print('Count of unique smiles:', df.SMILES.unique().shape[0])\n",
    "print('Count of all of the smiles:', df.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsmo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from MLPipeline import MLmodel, BinTheTarget\n",
    "\n",
    "Target = 'mp_bin'\n",
    "Features = ['SMILES']\n",
    "Feature_types = ['SMILES']\n",
    "input = df[:7000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random forest classifier model without hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:12:30] Explicit valence for atom # 10 S, 9, is greater than permitted\n",
      "[18:12:32] Explicit valence for atom # 16 S, 9, is greater than permitted\n",
      "[18:12:32] Explicit valence for atom # 10 S, 9, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "model = MLmodel(modelType='RandomForestClassifier',\n",
    "                    df=input,\n",
    "                    target=Target,\n",
    "                    features=Features,\n",
    "                    feature_types=Feature_types)\n",
    "\n",
    "# get the values (input and output) of the model\n",
    "X_train, X_test, y_train, y_test = model.getValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information about the dataset such as the splitting, wrong smiles, total number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin 0 fraction in original set: 0.5149349721309132\n",
      "bin 1 fraction in original set: 0.48506502786908673\n",
      "bin 0 fraction in training set: 0.52\n",
      "bin 1 fraction in training set: 0.48\n",
      "bin 0 fraction in test set: 0.52\n",
      "bin 1 fraction in test set: 0.48\n"
     ]
    }
   ],
   "source": [
    "number_of_samples, number_of_wrong_smiles, clean_df = model.getdfAnalysis(orginal_df=input)\n",
    "print('Number of samples:', number_of_samples)\n",
    "print('Number of wrong smiles:', number_of_wrong_smiles)\n",
    "\n",
    "\n",
    "for i in range(len(clean_df.mp_bin.value_counts())):\n",
    "    print(f'bin {i} fraction in original set:' , \n",
    "          clean_df.mp_bin.value_counts()[i]/clean_df.mp_bin.value_counts().sum())\n",
    "\n",
    "for i in range (len(pd.DataFrame(y_train).value_counts())):\n",
    "    print(f'bin {i} fraction in training set:' , \n",
    "          pd.DataFrame(y_train).value_counts()[i]/pd.DataFrame(y_train).value_counts().sum())\n",
    "\n",
    "for i in range(len(pd.DataFrame(y_test).value_counts())):\n",
    "    print(f'bin {i} fraction in test set:' , \n",
    "          pd.DataFrame(y_test).value_counts()[i]/pd.DataFrame(y_test).value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier model trained successfully.\n",
      "Accuracy for RandomForestClassifier: 0.68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the random forest classifier using hyperparameter optimization with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "def objective(trial, model_instance):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to minimize.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters to tune\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [None, 10, 20, 30, 40]),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 6),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "\n",
    "    # Clone the model to ensure a fresh instance each trial\n",
    "    model_clone = clone(model_instance.model)\n",
    "    model_clone.set_params(**params)\n",
    "    \n",
    "    # Define the score metric\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model_clone, model_instance.X_train, model_instance.y_train, cv=model_instance.cv, scoring=scoring)\n",
    "\n",
    "    # Return the average score across all folds\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:12:36] Explicit valence for atom # 10 S, 9, is greater than permitted\n",
      "[18:12:38] Explicit valence for atom # 16 S, 9, is greater than permitted\n",
      "[18:12:39] Explicit valence for atom # 10 S, 9, is greater than permitted\n",
      "[I 2024-09-11 18:12:40,274] A new study created in memory with name: no-name-e8d1e17b-ca87-4a31-8deb-c7b115a13cce\n",
      "[I 2024-09-11 18:12:40,726] Trial 0 finished with value: 0.54 and parameters: {'n_estimators': 117, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.54.\n",
      "[I 2024-09-11 18:12:41,723] Trial 1 finished with value: 0.58 and parameters: {'n_estimators': 185, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 1 with value: 0.58.\n",
      "[I 2024-09-11 18:12:42,855] Trial 2 finished with value: 0.62 and parameters: {'n_estimators': 288, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 2 with value: 0.62.\n",
      "[I 2024-09-11 18:12:43,539] Trial 3 finished with value: 0.58 and parameters: {'n_estimators': 178, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 2 with value: 0.62.\n",
      "[I 2024-09-11 18:12:44,420] Trial 4 finished with value: 0.66 and parameters: {'n_estimators': 222, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:45,413] Trial 5 finished with value: 0.56 and parameters: {'n_estimators': 260, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:46,016] Trial 6 finished with value: 0.56 and parameters: {'n_estimators': 163, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:46,838] Trial 7 finished with value: 0.5599999999999999 and parameters: {'n_estimators': 156, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:47,957] Trial 8 finished with value: 0.6 and parameters: {'n_estimators': 293, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:48,214] Trial 9 finished with value: 0.58 and parameters: {'n_estimators': 64, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:49,481] Trial 10 finished with value: 0.5599999999999999 and parameters: {'n_estimators': 230, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:50,399] Trial 11 finished with value: 0.5800000000000001 and parameters: {'n_estimators': 234, 'max_depth': 40, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:51,595] Trial 12 finished with value: 0.6599999999999999 and parameters: {'n_estimators': 294, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:52,524] Trial 13 finished with value: 0.66 and parameters: {'n_estimators': 226, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:53,677] Trial 14 finished with value: 0.62 and parameters: {'n_estimators': 209, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:54,690] Trial 15 finished with value: 0.6 and parameters: {'n_estimators': 249, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:55,521] Trial 16 finished with value: 0.58 and parameters: {'n_estimators': 208, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:56,053] Trial 17 finished with value: 0.6399999999999999 and parameters: {'n_estimators': 129, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:57,189] Trial 18 finished with value: 0.54 and parameters: {'n_estimators': 202, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:58,275] Trial 19 finished with value: 0.56 and parameters: {'n_estimators': 264, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:12:58,868] Trial 20 finished with value: 0.6 and parameters: {'n_estimators': 135, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:13:00,071] Trial 21 finished with value: 0.6199999999999999 and parameters: {'n_estimators': 272, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:13:01,173] Trial 22 finished with value: 0.5599999999999999 and parameters: {'n_estimators': 234, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:13:02,269] Trial 23 finished with value: 0.6199999999999999 and parameters: {'n_estimators': 279, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.66.\n",
      "[I 2024-09-11 18:13:03,246] Trial 24 finished with value: 0.7000000000000001 and parameters: {'n_estimators': 249, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:04,129] Trial 25 finished with value: 0.62 and parameters: {'n_estimators': 227, 'max_depth': 40, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:05,150] Trial 26 finished with value: 0.52 and parameters: {'n_estimators': 194, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:06,120] Trial 27 finished with value: 0.6199999999999999 and parameters: {'n_estimators': 243, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:06,990] Trial 28 finished with value: 0.5799999999999998 and parameters: {'n_estimators': 224, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:07,278] Trial 29 finished with value: 0.58 and parameters: {'n_estimators': 69, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:08,293] Trial 30 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 251, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:09,499] Trial 31 finished with value: 0.64 and parameters: {'n_estimators': 293, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:10,596] Trial 32 finished with value: 0.56 and parameters: {'n_estimators': 272, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:11,550] Trial 33 finished with value: 0.64 and parameters: {'n_estimators': 216, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:12,881] Trial 34 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:13,642] Trial 35 finished with value: 0.6 and parameters: {'n_estimators': 187, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:14,980] Trial 36 finished with value: 0.5 and parameters: {'n_estimators': 256, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:15,660] Trial 37 finished with value: 0.5199999999999999 and parameters: {'n_estimators': 173, 'max_depth': None, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:16,815] Trial 38 finished with value: 0.6 and parameters: {'n_estimators': 282, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:17,770] Trial 39 finished with value: 0.64 and parameters: {'n_estimators': 243, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:19,194] Trial 40 finished with value: 0.6199999999999999 and parameters: {'n_estimators': 264, 'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:20,376] Trial 41 finished with value: 0.64 and parameters: {'n_estimators': 292, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:21,525] Trial 42 finished with value: 0.6199999999999999 and parameters: {'n_estimators': 286, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:22,737] Trial 43 finished with value: 0.6 and parameters: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:23,099] Trial 44 finished with value: 0.58 and parameters: {'n_estimators': 85, 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:24,197] Trial 45 finished with value: 0.64 and parameters: {'n_estimators': 273, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:25,029] Trial 46 finished with value: 0.6 and parameters: {'n_estimators': 217, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:25,999] Trial 47 finished with value: 0.58 and parameters: {'n_estimators': 239, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:26,858] Trial 48 finished with value: 0.58 and parameters: {'n_estimators': 161, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 24 with value: 0.7000000000000001.\n",
      "[I 2024-09-11 18:13:27,930] Trial 49 finished with value: 0.52 and parameters: {'n_estimators': 260, 'max_depth': 30, 'min_samples_split': 12, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 24 with value: 0.7000000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier model trained successfully.\n",
      "Accuracy for RandomForestClassifier: 0.64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLmodel(modelType='RandomForestClassifier', df=input, target=Target, \n",
    "                features=['SMILES'], hyperparameter_tuning=True,\n",
    "                feature_types=Feature_types,\n",
    "                optimization_method='optuna', objective=lambda trial: objective(trial, model))\n",
    "\n",
    "model.train()\n",
    "predictions = model.predict()\n",
    "model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JorenML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
