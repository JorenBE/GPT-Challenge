{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional machine learning\n",
    "Feature(s): 'SMILES' column\n",
    "    translate to morgan fingerprint\n",
    "\n",
    "target: mp_bin\n",
    "    binary class of melting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Append the parent directory of your package to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..', '..')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset from the zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique smiles: 273237\n",
      "Count of all of the smiles: 273237\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "path_to_dataset = 'train_meltingPoint_noDuplicates.zip'\n",
    "csv_filename = 'train_meltingPoint_noDuplicates.csv'\n",
    "\n",
    "# Open the file, Correct the encoding and sep if necessary\n",
    "if path_to_dataset.endswith('.zip'):\n",
    "    with zipfile.ZipFile(path_to_dataset, 'r') as z:\n",
    "        # Open the CSV file within the ZIP file\n",
    "        with z.open(csv_filename) as f:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(f, sep=',', on_bad_lines='warn', index_col = 0)\n",
    "else:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(path_to_dataset, sep=',', on_bad_lines='warn', index_col = 0)\n",
    "\n",
    "\n",
    "print('Count of unique smiles:', df.SMILES.unique().shape[0])\n",
    "print('Count of all of the smiles:', df.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsmo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from MLPipeline import MLmodel, BinTheTarget\n",
    "\n",
    "Target = ['mp_bin']\n",
    "Features = ['SMILES']\n",
    "Feature_types = ['SMILES']\n",
    "input = df[:7000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random forest classifier model without hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:08:59] Explicit valence for atom # 10 S, 9, is greater than permitted\n",
      "[17:09:01] Explicit valence for atom # 16 S, 9, is greater than permitted\n",
      "[17:09:01] Explicit valence for atom # 10 S, 9, is greater than permitted\n",
      "\u001b[32m2024-09-12 17:09:03.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mndim y_train: 1\u001b[0m\n",
      "\u001b[32m2024-09-12 17:09:03.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mndim x_train: 2\u001b[0m\n",
      "\u001b[32m2024-09-12 17:09:03.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mshape y_train: (50,)\u001b[0m\n",
      "\u001b[32m2024-09-12 17:09:03.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mshape x_train: (50, 512)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = MLmodel(modelType='RandomForestClassifier',\n",
    "                    df=input,\n",
    "                    target=Target,\n",
    "                    features=Features,\n",
    "                    feature_types=Feature_types)\n",
    "\n",
    "# get the values (input and output) of the model\n",
    "X_train, X_test, y_train, y_test = model.getValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information about the dataset such as the splitting, wrong smiles, total number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 7000\n",
      "Number of wrong smiles: 3\n",
      "bin 0 fraction in original set: 0.5149349721309132\n",
      "bin 1 fraction in original set: 0.48506502786908673\n",
      "bin 0 fraction in training set: 0.48\n",
      "bin 1 fraction in training set: 0.52\n",
      "bin 0 fraction in test set: 0.42\n",
      "bin 1 fraction in test set: 0.58\n"
     ]
    }
   ],
   "source": [
    "number_of_samples, number_of_wrong_smiles, clean_df = model.getdfAnalysis(orginal_df=input)\n",
    "print('Number of samples:', number_of_samples)\n",
    "print('Number of wrong smiles:', number_of_wrong_smiles)\n",
    "\n",
    "\n",
    "for i in range(len(clean_df.mp_bin.value_counts())):\n",
    "    print(f'bin {i} fraction in original set:' , \n",
    "          clean_df.mp_bin.value_counts()[i]/clean_df.mp_bin.value_counts().sum())\n",
    "\n",
    "for i in range (len(pd.DataFrame(y_train).value_counts())):\n",
    "    print(f'bin {i} fraction in training set:' , \n",
    "          pd.DataFrame(y_train).value_counts()[i]/pd.DataFrame(y_train).value_counts().sum())\n",
    "\n",
    "for i in range(len(pd.DataFrame(y_test).value_counts())):\n",
    "    print(f'bin {i} fraction in test set:' , \n",
    "          pd.DataFrame(y_test).value_counts()[i]/pd.DataFrame(y_test).value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier model trained successfully.\n",
      "Accuracy for RandomForestClassifier: 0.58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the random forest classifier using hyperparameter optimization with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "def objective(trial, model_instance):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to minimize.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters to tune\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [None, 10, 20, 30, 40]),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 6),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "\n",
    "    # Clone the model to ensure a fresh instance each trial\n",
    "    model_clone = clone(model_instance.model)\n",
    "    model_clone.set_params(**params)\n",
    "    \n",
    "    # Define the score metric\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model_clone, model_instance.X_train, model_instance.y_train, cv=model_instance.cv, scoring=scoring)\n",
    "\n",
    "    # Return the average score across all folds\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:09:06] Explicit valence for atom # 10 S, 9, is greater than permitted\n",
      "[17:09:08] Explicit valence for atom # 16 S, 9, is greater than permitted\n",
      "[17:09:09] Explicit valence for atom # 10 S, 9, is greater than permitted\n",
      "\u001b[32m2024-09-12 17:09:10.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mndim y_train: 1\u001b[0m\n",
      "\u001b[32m2024-09-12 17:09:10.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mndim x_train: 2\u001b[0m\n",
      "\u001b[32m2024-09-12 17:09:10.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mshape y_train: (50,)\u001b[0m\n",
      "\u001b[32m2024-09-12 17:09:10.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mshape x_train: (50, 512)\u001b[0m\n",
      "[I 2024-09-12 17:09:10,416] A new study created in memory with name: no-name-7d09ac84-9333-4061-9a56-a98c03c2a5c4\n",
      "[I 2024-09-12 17:09:11,539] Trial 0 finished with value: 0.6599999999999999 and parameters: {'n_estimators': 298, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.6599999999999999.\n",
      "[I 2024-09-12 17:09:11,805] Trial 1 finished with value: 0.62 and parameters: {'n_estimators': 69, 'max_depth': 30, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.6599999999999999.\n",
      "[I 2024-09-12 17:09:12,069] Trial 2 finished with value: 0.62 and parameters: {'n_estimators': 69, 'max_depth': 40, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.6599999999999999.\n",
      "[I 2024-09-12 17:09:12,905] Trial 3 finished with value: 0.6199999999999999 and parameters: {'n_estimators': 158, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.6599999999999999.\n",
      "[I 2024-09-12 17:09:13,681] Trial 4 finished with value: 0.54 and parameters: {'n_estimators': 221, 'max_depth': 20, 'min_samples_split': 11, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.6599999999999999.\n",
      "[I 2024-09-12 17:09:14,587] Trial 5 finished with value: 0.6199999999999999 and parameters: {'n_estimators': 183, 'max_depth': 40, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.6599999999999999.\n",
      "[I 2024-09-12 17:09:14,802] Trial 6 finished with value: 0.58 and parameters: {'n_estimators': 57, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.6599999999999999.\n",
      "[I 2024-09-12 17:09:15,664] Trial 7 finished with value: 0.58 and parameters: {'n_estimators': 239, 'max_depth': None, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.6599999999999999.\n",
      "[I 2024-09-12 17:09:16,463] Trial 8 finished with value: 0.64 and parameters: {'n_estimators': 159, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.6599999999999999.\n",
      "[I 2024-09-12 17:09:16,725] Trial 9 finished with value: 0.54 and parameters: {'n_estimators': 52, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.6599999999999999.\n",
      "[I 2024-09-12 17:09:17,791] Trial 10 finished with value: 0.6599999999999999 and parameters: {'n_estimators': 296, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.6599999999999999.\n",
      "[I 2024-09-12 17:09:18,862] Trial 11 finished with value: 0.68 and parameters: {'n_estimators': 297, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 0.68.\n",
      "[I 2024-09-12 17:09:19,891] Trial 12 finished with value: 0.6599999999999999 and parameters: {'n_estimators': 281, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 0.68.\n",
      "[I 2024-09-12 17:09:20,853] Trial 13 finished with value: 0.6599999999999999 and parameters: {'n_estimators': 260, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 11 with value: 0.68.\n",
      "[I 2024-09-12 17:09:21,615] Trial 14 finished with value: 0.7 and parameters: {'n_estimators': 211, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:22,046] Trial 15 finished with value: 0.6599999999999999 and parameters: {'n_estimators': 117, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:22,791] Trial 16 finished with value: 0.6 and parameters: {'n_estimators': 206, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:23,225] Trial 17 finished with value: 0.5800000000000001 and parameters: {'n_estimators': 118, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:24,483] Trial 18 finished with value: 0.64 and parameters: {'n_estimators': 253, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:25,217] Trial 19 finished with value: 0.54 and parameters: {'n_estimators': 205, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:26,201] Trial 20 finished with value: 0.64 and parameters: {'n_estimators': 272, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:27,307] Trial 21 finished with value: 0.68 and parameters: {'n_estimators': 291, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:28,173] Trial 22 finished with value: 0.64 and parameters: {'n_estimators': 236, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:29,215] Trial 23 finished with value: 0.6599999999999999 and parameters: {'n_estimators': 269, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:30,288] Trial 24 finished with value: 0.64 and parameters: {'n_estimators': 299, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:31,160] Trial 25 finished with value: 0.62 and parameters: {'n_estimators': 244, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:32,105] Trial 26 finished with value: 0.68 and parameters: {'n_estimators': 184, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:33,129] Trial 27 finished with value: 0.66 and parameters: {'n_estimators': 283, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 14 with value: 0.7.\n",
      "[I 2024-09-12 17:09:33,941] Trial 28 finished with value: 0.7200000000000001 and parameters: {'n_estimators': 219, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:34,755] Trial 29 finished with value: 0.58 and parameters: {'n_estimators': 216, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:35,268] Trial 30 finished with value: 0.6199999999999999 and parameters: {'n_estimators': 133, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:36,119] Trial 31 finished with value: 0.6799999999999999 and parameters: {'n_estimators': 230, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:36,889] Trial 32 finished with value: 0.6 and parameters: {'n_estimators': 202, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:37,876] Trial 33 finished with value: 0.6199999999999999 and parameters: {'n_estimators': 261, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:38,964] Trial 34 finished with value: 0.6 and parameters: {'n_estimators': 287, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:39,570] Trial 35 finished with value: 0.66 and parameters: {'n_estimators': 160, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:40,331] Trial 36 finished with value: 0.6799999999999999 and parameters: {'n_estimators': 195, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:40,797] Trial 37 finished with value: 0.6 and parameters: {'n_estimators': 89, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:41,634] Trial 38 finished with value: 0.62 and parameters: {'n_estimators': 222, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:42,581] Trial 39 finished with value: 0.64 and parameters: {'n_estimators': 249, 'max_depth': 30, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:43,449] Trial 40 finished with value: 0.5399999999999999 and parameters: {'n_estimators': 172, 'max_depth': 20, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:44,383] Trial 41 finished with value: 0.64 and parameters: {'n_estimators': 181, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:45,129] Trial 42 finished with value: 0.62 and parameters: {'n_estimators': 143, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:46,089] Trial 43 finished with value: 0.6399999999999999 and parameters: {'n_estimators': 184, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:46,954] Trial 44 finished with value: 0.64 and parameters: {'n_estimators': 168, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:47,940] Trial 45 finished with value: 0.64 and parameters: {'n_estimators': 191, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:49,115] Trial 46 finished with value: 0.54 and parameters: {'n_estimators': 220, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:49,670] Trial 47 finished with value: 0.7000000000000001 and parameters: {'n_estimators': 145, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:50,249] Trial 48 finished with value: 0.62 and parameters: {'n_estimators': 149, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n",
      "[I 2024-09-12 17:09:50,685] Trial 49 finished with value: 0.7 and parameters: {'n_estimators': 111, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 28 with value: 0.7200000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForestClassifier model trained successfully with hyperparameter tuning using Optuna.\n",
      "Best hyperparameters: {'n_estimators': 219, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}\n",
      "RandomForestClassifier model trained successfully.\n",
      "Accuracy for RandomForestClassifier: 0.56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLmodel(modelType='RandomForestClassifier', df=input, target=Target, \n",
    "                features=['SMILES'], hyperparameter_tuning=True,\n",
    "                feature_types=Feature_types,\n",
    "                optimization_method='optuna', objective=lambda trial: objective(trial, model))\n",
    "\n",
    "model.train()\n",
    "predictions = model.predict()\n",
    "model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JorenML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
