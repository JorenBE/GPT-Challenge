{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional machine learning\n",
    "Feature(s): 'SMILES' column\n",
    "\n",
    "- Copolymer sequence of A and B monomer\n",
    "- Binary encoding\n",
    "\n",
    "Target: y_bin\n",
    "\n",
    "- Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import clone\n",
    "from loguru import logger\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"WARNING\")\n",
    "# Append the parent directory of your package to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..', '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique smiles: 16000\n",
      "Count of all of the smiles: 16000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "path_to_dataset = 'train_polymers.csv'\n",
    "csv_filename = 'train_polymers.csv'\n",
    "\n",
    "# Open the file, Correct the encoding and sep if necessary\n",
    "if path_to_dataset.endswith('.zip'):\n",
    "    with zipfile.ZipFile(path_to_dataset, 'r') as z:\n",
    "        # Open the CSV file within the ZIP file\n",
    "        with z.open(csv_filename) as f:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(f, sep=',', on_bad_lines='warn', index_col = 0)\n",
    "else:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(path_to_dataset, sep=',', on_bad_lines='warn', index_col = 0)\n",
    "\n",
    "\n",
    "print('Count of unique smiles:', df.SMILES.unique().shape[0])\n",
    "print('Count of all of the smiles:', df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping\n",
    "mapping = {'A': 0, 'B': 1}\n",
    "\n",
    "# Apply mapping and convert sequences to arrays\n",
    "def encode_sequence(sequence):\n",
    "    return np.array([mapping[char] for char in sequence.split()])\n",
    "\n",
    "df['Encoded'] = df['SMILES'].apply(encode_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>y</th>\n",
       "      <th>y_bin</th>\n",
       "      <th>Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B B B B A A B B B A B A B B B A B B B B</td>\n",
       "      <td>7.759848</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B B B A A A B B A A B A B A B B B A B B</td>\n",
       "      <td>8.133042</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A A B B A B B A B A B B B B A B B B B B</td>\n",
       "      <td>7.717979</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B B B A B A A A A B A B A B A B B B B B</td>\n",
       "      <td>8.147355</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B B B B B B A B B A B B B B B B B B B A</td>\n",
       "      <td>7.603120</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    SMILES         y  y_bin  \\\n",
       "0  B B B B A A B B B A B A B B B A B B B B  7.759848      0   \n",
       "1  B B B A A A B B A A B A B A B B B A B B  8.133042      0   \n",
       "2  A A B B A B B A B A B B B B A B B B B B  7.717979      0   \n",
       "3  B B B A B A A A A B A B A B A B B B B B  8.147355      0   \n",
       "4  B B B B B B A B B A B B B B B B B B B A  7.603120      0   \n",
       "\n",
       "                                             Encoded  \n",
       "0  [1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, ...  \n",
       "2  [0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, ...  \n",
       "3  [1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLPipeline import MLmodel, BinTheTarget\n",
    "\n",
    "Target = ['y_bin']\n",
    "Features = ['Encoded']\n",
    "Feature_types = ['numerical']\n",
    "input = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveRandomForestClassifier(trial, model_instance):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to minimize.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters to tune\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [None, 10, 20, 30, 40]),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 6),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "\n",
    "    # Clone the model to ensure a fresh instance each trial\n",
    "    model_clone = clone(model_instance.model)\n",
    "    model_clone.set_params(**params)\n",
    "    \n",
    "    # Define the score metric\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model_clone, model_instance.X_train, model_instance.y_train, cv=model_instance.cv, scoring=scoring)\n",
    "\n",
    "    # Return the average score across all folds\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "def objectiveXGBClassifier(trial, model_instance):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to minimize for XGBClassifier.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters to tune\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),  # L1 regularization\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),  # L2 regularization\n",
    "    }\n",
    "\n",
    "    # Clone the model to ensure a fresh instance each trial\n",
    "    model_clone = clone(model_instance.model)\n",
    "    model_clone.set_params(**params)\n",
    "    \n",
    "    # Define the score metric\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model_clone, model_instance.X_train, model_instance.y_train, cv=model_instance.cv, scoring=scoring)\n",
    "\n",
    "    # Return the average score across all folds\n",
    "    return scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:46:30,141]\u001b[0m A new study created in memory with name: no-name-7790be5e-7046-4f7a-b365-6a683099ebf7\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:30,303]\u001b[0m Trial 0 finished with value: 0.75 and parameters: {'n_estimators': 76, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.75.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:100 / Seed:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:46:31,032]\u001b[0m Trial 1 finished with value: 0.8099999999999999 and parameters: {'n_estimators': 292, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 1 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:31,221]\u001b[0m Trial 2 finished with value: 0.74 and parameters: {'n_estimators': 72, 'max_depth': 20, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 1 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:31,504]\u001b[0m Trial 3 finished with value: 0.76 and parameters: {'n_estimators': 145, 'max_depth': 30, 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 1 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:31,950]\u001b[0m Trial 4 finished with value: 0.8 and parameters: {'n_estimators': 179, 'max_depth': 30, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 1 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:32,327]\u001b[0m Trial 5 finished with value: 0.76 and parameters: {'n_estimators': 196, 'max_depth': 30, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 1 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:33,040]\u001b[0m Trial 6 finished with value: 0.7899999999999999 and parameters: {'n_estimators': 288, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 1 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:33,450]\u001b[0m Trial 7 finished with value: 0.7700000000000001 and parameters: {'n_estimators': 212, 'max_depth': None, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 1 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:34,006]\u001b[0m Trial 8 finished with value: 0.78 and parameters: {'n_estimators': 287, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 1 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:34,314]\u001b[0m Trial 9 finished with value: 0.78 and parameters: {'n_estimators': 158, 'max_depth': None, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 1 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:34,472]\u001b[0m A new study created in memory with name: no-name-82202542-c864-487b-b74f-9001e505dac0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:500 / Seed:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:46:34,825]\u001b[0m Trial 0 finished with value: 0.8220000000000001 and parameters: {'n_estimators': 122, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.8220000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:35,444]\u001b[0m Trial 1 finished with value: 0.826 and parameters: {'n_estimators': 215, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 1 with value: 0.826.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:36,023]\u001b[0m Trial 2 finished with value: 0.8320000000000001 and parameters: {'n_estimators': 243, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 2 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:36,408]\u001b[0m Trial 3 finished with value: 0.8300000000000001 and parameters: {'n_estimators': 161, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 2 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:37,226]\u001b[0m Trial 4 finished with value: 0.826 and parameters: {'n_estimators': 286, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 2 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:37,854]\u001b[0m Trial 5 finished with value: 0.8240000000000001 and parameters: {'n_estimators': 225, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 2 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:38,477]\u001b[0m Trial 6 finished with value: 0.828 and parameters: {'n_estimators': 219, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 2 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:38,682]\u001b[0m Trial 7 finished with value: 0.818 and parameters: {'n_estimators': 70, 'max_depth': 40, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 2 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:39,483]\u001b[0m Trial 8 finished with value: 0.8240000000000001 and parameters: {'n_estimators': 283, 'max_depth': 30, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 2 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:40,341]\u001b[0m Trial 9 finished with value: 0.8239999999999998 and parameters: {'n_estimators': 300, 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 2 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:40,471]\u001b[0m A new study created in memory with name: no-name-0aaa981e-e929-457b-b3fa-0d4bf7475fdf\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:1000 / Seed:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:46:40,891]\u001b[0m Trial 0 finished with value: 0.821 and parameters: {'n_estimators': 141, 'max_depth': 20, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.821.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:41,471]\u001b[0m Trial 1 finished with value: 0.8099999999999999 and parameters: {'n_estimators': 172, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.821.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:42,043]\u001b[0m Trial 2 finished with value: 0.8140000000000001 and parameters: {'n_estimators': 187, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.821.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:42,785]\u001b[0m Trial 3 finished with value: 0.8150000000000001 and parameters: {'n_estimators': 256, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.821.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:43,678]\u001b[0m Trial 4 finished with value: 0.8130000000000001 and parameters: {'n_estimators': 268, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.821.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:44,242]\u001b[0m Trial 5 finished with value: 0.8019999999999999 and parameters: {'n_estimators': 169, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.821.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:44,607]\u001b[0m Trial 6 finished with value: 0.8099999999999999 and parameters: {'n_estimators': 112, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.821.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:45,236]\u001b[0m Trial 7 finished with value: 0.817 and parameters: {'n_estimators': 185, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.821.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:45,816]\u001b[0m Trial 8 finished with value: 0.8119999999999999 and parameters: {'n_estimators': 178, 'max_depth': 30, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.821.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:46,474]\u001b[0m Trial 9 finished with value: 0.818 and parameters: {'n_estimators': 220, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.821.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:46,575]\u001b[0m A new study created in memory with name: no-name-4d542191-e207-4e87-9ea8-2a652401ef86\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:5000 / Seed:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:46:48,211]\u001b[0m Trial 0 finished with value: 0.8433999999999999 and parameters: {'n_estimators': 241, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.8433999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:50,104]\u001b[0m Trial 1 finished with value: 0.8428000000000001 and parameters: {'n_estimators': 270, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.8433999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:50,712]\u001b[0m Trial 2 finished with value: 0.8426 and parameters: {'n_estimators': 90, 'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.8433999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:51,969]\u001b[0m Trial 3 finished with value: 0.8478 and parameters: {'n_estimators': 159, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 3 with value: 0.8478.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:53,444]\u001b[0m Trial 4 finished with value: 0.8458 and parameters: {'n_estimators': 192, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 3 with value: 0.8478.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:53,848]\u001b[0m Trial 5 finished with value: 0.8448 and parameters: {'n_estimators': 59, 'max_depth': 40, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 3 with value: 0.8478.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:54,807]\u001b[0m Trial 6 finished with value: 0.8441999999999998 and parameters: {'n_estimators': 145, 'max_depth': 30, 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 3 with value: 0.8478.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:56,679]\u001b[0m Trial 7 finished with value: 0.8438000000000001 and parameters: {'n_estimators': 269, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 3 with value: 0.8478.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:57,924]\u001b[0m Trial 8 finished with value: 0.8421999999999998 and parameters: {'n_estimators': 188, 'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 3 with value: 0.8478.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:58,648]\u001b[0m Trial 9 finished with value: 0.8485999999999999 and parameters: {'n_estimators': 94, 'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 9 with value: 0.8485999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:58,818]\u001b[0m A new study created in memory with name: no-name-9e01e4cc-bcca-4337-925d-40c2459ffe43\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:100 / Seed:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:46:59,021]\u001b[0m Trial 0 finished with value: 0.7699999999999999 and parameters: {'n_estimators': 206, 'max_depth': 3, 'learning_rate': 0.011443379247660061, 'subsample': 0.6698798025870328, 'colsample_bytree': 0.7193717472199362, 'gamma': 0.00010036228128395817, 'reg_alpha': 0.47690731318700696, 'reg_lambda': 0.03407385165863573}. Best is trial 0 with value: 0.7699999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:59,180]\u001b[0m Trial 1 finished with value: 0.7699999999999999 and parameters: {'n_estimators': 118, 'max_depth': 9, 'learning_rate': 0.03623479780548862, 'subsample': 0.5066378380601395, 'colsample_bytree': 0.560785193911985, 'gamma': 5.247665225640046e-05, 'reg_alpha': 0.003879648778974161, 'reg_lambda': 0.03496869746852019}. Best is trial 0 with value: 0.7699999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:59,302]\u001b[0m Trial 2 finished with value: 0.76 and parameters: {'n_estimators': 67, 'max_depth': 10, 'learning_rate': 0.08404377561478704, 'subsample': 0.7555379120794854, 'colsample_bytree': 0.730501435700986, 'gamma': 1.0616800004252485e-08, 'reg_alpha': 0.32574298541882835, 'reg_lambda': 9.486774577883779e-06}. Best is trial 0 with value: 0.7699999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:59,518]\u001b[0m Trial 3 finished with value: 0.78 and parameters: {'n_estimators': 102, 'max_depth': 6, 'learning_rate': 0.03021604581506184, 'subsample': 0.6248182751237158, 'colsample_bytree': 0.7484991254884141, 'gamma': 0.00018258502910985168, 'reg_alpha': 0.0006257677503320872, 'reg_lambda': 6.8954288084239345e-06}. Best is trial 3 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:59,678]\u001b[0m Trial 4 finished with value: 0.74 and parameters: {'n_estimators': 173, 'max_depth': 3, 'learning_rate': 0.15025746627310893, 'subsample': 0.8882144884951644, 'colsample_bytree': 0.667578937329752, 'gamma': 0.00028353301486353996, 'reg_alpha': 1.9006878823203158e-08, 'reg_lambda': 0.001664495129256299}. Best is trial 3 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:46:59,975]\u001b[0m Trial 5 finished with value: 0.75 and parameters: {'n_estimators': 254, 'max_depth': 4, 'learning_rate': 0.2497934924477276, 'subsample': 0.9896122346307548, 'colsample_bytree': 0.5822136396640896, 'gamma': 0.010226265743438377, 'reg_alpha': 5.6706722704170865e-08, 'reg_lambda': 0.001892298312159321}. Best is trial 3 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:00,129]\u001b[0m Trial 6 finished with value: 0.74 and parameters: {'n_estimators': 139, 'max_depth': 13, 'learning_rate': 0.1698655603476777, 'subsample': 0.9476037919482327, 'colsample_bytree': 0.7765068011538607, 'gamma': 0.0738534420344228, 'reg_alpha': 0.01824944037043948, 'reg_lambda': 1.3027990963381586e-08}. Best is trial 3 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:00,302]\u001b[0m Trial 7 finished with value: 0.76 and parameters: {'n_estimators': 133, 'max_depth': 14, 'learning_rate': 0.020726696484469915, 'subsample': 0.5820448730600021, 'colsample_bytree': 0.958152681476546, 'gamma': 1.902627297550038e-07, 'reg_alpha': 1.6465464980190815e-06, 'reg_lambda': 6.534644487796859e-05}. Best is trial 3 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:00,397]\u001b[0m Trial 8 finished with value: 0.7300000000000001 and parameters: {'n_estimators': 86, 'max_depth': 15, 'learning_rate': 0.2666054145253653, 'subsample': 0.7586346532578069, 'colsample_bytree': 0.8149303455038063, 'gamma': 0.008121685623819874, 'reg_alpha': 0.0005507858810488696, 'reg_lambda': 4.178591131211534e-08}. Best is trial 3 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:00,588]\u001b[0m Trial 9 finished with value: 0.78 and parameters: {'n_estimators': 202, 'max_depth': 11, 'learning_rate': 0.026449975579933904, 'subsample': 0.702205539507998, 'colsample_bytree': 0.5234760221666269, 'gamma': 4.498300516513868e-05, 'reg_alpha': 0.03737259428970445, 'reg_lambda': 0.13068760375594676}. Best is trial 3 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:00,631]\u001b[0m A new study created in memory with name: no-name-f0d946e3-cfea-4410-a590-14b923364f9d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:500 / Seed:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:47:01,423]\u001b[0m Trial 0 finished with value: 0.826 and parameters: {'n_estimators': 178, 'max_depth': 7, 'learning_rate': 0.015298634248627593, 'subsample': 0.8880175978106601, 'colsample_bytree': 0.5405446423394438, 'gamma': 6.449604035430262e-05, 'reg_alpha': 4.030114386870875e-05, 'reg_lambda': 1.8405039231622173e-07}. Best is trial 0 with value: 0.826.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:01,879]\u001b[0m Trial 1 finished with value: 0.842 and parameters: {'n_estimators': 68, 'max_depth': 12, 'learning_rate': 0.07488323465579129, 'subsample': 0.8463984758859247, 'colsample_bytree': 0.8226855568849833, 'gamma': 0.008724451919147494, 'reg_alpha': 0.0053497799016607025, 'reg_lambda': 6.705887513425426e-08}. Best is trial 1 with value: 0.842.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:02,174]\u001b[0m Trial 2 finished with value: 0.8379999999999999 and parameters: {'n_estimators': 97, 'max_depth': 9, 'learning_rate': 0.06915978305929256, 'subsample': 0.735021386522144, 'colsample_bytree': 0.780956220874138, 'gamma': 0.002430308571409111, 'reg_alpha': 1.9899985928490386e-05, 'reg_lambda': 0.8088654064149666}. Best is trial 1 with value: 0.842.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:02,386]\u001b[0m Trial 3 finished with value: 0.8320000000000001 and parameters: {'n_estimators': 103, 'max_depth': 10, 'learning_rate': 0.16057540562031947, 'subsample': 0.8162044306498353, 'colsample_bytree': 0.9920275640199798, 'gamma': 0.5153522595971625, 'reg_alpha': 4.1121394967015695e-06, 'reg_lambda': 0.437284631123705}. Best is trial 1 with value: 0.842.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:02,632]\u001b[0m Trial 4 finished with value: 0.82 and parameters: {'n_estimators': 102, 'max_depth': 8, 'learning_rate': 0.1817435946052505, 'subsample': 0.9330141273805249, 'colsample_bytree': 0.5813570335992408, 'gamma': 0.02577067244235914, 'reg_alpha': 1.1420394214953413e-05, 'reg_lambda': 2.816859507374008e-05}. Best is trial 1 with value: 0.842.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:02,959]\u001b[0m Trial 5 finished with value: 0.8240000000000001 and parameters: {'n_estimators': 209, 'max_depth': 6, 'learning_rate': 0.17432334125846188, 'subsample': 0.9519994047063319, 'colsample_bytree': 0.5611005768386189, 'gamma': 4.517586178989882e-05, 'reg_alpha': 0.7472294851608487, 'reg_lambda': 0.002102456791716264}. Best is trial 1 with value: 0.842.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:03,232]\u001b[0m Trial 6 finished with value: 0.8240000000000001 and parameters: {'n_estimators': 124, 'max_depth': 6, 'learning_rate': 0.013527507889765812, 'subsample': 0.5228606780240527, 'colsample_bytree': 0.6265656391907277, 'gamma': 3.885071340756736e-06, 'reg_alpha': 0.003811019263092825, 'reg_lambda': 0.5510281995571531}. Best is trial 1 with value: 0.842.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:03,592]\u001b[0m Trial 7 finished with value: 0.8320000000000001 and parameters: {'n_estimators': 278, 'max_depth': 11, 'learning_rate': 0.25228433930764077, 'subsample': 0.5729052024383787, 'colsample_bytree': 0.7715319362361488, 'gamma': 0.08499379938816122, 'reg_alpha': 1.4868597914724606e-06, 'reg_lambda': 4.003858785859784e-07}. Best is trial 1 with value: 0.842.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:03,846]\u001b[0m Trial 8 finished with value: 0.8160000000000001 and parameters: {'n_estimators': 52, 'max_depth': 15, 'learning_rate': 0.07164210949840388, 'subsample': 0.5057425391093253, 'colsample_bytree': 0.6193983834107826, 'gamma': 0.013223766988949576, 'reg_alpha': 2.2727912980421292e-08, 'reg_lambda': 6.626129416647778e-07}. Best is trial 1 with value: 0.842.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:04,207]\u001b[0m Trial 9 finished with value: 0.8240000000000001 and parameters: {'n_estimators': 63, 'max_depth': 14, 'learning_rate': 0.025244765278573823, 'subsample': 0.7957658644805616, 'colsample_bytree': 0.9392331432882213, 'gamma': 2.1712007604837963e-06, 'reg_alpha': 3.0276691203172504e-08, 'reg_lambda': 3.20109378265448e-05}. Best is trial 1 with value: 0.842.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:04,274]\u001b[0m A new study created in memory with name: no-name-da9908ba-6b5b-41bf-a3ae-13a329748bb9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:1000 / Seed:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:47:04,710]\u001b[0m Trial 0 finished with value: 0.837 and parameters: {'n_estimators': 69, 'max_depth': 15, 'learning_rate': 0.08128556865273733, 'subsample': 0.5793314889270815, 'colsample_bytree': 0.8635661736304687, 'gamma': 3.7679584683711377e-07, 'reg_alpha': 1.7632010237624751e-07, 'reg_lambda': 0.0008298027311930528}. Best is trial 0 with value: 0.837.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:04,955]\u001b[0m Trial 1 finished with value: 0.8300000000000001 and parameters: {'n_estimators': 78, 'max_depth': 4, 'learning_rate': 0.048641593303825094, 'subsample': 0.5753662646787312, 'colsample_bytree': 0.9096200518457809, 'gamma': 8.38789277664675e-07, 'reg_alpha': 0.009174574080021938, 'reg_lambda': 0.49642682390632015}. Best is trial 0 with value: 0.837.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:06,221]\u001b[0m Trial 2 finished with value: 0.837 and parameters: {'n_estimators': 119, 'max_depth': 11, 'learning_rate': 0.06520740500043003, 'subsample': 0.986289978210208, 'colsample_bytree': 0.6963833683235889, 'gamma': 0.0791824833233428, 'reg_alpha': 0.026960690181464728, 'reg_lambda': 0.003356228142760209}. Best is trial 0 with value: 0.837.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:06,888]\u001b[0m Trial 3 finished with value: 0.843 and parameters: {'n_estimators': 134, 'max_depth': 15, 'learning_rate': 0.07854348028728746, 'subsample': 0.7085531981039055, 'colsample_bytree': 0.7050438946467549, 'gamma': 2.5386820673619736e-05, 'reg_alpha': 6.467970140125771e-06, 'reg_lambda': 0.1971003799321742}. Best is trial 3 with value: 0.843.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:07,286]\u001b[0m Trial 4 finished with value: 0.867 and parameters: {'n_estimators': 264, 'max_depth': 4, 'learning_rate': 0.09521774133110437, 'subsample': 0.9651385973582548, 'colsample_bytree': 0.8345837079141437, 'gamma': 3.5012514201133323e-07, 'reg_alpha': 1.896463602054661e-08, 'reg_lambda': 1.7453454085236373e-08}. Best is trial 4 with value: 0.867.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:07,454]\u001b[0m Trial 5 finished with value: 0.817 and parameters: {'n_estimators': 124, 'max_depth': 3, 'learning_rate': 0.022474015429890925, 'subsample': 0.7223763502835991, 'colsample_bytree': 0.8226081974034432, 'gamma': 0.007635856974328733, 'reg_alpha': 0.01806820404936012, 'reg_lambda': 7.647620755470278e-07}. Best is trial 4 with value: 0.867.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:07,798]\u001b[0m Trial 6 finished with value: 0.8200000000000001 and parameters: {'n_estimators': 77, 'max_depth': 6, 'learning_rate': 0.05175676135023347, 'subsample': 0.9877339601407307, 'colsample_bytree': 0.9193304956578834, 'gamma': 0.00040513285855156556, 'reg_alpha': 0.007117230670124074, 'reg_lambda': 9.104827887875424e-07}. Best is trial 4 with value: 0.867.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:09,179]\u001b[0m Trial 7 finished with value: 0.833 and parameters: {'n_estimators': 205, 'max_depth': 12, 'learning_rate': 0.013153144818724921, 'subsample': 0.6621254107142355, 'colsample_bytree': 0.5033178124867448, 'gamma': 0.00012512226215591273, 'reg_alpha': 5.204147497749149e-06, 'reg_lambda': 0.004183519377345623}. Best is trial 4 with value: 0.867.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:10,026]\u001b[0m Trial 8 finished with value: 0.8390000000000001 and parameters: {'n_estimators': 212, 'max_depth': 14, 'learning_rate': 0.0688718179263859, 'subsample': 0.9757200671912076, 'colsample_bytree': 0.8811513915481306, 'gamma': 5.637650770121089e-07, 'reg_alpha': 8.46684750887097e-05, 'reg_lambda': 0.005036926007456622}. Best is trial 4 with value: 0.867.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:10,623]\u001b[0m Trial 9 finished with value: 0.857 and parameters: {'n_estimators': 231, 'max_depth': 7, 'learning_rate': 0.2872146413846845, 'subsample': 0.9454606488836785, 'colsample_bytree': 0.926508206952056, 'gamma': 0.03542178299216318, 'reg_alpha': 1.6174675349515136e-05, 'reg_lambda': 0.019382471900852568}. Best is trial 4 with value: 0.867.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:10,757]\u001b[0m A new study created in memory with name: no-name-7a87870d-f2d8-4cdc-b5a2-4a84ff2bef45\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:5000 / Seed:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:47:12,919]\u001b[0m Trial 0 finished with value: 0.8708 and parameters: {'n_estimators': 282, 'max_depth': 11, 'learning_rate': 0.21188015645892416, 'subsample': 0.5012432339407793, 'colsample_bytree': 0.84735760603567, 'gamma': 0.00023223452657445377, 'reg_alpha': 1.2001070008027153e-06, 'reg_lambda': 0.002932317363790136}. Best is trial 0 with value: 0.8708.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:14,788]\u001b[0m Trial 1 finished with value: 0.8655999999999999 and parameters: {'n_estimators': 279, 'max_depth': 6, 'learning_rate': 0.2064958112650745, 'subsample': 0.8281010200929972, 'colsample_bytree': 0.7684861764609598, 'gamma': 1.5170474107532456e-08, 'reg_alpha': 9.968434445508673e-05, 'reg_lambda': 3.336557497106265e-05}. Best is trial 0 with value: 0.8708.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:15,359]\u001b[0m Trial 2 finished with value: 0.8886 and parameters: {'n_estimators': 236, 'max_depth': 3, 'learning_rate': 0.2837966560788063, 'subsample': 0.7728714682692328, 'colsample_bytree': 0.5575846944845497, 'gamma': 0.08535563970387627, 'reg_alpha': 1.1866640999090827e-05, 'reg_lambda': 0.5879949987815367}. Best is trial 2 with value: 0.8886.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:19,261]\u001b[0m Trial 3 finished with value: 0.8488 and parameters: {'n_estimators': 174, 'max_depth': 14, 'learning_rate': 0.011997099923766696, 'subsample': 0.86655797098336, 'colsample_bytree': 0.5390805384811174, 'gamma': 4.482675759426422e-08, 'reg_alpha': 0.00033626579957295546, 'reg_lambda': 0.30087139667439095}. Best is trial 2 with value: 0.8886.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:22,943]\u001b[0m Trial 4 finished with value: 0.8573999999999999 and parameters: {'n_estimators': 182, 'max_depth': 11, 'learning_rate': 0.019961966613153758, 'subsample': 0.7286183882458968, 'colsample_bytree': 0.9321826185147344, 'gamma': 0.0013503370942611545, 'reg_alpha': 0.0018453569897505615, 'reg_lambda': 0.012047415993003765}. Best is trial 2 with value: 0.8886.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:25,609]\u001b[0m Trial 5 finished with value: 0.8615999999999999 and parameters: {'n_estimators': 131, 'max_depth': 14, 'learning_rate': 0.08320900273253848, 'subsample': 0.8031812289553326, 'colsample_bytree': 0.7003075947612292, 'gamma': 6.80680003638143e-07, 'reg_alpha': 0.006301140950312843, 'reg_lambda': 0.7321102362854768}. Best is trial 2 with value: 0.8886.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:28,677]\u001b[0m Trial 6 finished with value: 0.8623999999999998 and parameters: {'n_estimators': 278, 'max_depth': 9, 'learning_rate': 0.07838945752491497, 'subsample': 0.9519531590842086, 'colsample_bytree': 0.6857681128918494, 'gamma': 0.00015493589002263665, 'reg_alpha': 0.14300499450210155, 'reg_lambda': 0.00015874806211170692}. Best is trial 2 with value: 0.8886.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:30,792]\u001b[0m Trial 7 finished with value: 0.859 and parameters: {'n_estimators': 145, 'max_depth': 8, 'learning_rate': 0.026302177237379692, 'subsample': 0.671513394792138, 'colsample_bytree': 0.9816262187353215, 'gamma': 0.0023676046018640978, 'reg_alpha': 0.03448740665600463, 'reg_lambda': 4.615160406332272e-07}. Best is trial 2 with value: 0.8886.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:33,569]\u001b[0m Trial 8 finished with value: 0.8619999999999999 and parameters: {'n_estimators': 189, 'max_depth': 12, 'learning_rate': 0.04365292417430821, 'subsample': 0.559376748456971, 'colsample_bytree': 0.5250623202506857, 'gamma': 0.00016010952792071926, 'reg_alpha': 0.0016514920547611872, 'reg_lambda': 0.016736797806607452}. Best is trial 2 with value: 0.8886.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:33,911]\u001b[0m Trial 9 finished with value: 0.8438000000000001 and parameters: {'n_estimators': 62, 'max_depth': 4, 'learning_rate': 0.014402512213437961, 'subsample': 0.6076019267877018, 'colsample_bytree': 0.8971457032022945, 'gamma': 3.4895014568151417e-06, 'reg_alpha': 0.2360301949604858, 'reg_lambda': 1.2811414472396046e-08}. Best is trial 2 with value: 0.8886.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:34,060]\u001b[0m A new study created in memory with name: no-name-2fe7d001-4793-4018-a467-903615b9f7db\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:34,247]\u001b[0m Trial 0 finished with value: 0.79 and parameters: {'n_estimators': 91, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.79.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:100 / Seed:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:47:34,390]\u001b[0m Trial 1 finished with value: 0.79 and parameters: {'n_estimators': 69, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.79.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:35,092]\u001b[0m Trial 2 finished with value: 0.79 and parameters: {'n_estimators': 276, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.79.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:35,683]\u001b[0m Trial 3 finished with value: 0.8 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 3 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:36,204]\u001b[0m Trial 4 finished with value: 0.79 and parameters: {'n_estimators': 265, 'max_depth': 20, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 3 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:36,681]\u001b[0m Trial 5 finished with value: 0.8099999999999999 and parameters: {'n_estimators': 188, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}. Best is trial 5 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:37,149]\u001b[0m Trial 6 finished with value: 0.8 and parameters: {'n_estimators': 240, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 5 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:37,379]\u001b[0m Trial 7 finished with value: 0.8 and parameters: {'n_estimators': 117, 'max_depth': None, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 5 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:37,510]\u001b[0m Trial 8 finished with value: 0.7799999999999999 and parameters: {'n_estimators': 65, 'max_depth': None, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 5 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:37,848]\u001b[0m Trial 9 finished with value: 0.79 and parameters: {'n_estimators': 170, 'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 5 with value: 0.8099999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:37,956]\u001b[0m A new study created in memory with name: no-name-50b86acc-824f-4859-ab79-06073a6bf0e7\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:38,116]\u001b[0m Trial 0 finished with value: 0.808 and parameters: {'n_estimators': 53, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.808.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:500 / Seed:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:47:38,631]\u001b[0m Trial 1 finished with value: 0.8140000000000001 and parameters: {'n_estimators': 205, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 1 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:39,434]\u001b[0m Trial 2 finished with value: 0.8099999999999999 and parameters: {'n_estimators': 274, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 1 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:39,883]\u001b[0m Trial 3 finished with value: 0.806 and parameters: {'n_estimators': 156, 'max_depth': 20, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 1 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:40,608]\u001b[0m Trial 4 finished with value: 0.8059999999999998 and parameters: {'n_estimators': 246, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 1 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:40,831]\u001b[0m Trial 5 finished with value: 0.8 and parameters: {'n_estimators': 73, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 1 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:41,444]\u001b[0m Trial 6 finished with value: 0.8 and parameters: {'n_estimators': 215, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 1 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:42,133]\u001b[0m Trial 7 finished with value: 0.8019999999999999 and parameters: {'n_estimators': 288, 'max_depth': None, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 1 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:42,800]\u001b[0m Trial 8 finished with value: 0.806 and parameters: {'n_estimators': 278, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 1 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:43,294]\u001b[0m Trial 9 finished with value: 0.7979999999999999 and parameters: {'n_estimators': 173, 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 1 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:43,412]\u001b[0m A new study created in memory with name: no-name-de3cc755-4187-4e69-9d14-0365daf90746\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:1000 / Seed:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:47:43,871]\u001b[0m Trial 0 finished with value: 0.82 and parameters: {'n_estimators': 148, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:44,451]\u001b[0m Trial 1 finished with value: 0.8119999999999999 and parameters: {'n_estimators': 191, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:44,842]\u001b[0m Trial 2 finished with value: 0.8150000000000001 and parameters: {'n_estimators': 117, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:45,252]\u001b[0m Trial 3 finished with value: 0.806 and parameters: {'n_estimators': 138, 'max_depth': None, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:45,981]\u001b[0m Trial 4 finished with value: 0.8089999999999999 and parameters: {'n_estimators': 244, 'max_depth': 30, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:46,248]\u001b[0m Trial 5 finished with value: 0.8140000000000001 and parameters: {'n_estimators': 76, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:46,939]\u001b[0m Trial 6 finished with value: 0.813 and parameters: {'n_estimators': 206, 'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:47,592]\u001b[0m Trial 7 finished with value: 0.8150000000000001 and parameters: {'n_estimators': 197, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:48,524]\u001b[0m Trial 8 finished with value: 0.8109999999999999 and parameters: {'n_estimators': 278, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:48,836]\u001b[0m Trial 9 finished with value: 0.8130000000000001 and parameters: {'n_estimators': 101, 'max_depth': 20, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:48,946]\u001b[0m A new study created in memory with name: no-name-5add8538-28c0-4af3-81dc-b2cc7c34788c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:5000 / Seed:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:47:50,257]\u001b[0m Trial 0 finished with value: 0.8493999999999999 and parameters: {'n_estimators': 141, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.8493999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:51,811]\u001b[0m Trial 1 finished with value: 0.8438000000000001 and parameters: {'n_estimators': 204, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.8493999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:53,242]\u001b[0m Trial 2 finished with value: 0.8413999999999999 and parameters: {'n_estimators': 194, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.8493999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:54,043]\u001b[0m Trial 3 finished with value: 0.8421999999999998 and parameters: {'n_estimators': 103, 'max_depth': 30, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.8493999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:56,032]\u001b[0m Trial 4 finished with value: 0.8421999999999998 and parameters: {'n_estimators': 290, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.8493999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:58,008]\u001b[0m Trial 5 finished with value: 0.8468 and parameters: {'n_estimators': 241, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.8493999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:47:59,943]\u001b[0m Trial 6 finished with value: 0.8431999999999998 and parameters: {'n_estimators': 268, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.8493999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:01,287]\u001b[0m Trial 7 finished with value: 0.8477999999999998 and parameters: {'n_estimators': 148, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.8493999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:02,835]\u001b[0m Trial 8 finished with value: 0.842 and parameters: {'n_estimators': 224, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.8493999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:04,540]\u001b[0m Trial 9 finished with value: 0.8412 and parameters: {'n_estimators': 244, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.8493999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:04,852]\u001b[0m A new study created in memory with name: no-name-5357f410-54c5-4615-b9df-35e2f899f03e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:100 / Seed:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:48:05,272]\u001b[0m Trial 0 finished with value: 0.7699999999999999 and parameters: {'n_estimators': 293, 'max_depth': 10, 'learning_rate': 0.12955516144918802, 'subsample': 0.8897954189580778, 'colsample_bytree': 0.6416131353259855, 'gamma': 7.883316787480188e-07, 'reg_alpha': 0.1437341244209593, 'reg_lambda': 0.0016577062654436721}. Best is trial 0 with value: 0.7699999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:05,404]\u001b[0m Trial 1 finished with value: 0.76 and parameters: {'n_estimators': 115, 'max_depth': 11, 'learning_rate': 0.1564968735200426, 'subsample': 0.831833173082495, 'colsample_bytree': 0.9983325654110531, 'gamma': 7.755968003210876e-05, 'reg_alpha': 0.0033975893106905574, 'reg_lambda': 7.280278542241267e-05}. Best is trial 0 with value: 0.7699999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:05,634]\u001b[0m Trial 2 finished with value: 0.77 and parameters: {'n_estimators': 235, 'max_depth': 4, 'learning_rate': 0.12812037551715064, 'subsample': 0.8529735870547108, 'colsample_bytree': 0.5710871468722984, 'gamma': 0.0008177977100959584, 'reg_alpha': 1.0463471995254906e-07, 'reg_lambda': 8.249231078846422e-07}. Best is trial 2 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:05,909]\u001b[0m Trial 3 finished with value: 0.75 and parameters: {'n_estimators': 249, 'max_depth': 10, 'learning_rate': 0.08209276731626847, 'subsample': 0.6311597767715629, 'colsample_bytree': 0.6497706598789115, 'gamma': 0.45519251875379396, 'reg_alpha': 8.098948488717046e-07, 'reg_lambda': 3.558388445838014e-05}. Best is trial 2 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:06,250]\u001b[0m Trial 4 finished with value: 0.76 and parameters: {'n_estimators': 256, 'max_depth': 15, 'learning_rate': 0.1493059971447829, 'subsample': 0.7763213344250711, 'colsample_bytree': 0.6397877885545715, 'gamma': 0.00024251510653122796, 'reg_alpha': 1.531174950874908e-08, 'reg_lambda': 1.1304851849695223e-05}. Best is trial 2 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:06,514]\u001b[0m Trial 5 finished with value: 0.79 and parameters: {'n_estimators': 100, 'max_depth': 11, 'learning_rate': 0.032966445032104455, 'subsample': 0.9647178112048702, 'colsample_bytree': 0.8574282654738854, 'gamma': 3.567312146061166e-05, 'reg_alpha': 0.00532566893603094, 'reg_lambda': 2.263422900034555e-05}. Best is trial 5 with value: 0.79.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:06,749]\u001b[0m Trial 6 finished with value: 0.7799999999999999 and parameters: {'n_estimators': 179, 'max_depth': 12, 'learning_rate': 0.05965106265632677, 'subsample': 0.7735774945388005, 'colsample_bytree': 0.6885752058349088, 'gamma': 1.457279671217873e-07, 'reg_alpha': 0.11395359506797839, 'reg_lambda': 4.693015794519057e-08}. Best is trial 5 with value: 0.79.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:06,975]\u001b[0m Trial 7 finished with value: 0.79 and parameters: {'n_estimators': 194, 'max_depth': 14, 'learning_rate': 0.17464580809439367, 'subsample': 0.9220962160253872, 'colsample_bytree': 0.8692529446028758, 'gamma': 0.0019034471292004326, 'reg_alpha': 9.381157920186548e-06, 'reg_lambda': 5.4263110474998424e-08}. Best is trial 5 with value: 0.79.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:07,282]\u001b[0m Trial 8 finished with value: 0.8 and parameters: {'n_estimators': 282, 'max_depth': 12, 'learning_rate': 0.04044044190554321, 'subsample': 0.6454551079013557, 'colsample_bytree': 0.9733014897295427, 'gamma': 0.005843431334835936, 'reg_alpha': 0.00022066218359184536, 'reg_lambda': 0.41019795870533127}. Best is trial 8 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:07,439]\u001b[0m Trial 9 finished with value: 0.7699999999999999 and parameters: {'n_estimators': 161, 'max_depth': 4, 'learning_rate': 0.2000768219067336, 'subsample': 0.7973191695643786, 'colsample_bytree': 0.8149364839333193, 'gamma': 0.20830809329107886, 'reg_alpha': 8.365393067487587e-07, 'reg_lambda': 0.00011279164867707284}. Best is trial 8 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:07,532]\u001b[0m A new study created in memory with name: no-name-072fa1f1-cdc3-48f3-832a-e318e00a6271\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:07,713]\u001b[0m Trial 0 finished with value: 0.808 and parameters: {'n_estimators': 112, 'max_depth': 4, 'learning_rate': 0.01128386563224052, 'subsample': 0.9274104858998526, 'colsample_bytree': 0.6917121782182081, 'gamma': 6.427292447169015e-07, 'reg_alpha': 0.00023589406547943432, 'reg_lambda': 2.178343902232064e-08}. Best is trial 0 with value: 0.808.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:500 / Seed:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:48:07,934]\u001b[0m Trial 1 finished with value: 0.8039999999999999 and parameters: {'n_estimators': 76, 'max_depth': 5, 'learning_rate': 0.011094335628899723, 'subsample': 0.7662090478042474, 'colsample_bytree': 0.8105555066294229, 'gamma': 1.507843505169971e-07, 'reg_alpha': 3.249708207184669e-05, 'reg_lambda': 0.00012319389509578643}. Best is trial 0 with value: 0.808.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:08,776]\u001b[0m Trial 2 finished with value: 0.82 and parameters: {'n_estimators': 262, 'max_depth': 11, 'learning_rate': 0.047069538977757314, 'subsample': 0.7662156676001739, 'colsample_bytree': 0.8225057860335679, 'gamma': 0.03417092443940238, 'reg_alpha': 0.03880640515203776, 'reg_lambda': 0.0017740321242114066}. Best is trial 2 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:09,349]\u001b[0m Trial 3 finished with value: 0.818 and parameters: {'n_estimators': 227, 'max_depth': 9, 'learning_rate': 0.07892291891376002, 'subsample': 0.86674892456169, 'colsample_bytree': 0.5159622844507156, 'gamma': 2.91113422670872e-08, 'reg_alpha': 0.8232990369086326, 'reg_lambda': 4.931049927337065e-06}. Best is trial 2 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:09,598]\u001b[0m Trial 4 finished with value: 0.8039999999999999 and parameters: {'n_estimators': 58, 'max_depth': 8, 'learning_rate': 0.1735041829096299, 'subsample': 0.9431408971776547, 'colsample_bytree': 0.6154333694778178, 'gamma': 3.74547930929138e-08, 'reg_alpha': 0.23408214586298923, 'reg_lambda': 0.04568666575508522}. Best is trial 2 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:10,183]\u001b[0m Trial 5 finished with value: 0.8 and parameters: {'n_estimators': 107, 'max_depth': 9, 'learning_rate': 0.011273099790668973, 'subsample': 0.7088682210474294, 'colsample_bytree': 0.9334669440175845, 'gamma': 0.0011901766487165922, 'reg_alpha': 1.873157110446181e-08, 'reg_lambda': 1.5818818615120596e-05}. Best is trial 2 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:10,922]\u001b[0m Trial 6 finished with value: 0.8079999999999998 and parameters: {'n_estimators': 125, 'max_depth': 11, 'learning_rate': 0.01225643365274656, 'subsample': 0.8936586838624256, 'colsample_bytree': 0.6426582047061726, 'gamma': 2.162453960714298e-07, 'reg_alpha': 0.0191483972846268, 'reg_lambda': 0.06346937881365781}. Best is trial 2 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:11,188]\u001b[0m Trial 7 finished with value: 0.8140000000000001 and parameters: {'n_estimators': 81, 'max_depth': 14, 'learning_rate': 0.14094969040204366, 'subsample': 0.9645841489314413, 'colsample_bytree': 0.9533100155450619, 'gamma': 0.35478021661358666, 'reg_alpha': 0.0456831238260518, 'reg_lambda': 0.0646892844996003}. Best is trial 2 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:11,535]\u001b[0m Trial 8 finished with value: 0.842 and parameters: {'n_estimators': 248, 'max_depth': 10, 'learning_rate': 0.18747921666935333, 'subsample': 0.7283636819513225, 'colsample_bytree': 0.5410124326359522, 'gamma': 7.170793297106688e-06, 'reg_alpha': 2.002417818415997e-08, 'reg_lambda': 0.003301715400360867}. Best is trial 8 with value: 0.842.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:12,170]\u001b[0m Trial 9 finished with value: 0.808 and parameters: {'n_estimators': 186, 'max_depth': 13, 'learning_rate': 0.01780917268971226, 'subsample': 0.8466795568098491, 'colsample_bytree': 0.7097981224585008, 'gamma': 1.6302129046909331e-06, 'reg_alpha': 1.1935382241819932e-07, 'reg_lambda': 3.843702235626664e-05}. Best is trial 8 with value: 0.842.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:12,265]\u001b[0m A new study created in memory with name: no-name-c0db3321-3ff6-4cff-af79-02973f349896\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:1000 / Seed:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:48:12,686]\u001b[0m Trial 0 finished with value: 0.8489999999999999 and parameters: {'n_estimators': 90, 'max_depth': 8, 'learning_rate': 0.19147278221344863, 'subsample': 0.9587800164246587, 'colsample_bytree': 0.6893651181291977, 'gamma': 2.5086828822263282e-06, 'reg_alpha': 2.7105850600836776e-07, 'reg_lambda': 0.009208187779457191}. Best is trial 0 with value: 0.8489999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:13,170]\u001b[0m Trial 1 finished with value: 0.8379999999999999 and parameters: {'n_estimators': 111, 'max_depth': 14, 'learning_rate': 0.20366368603030566, 'subsample': 0.6037765720911936, 'colsample_bytree': 0.9763804204924917, 'gamma': 1.5815237233907456e-05, 'reg_alpha': 0.1963415853411575, 'reg_lambda': 0.005526001195541219}. Best is trial 0 with value: 0.8489999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:13,866]\u001b[0m Trial 2 finished with value: 0.8029999999999999 and parameters: {'n_estimators': 88, 'max_depth': 13, 'learning_rate': 0.020533693115347553, 'subsample': 0.9998567449094429, 'colsample_bytree': 0.9418726156708196, 'gamma': 0.15319428269654434, 'reg_alpha': 0.01736176044613238, 'reg_lambda': 0.4073176672312894}. Best is trial 0 with value: 0.8489999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:14,115]\u001b[0m Trial 3 finished with value: 0.819 and parameters: {'n_estimators': 136, 'max_depth': 4, 'learning_rate': 0.031990495146659095, 'subsample': 0.9892005007287022, 'colsample_bytree': 0.5414650187446313, 'gamma': 0.0006690138227777585, 'reg_alpha': 0.007077052974954093, 'reg_lambda': 4.679396473414253e-05}. Best is trial 0 with value: 0.8489999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:14,436]\u001b[0m Trial 4 finished with value: 0.825 and parameters: {'n_estimators': 149, 'max_depth': 4, 'learning_rate': 0.02106287258226963, 'subsample': 0.5303332038504491, 'colsample_bytree': 0.9126430969002599, 'gamma': 9.823372760952714e-08, 'reg_alpha': 0.0032176476603017375, 'reg_lambda': 5.186833980954501e-08}. Best is trial 0 with value: 0.8489999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:14,879]\u001b[0m Trial 5 finished with value: 0.8089999999999999 and parameters: {'n_estimators': 221, 'max_depth': 3, 'learning_rate': 0.013301893787989993, 'subsample': 0.8672727099622441, 'colsample_bytree': 0.585206405072132, 'gamma': 2.740529753610342e-07, 'reg_alpha': 8.137235217577729e-08, 'reg_lambda': 0.0016456209829768358}. Best is trial 0 with value: 0.8489999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:15,711]\u001b[0m Trial 6 finished with value: 0.844 and parameters: {'n_estimators': 260, 'max_depth': 6, 'learning_rate': 0.04129360718945224, 'subsample': 0.5467342186704373, 'colsample_bytree': 0.5929660384066551, 'gamma': 2.5379442981485842e-06, 'reg_alpha': 1.881948338869984e-07, 'reg_lambda': 0.00030115608283535773}. Best is trial 0 with value: 0.8489999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:16,027]\u001b[0m Trial 7 finished with value: 0.851 and parameters: {'n_estimators': 248, 'max_depth': 3, 'learning_rate': 0.1783081964044374, 'subsample': 0.6642018513143975, 'colsample_bytree': 0.988677288266923, 'gamma': 1.6881552777207192e-06, 'reg_alpha': 0.05164468772120184, 'reg_lambda': 0.11690921582040839}. Best is trial 7 with value: 0.851.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:17,210]\u001b[0m Trial 8 finished with value: 0.8400000000000001 and parameters: {'n_estimators': 208, 'max_depth': 8, 'learning_rate': 0.16807049837857188, 'subsample': 0.5514084570484865, 'colsample_bytree': 0.9141072378861912, 'gamma': 1.5095294552445646e-08, 'reg_alpha': 0.0033692334440098334, 'reg_lambda': 2.651511362488247e-08}. Best is trial 7 with value: 0.851.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:17,940]\u001b[0m Trial 9 finished with value: 0.844 and parameters: {'n_estimators': 211, 'max_depth': 8, 'learning_rate': 0.08831818689882587, 'subsample': 0.7368956989074966, 'colsample_bytree': 0.7771003404044674, 'gamma': 0.13477474731989586, 'reg_alpha': 0.007026940054890154, 'reg_lambda': 6.914220523557675e-06}. Best is trial 7 with value: 0.851.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:18,022]\u001b[0m A new study created in memory with name: no-name-135b66ca-4cf3-417c-9409-20d694232ce0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:5000 / Seed:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:48:19,854]\u001b[0m Trial 0 finished with value: 0.8562 and parameters: {'n_estimators': 59, 'max_depth': 13, 'learning_rate': 0.03838764943257529, 'subsample': 0.8993012056267577, 'colsample_bytree': 0.7916214870597909, 'gamma': 1.1700339752338776e-06, 'reg_alpha': 9.625106192727183e-07, 'reg_lambda': 0.0013403437095343537}. Best is trial 0 with value: 0.8562.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:21,151]\u001b[0m Trial 1 finished with value: 0.8698 and parameters: {'n_estimators': 159, 'max_depth': 15, 'learning_rate': 0.24589430831468573, 'subsample': 0.5919288865451902, 'colsample_bytree': 0.9836598347888091, 'gamma': 5.892692838685995e-06, 'reg_alpha': 0.00031823992185322326, 'reg_lambda': 2.7741883621669497e-06}. Best is trial 1 with value: 0.8698.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:22,157]\u001b[0m Trial 2 finished with value: 0.8527999999999999 and parameters: {'n_estimators': 170, 'max_depth': 6, 'learning_rate': 0.013137501831972428, 'subsample': 0.8042536526838182, 'colsample_bytree': 0.935530178721635, 'gamma': 0.01012862228751712, 'reg_alpha': 7.394557932580066e-07, 'reg_lambda': 1.4327698785377224e-05}. Best is trial 1 with value: 0.8698.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:23,111]\u001b[0m Trial 3 finished with value: 0.8672000000000001 and parameters: {'n_estimators': 121, 'max_depth': 7, 'learning_rate': 0.048474546802424794, 'subsample': 0.8403652293752515, 'colsample_bytree': 0.8379299833433724, 'gamma': 0.030597326489158583, 'reg_alpha': 0.00017039194774284003, 'reg_lambda': 2.7660661853178895e-06}. Best is trial 1 with value: 0.8698.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:27,699]\u001b[0m Trial 4 finished with value: 0.8666 and parameters: {'n_estimators': 260, 'max_depth': 13, 'learning_rate': 0.045849125380227576, 'subsample': 0.9527455386653694, 'colsample_bytree': 0.8370241761362877, 'gamma': 0.1881758145078345, 'reg_alpha': 1.0815639619623267e-07, 'reg_lambda': 1.572790569307069e-05}. Best is trial 1 with value: 0.8698.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:29,969]\u001b[0m Trial 5 finished with value: 0.8664 and parameters: {'n_estimators': 292, 'max_depth': 7, 'learning_rate': 0.016005237937786482, 'subsample': 0.898684404532591, 'colsample_bytree': 0.9834221297596137, 'gamma': 1.5227749650811212e-08, 'reg_alpha': 8.583704128936895e-07, 'reg_lambda': 5.84751908628398e-08}. Best is trial 1 with value: 0.8698.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:36,056]\u001b[0m Trial 6 finished with value: 0.86 and parameters: {'n_estimators': 291, 'max_depth': 10, 'learning_rate': 0.011033080700722947, 'subsample': 0.6187298996052615, 'colsample_bytree': 0.771241253372844, 'gamma': 0.002541840432888096, 'reg_alpha': 1.5814122691213194e-07, 'reg_lambda': 9.048783569957816e-05}. Best is trial 1 with value: 0.8698.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:36,893]\u001b[0m Trial 7 finished with value: 0.8865999999999999 and parameters: {'n_estimators': 215, 'max_depth': 4, 'learning_rate': 0.19893953482893967, 'subsample': 0.8124277984789795, 'colsample_bytree': 0.7646567376729176, 'gamma': 7.58160755237314e-08, 'reg_alpha': 0.021773425167510407, 'reg_lambda': 1.6099620137337015e-08}. Best is trial 7 with value: 0.8865999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:38,655]\u001b[0m Trial 8 finished with value: 0.865 and parameters: {'n_estimators': 148, 'max_depth': 8, 'learning_rate': 0.12465692459121633, 'subsample': 0.9613090600316224, 'colsample_bytree': 0.8464794784527925, 'gamma': 6.347056645963973e-05, 'reg_alpha': 0.00011007598572317753, 'reg_lambda': 4.942286019837454e-06}. Best is trial 7 with value: 0.8865999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:43,985]\u001b[0m Trial 9 finished with value: 0.8564 and parameters: {'n_estimators': 136, 'max_depth': 13, 'learning_rate': 0.013555663648992517, 'subsample': 0.8096803550806471, 'colsample_bytree': 0.8751895440401574, 'gamma': 2.0044702172743493e-05, 'reg_alpha': 8.302210708262592e-08, 'reg_lambda': 3.4624382074462285e-07}. Best is trial 7 with value: 0.8865999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:44,251]\u001b[0m A new study created in memory with name: no-name-5b549276-b335-44af-b9ee-a11e6834ef35\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:100 / Seed:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:48:44,486]\u001b[0m Trial 0 finished with value: 0.82 and parameters: {'n_estimators': 114, 'max_depth': None, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:45,162]\u001b[0m Trial 1 finished with value: 0.8300000000000001 and parameters: {'n_estimators': 268, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 1 with value: 0.8300000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:45,408]\u001b[0m Trial 2 finished with value: 0.8300000000000001 and parameters: {'n_estimators': 123, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 1 with value: 0.8300000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:45,539]\u001b[0m Trial 3 finished with value: 0.8400000000000001 and parameters: {'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 3 with value: 0.8400000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:45,994]\u001b[0m Trial 4 finished with value: 0.8400000000000001 and parameters: {'n_estimators': 232, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 3 with value: 0.8400000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:46,329]\u001b[0m Trial 5 finished with value: 0.8400000000000001 and parameters: {'n_estimators': 133, 'max_depth': None, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}. Best is trial 3 with value: 0.8400000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:46,946]\u001b[0m Trial 6 finished with value: 0.8400000000000001 and parameters: {'n_estimators': 246, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True}. Best is trial 3 with value: 0.8400000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:47,350]\u001b[0m Trial 7 finished with value: 0.85 and parameters: {'n_estimators': 204, 'max_depth': 30, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 7 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:48,048]\u001b[0m Trial 8 finished with value: 0.8300000000000001 and parameters: {'n_estimators': 278, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 7 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:48,585]\u001b[0m Trial 9 finished with value: 0.85 and parameters: {'n_estimators': 276, 'max_depth': None, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 7 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:48,675]\u001b[0m A new study created in memory with name: no-name-5df44b2b-1559-4d8f-85da-9fe05f7e8cac\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:500 / Seed:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:48:48,897]\u001b[0m Trial 0 finished with value: 0.8019999999999999 and parameters: {'n_estimators': 74, 'max_depth': 20, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.8019999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:49,441]\u001b[0m Trial 1 finished with value: 0.808 and parameters: {'n_estimators': 191, 'max_depth': 20, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 1 with value: 0.808.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:49,865]\u001b[0m Trial 2 finished with value: 0.8019999999999999 and parameters: {'n_estimators': 177, 'max_depth': 30, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 1 with value: 0.808.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:50,109]\u001b[0m Trial 3 finished with value: 0.806 and parameters: {'n_estimators': 98, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 1 with value: 0.808.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:50,570]\u001b[0m Trial 4 finished with value: 0.804 and parameters: {'n_estimators': 193, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 1 with value: 0.808.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:50,991]\u001b[0m Trial 5 finished with value: 0.792 and parameters: {'n_estimators': 174, 'max_depth': 40, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 1 with value: 0.808.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:51,796]\u001b[0m Trial 6 finished with value: 0.8140000000000001 and parameters: {'n_estimators': 273, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}. Best is trial 6 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:52,215]\u001b[0m Trial 7 finished with value: 0.8059999999999998 and parameters: {'n_estimators': 141, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 6 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:52,982]\u001b[0m Trial 8 finished with value: 0.8019999999999999 and parameters: {'n_estimators': 262, 'max_depth': 40, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 6 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:53,304]\u001b[0m Trial 9 finished with value: 0.796 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 6 with value: 0.8140000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:53,482]\u001b[0m A new study created in memory with name: no-name-ae57e178-7363-4735-8243-89845a06decb\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:1000 / Seed:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:48:53,744]\u001b[0m Trial 0 finished with value: 0.843 and parameters: {'n_estimators': 83, 'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.843.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:54,026]\u001b[0m Trial 1 finished with value: 0.8379999999999999 and parameters: {'n_estimators': 81, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.843.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:54,931]\u001b[0m Trial 2 finished with value: 0.8370000000000001 and parameters: {'n_estimators': 262, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.843.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:55,138]\u001b[0m Trial 3 finished with value: 0.835 and parameters: {'n_estimators': 67, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.843.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:55,617]\u001b[0m Trial 4 finished with value: 0.8469999999999999 and parameters: {'n_estimators': 153, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8469999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:56,389]\u001b[0m Trial 5 finished with value: 0.841 and parameters: {'n_estimators': 246, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8469999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:56,642]\u001b[0m Trial 6 finished with value: 0.8310000000000001 and parameters: {'n_estimators': 84, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8469999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:57,393]\u001b[0m Trial 7 finished with value: 0.841 and parameters: {'n_estimators': 239, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8469999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:58,134]\u001b[0m Trial 8 finished with value: 0.835 and parameters: {'n_estimators': 253, 'max_depth': 40, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.8469999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:58,554]\u001b[0m Trial 9 finished with value: 0.833 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8469999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:58,671]\u001b[0m A new study created in memory with name: no-name-d5dc1aef-d50a-44f5-aa4e-136178b61b85\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:RandomForestClassifier / Target:['y_bin'] / Train size:5000 / Seed:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:48:59,146]\u001b[0m Trial 0 finished with value: 0.8489999999999999 and parameters: {'n_estimators': 61, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.8489999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:48:59,609]\u001b[0m Trial 1 finished with value: 0.8530000000000001 and parameters: {'n_estimators': 65, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}. Best is trial 1 with value: 0.8530000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:01,722]\u001b[0m Trial 2 finished with value: 0.8550000000000001 and parameters: {'n_estimators': 278, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 2 with value: 0.8550000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:02,311]\u001b[0m Trial 3 finished with value: 0.8497999999999999 and parameters: {'n_estimators': 84, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 2 with value: 0.8550000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:04,450]\u001b[0m Trial 4 finished with value: 0.8550000000000001 and parameters: {'n_estimators': 263, 'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 2 with value: 0.8550000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:06,476]\u001b[0m Trial 5 finished with value: 0.8516 and parameters: {'n_estimators': 266, 'max_depth': None, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 2 with value: 0.8550000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:08,109]\u001b[0m Trial 6 finished with value: 0.8538 and parameters: {'n_estimators': 226, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 2 with value: 0.8550000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:10,349]\u001b[0m Trial 7 finished with value: 0.8558 and parameters: {'n_estimators': 298, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}. Best is trial 7 with value: 0.8558.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:10,860]\u001b[0m Trial 8 finished with value: 0.8488 and parameters: {'n_estimators': 66, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 7 with value: 0.8558.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:11,467]\u001b[0m Trial 9 finished with value: 0.8462 and parameters: {'n_estimators': 88, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 7 with value: 0.8558.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:11,974]\u001b[0m A new study created in memory with name: no-name-57e96bf7-0e1d-4083-bf8a-f594fdbaf88f\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:12,116]\u001b[0m Trial 0 finished with value: 0.8200000000000001 and parameters: {'n_estimators': 80, 'max_depth': 12, 'learning_rate': 0.015583109697114163, 'subsample': 0.8249986459673297, 'colsample_bytree': 0.9680145185509126, 'gamma': 0.9468214731330132, 'reg_alpha': 4.050350404673338e-06, 'reg_lambda': 1.615412191485877e-05}. Best is trial 0 with value: 0.8200000000000001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:100 / Seed:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:49:12,335]\u001b[0m Trial 1 finished with value: 0.78 and parameters: {'n_estimators': 248, 'max_depth': 4, 'learning_rate': 0.2506066870859788, 'subsample': 0.601618907213401, 'colsample_bytree': 0.6907912446148383, 'gamma': 1.5377076692520912e-07, 'reg_alpha': 0.11732195581389455, 'reg_lambda': 0.034336818292920256}. Best is trial 0 with value: 0.8200000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:12,533]\u001b[0m Trial 2 finished with value: 0.8300000000000001 and parameters: {'n_estimators': 218, 'max_depth': 10, 'learning_rate': 0.07934745892053388, 'subsample': 0.5308556876113008, 'colsample_bytree': 0.5678247828150473, 'gamma': 0.0007134878585202755, 'reg_alpha': 2.8504909766322215e-06, 'reg_lambda': 0.0003829657257818648}. Best is trial 2 with value: 0.8300000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:12,748]\u001b[0m Trial 3 finished with value: 0.8300000000000001 and parameters: {'n_estimators': 270, 'max_depth': 14, 'learning_rate': 0.05524821788350823, 'subsample': 0.7202776850382568, 'colsample_bytree': 0.7998971037399601, 'gamma': 0.0003337661317788299, 'reg_alpha': 0.036184540062623366, 'reg_lambda': 0.3998061613474554}. Best is trial 2 with value: 0.8300000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:12,887]\u001b[0m Trial 4 finished with value: 0.8400000000000001 and parameters: {'n_estimators': 181, 'max_depth': 3, 'learning_rate': 0.08313850465165083, 'subsample': 0.5141343167381505, 'colsample_bytree': 0.7312911401192729, 'gamma': 0.2776215966533167, 'reg_alpha': 0.00010629984426023944, 'reg_lambda': 1.5174477520579416e-08}. Best is trial 4 with value: 0.8400000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:13,033]\u001b[0m Trial 5 finished with value: 0.8300000000000001 and parameters: {'n_estimators': 195, 'max_depth': 11, 'learning_rate': 0.1235336255566804, 'subsample': 0.6319307398938587, 'colsample_bytree': 0.6502057783753608, 'gamma': 0.00019098710507188256, 'reg_alpha': 0.008984857179582511, 'reg_lambda': 1.3063312741577002e-05}. Best is trial 4 with value: 0.8400000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:13,310]\u001b[0m Trial 6 finished with value: 0.82 and parameters: {'n_estimators': 249, 'max_depth': 6, 'learning_rate': 0.05556331454892212, 'subsample': 0.7877540321120913, 'colsample_bytree': 0.7175351228329125, 'gamma': 1.8984113108326117e-08, 'reg_alpha': 1.2816620801735547e-08, 'reg_lambda': 0.004191809803771568}. Best is trial 4 with value: 0.8400000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:13,480]\u001b[0m Trial 7 finished with value: 0.82 and parameters: {'n_estimators': 102, 'max_depth': 7, 'learning_rate': 0.13813213753038708, 'subsample': 0.5277050588704556, 'colsample_bytree': 0.7790103989434116, 'gamma': 3.075640627241012e-05, 'reg_alpha': 5.987701798135915e-06, 'reg_lambda': 0.0005033174946964226}. Best is trial 4 with value: 0.8400000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:13,714]\u001b[0m Trial 8 finished with value: 0.8699999999999999 and parameters: {'n_estimators': 269, 'max_depth': 6, 'learning_rate': 0.011427268134250705, 'subsample': 0.627737942636224, 'colsample_bytree': 0.7413276936638153, 'gamma': 9.70243712360616e-08, 'reg_alpha': 3.5957294805786867e-08, 'reg_lambda': 0.5835681208526544}. Best is trial 8 with value: 0.8699999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:13,873]\u001b[0m Trial 9 finished with value: 0.8400000000000001 and parameters: {'n_estimators': 121, 'max_depth': 14, 'learning_rate': 0.015287242763279621, 'subsample': 0.8985321288795226, 'colsample_bytree': 0.5507451060873583, 'gamma': 3.9720840502716375e-06, 'reg_alpha': 7.070528436073493e-05, 'reg_lambda': 3.5464662229369125e-07}. Best is trial 8 with value: 0.8699999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:13,938]\u001b[0m A new study created in memory with name: no-name-048cf3d5-56b1-4fb2-ad49-234330bb5d53\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:500 / Seed:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:49:14,380]\u001b[0m Trial 0 finished with value: 0.8119999999999999 and parameters: {'n_estimators': 122, 'max_depth': 7, 'learning_rate': 0.08700957720333471, 'subsample': 0.6250148304763832, 'colsample_bytree': 0.8244182167505226, 'gamma': 0.034842845758594795, 'reg_alpha': 1.6968280129151223e-08, 'reg_lambda': 1.2357568953481787e-06}. Best is trial 0 with value: 0.8119999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:15,034]\u001b[0m Trial 1 finished with value: 0.808 and parameters: {'n_estimators': 180, 'max_depth': 8, 'learning_rate': 0.011283997212524101, 'subsample': 0.6951153077582415, 'colsample_bytree': 0.846346805969725, 'gamma': 0.006005251568524856, 'reg_alpha': 0.0011493099772097567, 'reg_lambda': 4.0283787922329174e-08}. Best is trial 0 with value: 0.8119999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:15,736]\u001b[0m Trial 2 finished with value: 0.8200000000000001 and parameters: {'n_estimators': 300, 'max_depth': 14, 'learning_rate': 0.047224860669445416, 'subsample': 0.7355690340760762, 'colsample_bytree': 0.5439288221120997, 'gamma': 1.1613657222731096e-07, 'reg_alpha': 1.1344526510932328e-05, 'reg_lambda': 0.023427767697910648}. Best is trial 2 with value: 0.8200000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:16,307]\u001b[0m Trial 3 finished with value: 0.818 and parameters: {'n_estimators': 258, 'max_depth': 8, 'learning_rate': 0.04109499853733132, 'subsample': 0.5820783077451079, 'colsample_bytree': 0.701800232256609, 'gamma': 5.492272217230817e-07, 'reg_alpha': 0.0014200764807681663, 'reg_lambda': 0.31319342051240545}. Best is trial 2 with value: 0.8200000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:16,990]\u001b[0m Trial 4 finished with value: 0.8160000000000001 and parameters: {'n_estimators': 269, 'max_depth': 11, 'learning_rate': 0.03778347506367568, 'subsample': 0.8574877373017697, 'colsample_bytree': 0.6623048819436265, 'gamma': 0.00031408684322332346, 'reg_alpha': 0.014181071469878388, 'reg_lambda': 0.0011571339912064776}. Best is trial 2 with value: 0.8200000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:17,260]\u001b[0m Trial 5 finished with value: 0.8140000000000001 and parameters: {'n_estimators': 59, 'max_depth': 10, 'learning_rate': 0.019821708399309412, 'subsample': 0.9461594195406565, 'colsample_bytree': 0.5269167257716526, 'gamma': 0.2642376760885972, 'reg_alpha': 0.16667991138175356, 'reg_lambda': 8.795306220741227e-05}. Best is trial 2 with value: 0.8200000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:18,325]\u001b[0m Trial 6 finished with value: 0.8019999999999999 and parameters: {'n_estimators': 271, 'max_depth': 12, 'learning_rate': 0.04982995425720987, 'subsample': 0.9562029419790417, 'colsample_bytree': 0.7992888518784754, 'gamma': 2.853349747793634e-05, 'reg_alpha': 0.0007680593001153495, 'reg_lambda': 0.06742297721172957}. Best is trial 2 with value: 0.8200000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:18,578]\u001b[0m Trial 7 finished with value: 0.8240000000000001 and parameters: {'n_estimators': 66, 'max_depth': 3, 'learning_rate': 0.24208647301604938, 'subsample': 0.581148044412828, 'colsample_bytree': 0.8541938289411216, 'gamma': 0.040985211684601966, 'reg_alpha': 0.41950125149065576, 'reg_lambda': 1.3551279172382585e-08}. Best is trial 7 with value: 0.8240000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:19,110]\u001b[0m Trial 8 finished with value: 0.8320000000000001 and parameters: {'n_estimators': 168, 'max_depth': 9, 'learning_rate': 0.10309724783154077, 'subsample': 0.5897853656193861, 'colsample_bytree': 0.6998652553377176, 'gamma': 3.149807788001458e-06, 'reg_alpha': 4.199076423740551e-07, 'reg_lambda': 0.00011434605497780671}. Best is trial 8 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:19,411]\u001b[0m Trial 9 finished with value: 0.812 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.04093599162157165, 'subsample': 0.5840953348084192, 'colsample_bytree': 0.9231820496866329, 'gamma': 7.164154128030606e-08, 'reg_alpha': 1.4872185660853557e-08, 'reg_lambda': 6.702167133685839e-06}. Best is trial 8 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:19,498]\u001b[0m A new study created in memory with name: no-name-4c1b5a4e-a765-4b85-97dc-fdc332832489\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:1000 / Seed:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:49:20,320]\u001b[0m Trial 0 finished with value: 0.849 and parameters: {'n_estimators': 143, 'max_depth': 9, 'learning_rate': 0.03427956982792925, 'subsample': 0.7855631255066953, 'colsample_bytree': 0.9285998859432678, 'gamma': 0.6201410055074186, 'reg_alpha': 0.020264938597686574, 'reg_lambda': 0.0022239538952481853}. Best is trial 0 with value: 0.849.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:21,018]\u001b[0m Trial 1 finished with value: 0.8470000000000001 and parameters: {'n_estimators': 238, 'max_depth': 8, 'learning_rate': 0.06515233149062877, 'subsample': 0.8641358760780831, 'colsample_bytree': 0.7566526855384373, 'gamma': 0.0011444624465867684, 'reg_alpha': 2.6813220843226053e-05, 'reg_lambda': 0.3628205019743623}. Best is trial 0 with value: 0.849.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:21,915]\u001b[0m Trial 2 finished with value: 0.8459999999999999 and parameters: {'n_estimators': 157, 'max_depth': 13, 'learning_rate': 0.04147166444870705, 'subsample': 0.6933888295408654, 'colsample_bytree': 0.6730437689761328, 'gamma': 0.006969530027721504, 'reg_alpha': 0.0772689084226874, 'reg_lambda': 1.025097640026899e-08}. Best is trial 0 with value: 0.849.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:22,439]\u001b[0m Trial 3 finished with value: 0.829 and parameters: {'n_estimators': 112, 'max_depth': 11, 'learning_rate': 0.016242038503212725, 'subsample': 0.8727185523200467, 'colsample_bytree': 0.9667218828623072, 'gamma': 0.00021163955293836497, 'reg_alpha': 0.00010147476433757996, 'reg_lambda': 0.6551038080693191}. Best is trial 0 with value: 0.849.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:23,422]\u001b[0m Trial 4 finished with value: 0.8419999999999999 and parameters: {'n_estimators': 199, 'max_depth': 14, 'learning_rate': 0.011266423843900624, 'subsample': 0.7822123045190585, 'colsample_bytree': 0.5046164921988001, 'gamma': 0.005018821154639349, 'reg_alpha': 0.007481562177662013, 'reg_lambda': 0.002632731228189181}. Best is trial 0 with value: 0.849.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:24,092]\u001b[0m Trial 5 finished with value: 0.8539999999999999 and parameters: {'n_estimators': 190, 'max_depth': 13, 'learning_rate': 0.1197370144737263, 'subsample': 0.8969178609944772, 'colsample_bytree': 0.717351729230217, 'gamma': 2.405782463778791e-05, 'reg_alpha': 1.0276993959855247e-08, 'reg_lambda': 0.002782991527788278}. Best is trial 5 with value: 0.8539999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:24,859]\u001b[0m Trial 6 finished with value: 0.8539999999999999 and parameters: {'n_estimators': 260, 'max_depth': 7, 'learning_rate': 0.06705143581433877, 'subsample': 0.6388871560637112, 'colsample_bytree': 0.757749140658091, 'gamma': 0.10491194707949716, 'reg_alpha': 0.01366382751479545, 'reg_lambda': 0.00572373727146347}. Best is trial 5 with value: 0.8539999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:26,497]\u001b[0m Trial 7 finished with value: 0.865 and parameters: {'n_estimators': 279, 'max_depth': 7, 'learning_rate': 0.05556547019486423, 'subsample': 0.6434396790826693, 'colsample_bytree': 0.671495115491017, 'gamma': 0.04579950340045636, 'reg_alpha': 0.05539414039249468, 'reg_lambda': 3.839262486838708e-06}. Best is trial 7 with value: 0.865.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:27,135]\u001b[0m Trial 8 finished with value: 0.859 and parameters: {'n_estimators': 196, 'max_depth': 6, 'learning_rate': 0.10434281799295446, 'subsample': 0.8610689247272831, 'colsample_bytree': 0.6625106005853028, 'gamma': 0.0019773693477616494, 'reg_alpha': 0.015489315177429555, 'reg_lambda': 5.285377760550991e-08}. Best is trial 7 with value: 0.865.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:27,540]\u001b[0m Trial 9 finished with value: 0.859 and parameters: {'n_estimators': 188, 'max_depth': 7, 'learning_rate': 0.2617209855296558, 'subsample': 0.9444164289896209, 'colsample_bytree': 0.6824853176273395, 'gamma': 4.127245565824215e-07, 'reg_alpha': 3.386351212482122e-07, 'reg_lambda': 0.9491885731208244}. Best is trial 7 with value: 0.865.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:27,738]\u001b[0m A new study created in memory with name: no-name-1b017435-d60b-4a2f-a554-713c81515419\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: Model:XGBClassifier / Target:['y_bin'] / Train size:5000 / Seed:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:49:30,417]\u001b[0m Trial 0 finished with value: 0.875 and parameters: {'n_estimators': 242, 'max_depth': 14, 'learning_rate': 0.11846293236455144, 'subsample': 0.6510175850163274, 'colsample_bytree': 0.7282224218257244, 'gamma': 0.16195669348055938, 'reg_alpha': 0.04724051823470925, 'reg_lambda': 0.00044665823583920906}. Best is trial 0 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:30,863]\u001b[0m Trial 1 finished with value: 0.8548 and parameters: {'n_estimators': 145, 'max_depth': 3, 'learning_rate': 0.05481490176122455, 'subsample': 0.7690044953919888, 'colsample_bytree': 0.726692792008937, 'gamma': 3.4288300902489797e-07, 'reg_alpha': 5.295221658112876e-05, 'reg_lambda': 0.04605111741833952}. Best is trial 0 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:31,377]\u001b[0m Trial 2 finished with value: 0.8469999999999999 and parameters: {'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.01768256280871136, 'subsample': 0.537598456699361, 'colsample_bytree': 0.5418933550353322, 'gamma': 0.018531454968183564, 'reg_alpha': 0.00015972895675916765, 'reg_lambda': 0.0002980460638290511}. Best is trial 0 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:32,217]\u001b[0m Trial 3 finished with value: 0.8684 and parameters: {'n_estimators': 66, 'max_depth': 12, 'learning_rate': 0.1410388737181013, 'subsample': 0.6915728704445518, 'colsample_bytree': 0.8108790071710983, 'gamma': 2.1244483827336672e-06, 'reg_alpha': 0.0545395590118702, 'reg_lambda': 0.009455414645143965}. Best is trial 0 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:33,105]\u001b[0m Trial 4 finished with value: 0.8614 and parameters: {'n_estimators': 69, 'max_depth': 8, 'learning_rate': 0.023423308027919757, 'subsample': 0.5213471389927598, 'colsample_bytree': 0.9752412800823775, 'gamma': 0.007251498992703363, 'reg_alpha': 1.5777120947983529e-06, 'reg_lambda': 0.0009357646541621127}. Best is trial 0 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:38,028]\u001b[0m Trial 5 finished with value: 0.859 and parameters: {'n_estimators': 225, 'max_depth': 9, 'learning_rate': 0.012104835698692515, 'subsample': 0.999172481538983, 'colsample_bytree': 0.5967109723344979, 'gamma': 0.29234547456266063, 'reg_alpha': 0.017119263933184078, 'reg_lambda': 7.820834625681677e-06}. Best is trial 0 with value: 0.875.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:39,044]\u001b[0m Trial 6 finished with value: 0.8863999999999999 and parameters: {'n_estimators': 238, 'max_depth': 4, 'learning_rate': 0.05181375995004, 'subsample': 0.6137905564063746, 'colsample_bytree': 0.8487875444165636, 'gamma': 0.00026114099192057973, 'reg_alpha': 1.082714162564849e-06, 'reg_lambda': 2.3052290095397625e-06}. Best is trial 6 with value: 0.8863999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:39,679]\u001b[0m Trial 7 finished with value: 0.8587999999999999 and parameters: {'n_estimators': 182, 'max_depth': 4, 'learning_rate': 0.02020327078636843, 'subsample': 0.5151751936217648, 'colsample_bytree': 0.9325979995446456, 'gamma': 1.8552599039961352e-08, 'reg_alpha': 0.007401889752843, 'reg_lambda': 0.2789240112937917}. Best is trial 6 with value: 0.8863999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:42,123]\u001b[0m Trial 8 finished with value: 0.8709999999999999 and parameters: {'n_estimators': 185, 'max_depth': 12, 'learning_rate': 0.05741918217151086, 'subsample': 0.5729073269661311, 'colsample_bytree': 0.9271411279951881, 'gamma': 2.8648709780267938e-08, 'reg_alpha': 0.0025399741689860634, 'reg_lambda': 0.0001321549102221643}. Best is trial 6 with value: 0.8863999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:49:42,684]\u001b[0m Trial 9 finished with value: 0.8713999999999998 and parameters: {'n_estimators': 64, 'max_depth': 8, 'learning_rate': 0.2559151291179708, 'subsample': 0.5023150802776908, 'colsample_bytree': 0.695868035770711, 'gamma': 0.020295628911778656, 'reg_alpha': 0.7052443190482706, 'reg_lambda': 7.397901970868305e-07}. Best is trial 6 with value: 0.8863999999999999.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAMES = ['RandomForestClassifier', 'XGBClassifier']\n",
    "TARGETS = [[i] for i in Target ]\n",
    "TRAIN_SIZES = [100, 500, 1000, 5000]\n",
    "\n",
    "result = []\n",
    "for seed in [1, 2, 3]:\n",
    "    for model_name in MODEL_NAMES:\n",
    "        for target in TARGETS:\n",
    "            for train_size in TRAIN_SIZES:\n",
    "                print(f'RUN: Model:{model_name} / Target:{target} / Train size:{train_size} / Seed:{seed}')\n",
    "                \n",
    "                if model_name == 'RandomForestClassifier':\n",
    "                    objective = objectiveRandomForestClassifier\n",
    "                elif model_name == 'XGBClassifier':\n",
    "                    objective = objectiveXGBClassifier\n",
    "\n",
    "                model = MLmodel(modelType=model_name, \n",
    "                df=input,\n",
    "                randomSeed=seed,\n",
    "                train_count = train_size,\n",
    "                test_count = 50, \n",
    "                target=target, \n",
    "                features=Features, \n",
    "                hyperparameter_tuning=True,\n",
    "                feature_types=Feature_types,\n",
    "                optimization_method='optuna', \n",
    "                optimization_trials=10,\n",
    "                objective=lambda trial: objective(trial, model)\n",
    "                )\n",
    "\n",
    "                model.train()\n",
    "                eval, summary = model.evaluate()\n",
    "                result.append({**summary, **eval, 'seed':seed})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modeltype</th>\n",
       "      <th>target</th>\n",
       "      <th>train_size</th>\n",
       "      <th>trues</th>\n",
       "      <th>preds</th>\n",
       "      <th>model_params</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>kappa</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.706015</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>500</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.772633</td>\n",
       "      <td>0.546952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>1000</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.772633</td>\n",
       "      <td>0.546952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>5000</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.837662</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.777184</td>\n",
       "      <td>0.557522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>500</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.816401</td>\n",
       "      <td>0.632953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>1000</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>5000</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.759615</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>500</td>\n",
       "      <td>[1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.859944</td>\n",
       "      <td>0.720893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>1000</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.761526</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>5000</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.899960</td>\n",
       "      <td>0.801902</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>100</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.799679</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>500</td>\n",
       "      <td>[1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.879808</td>\n",
       "      <td>0.761146</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>1000</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.959742</td>\n",
       "      <td>0.919485</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>5000</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.959742</td>\n",
       "      <td>0.919614</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.440895</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>500</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.799679</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>1000</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.839744</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>5000</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.959742</td>\n",
       "      <td>0.919485</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.699880</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>500</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>1000</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.859944</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>[y_bin]</td>\n",
       "      <td>5000</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>[0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.959612</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 modeltype   target  train_size  \\\n",
       "0   RandomForestClassifier  [y_bin]         100   \n",
       "1   RandomForestClassifier  [y_bin]         500   \n",
       "2   RandomForestClassifier  [y_bin]        1000   \n",
       "3   RandomForestClassifier  [y_bin]        5000   \n",
       "4            XGBClassifier  [y_bin]         100   \n",
       "5            XGBClassifier  [y_bin]         500   \n",
       "6            XGBClassifier  [y_bin]        1000   \n",
       "7            XGBClassifier  [y_bin]        5000   \n",
       "8   RandomForestClassifier  [y_bin]         100   \n",
       "9   RandomForestClassifier  [y_bin]         500   \n",
       "10  RandomForestClassifier  [y_bin]        1000   \n",
       "11  RandomForestClassifier  [y_bin]        5000   \n",
       "12           XGBClassifier  [y_bin]         100   \n",
       "13           XGBClassifier  [y_bin]         500   \n",
       "14           XGBClassifier  [y_bin]        1000   \n",
       "15           XGBClassifier  [y_bin]        5000   \n",
       "16  RandomForestClassifier  [y_bin]         100   \n",
       "17  RandomForestClassifier  [y_bin]         500   \n",
       "18  RandomForestClassifier  [y_bin]        1000   \n",
       "19  RandomForestClassifier  [y_bin]        5000   \n",
       "20           XGBClassifier  [y_bin]         100   \n",
       "21           XGBClassifier  [y_bin]         500   \n",
       "22           XGBClassifier  [y_bin]        1000   \n",
       "23           XGBClassifier  [y_bin]        5000   \n",
       "\n",
       "                                                trues  \\\n",
       "0   [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, ...   \n",
       "1   [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, ...   \n",
       "2   [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, ...   \n",
       "3   [1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...   \n",
       "4   [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, ...   \n",
       "5   [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, ...   \n",
       "6   [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, ...   \n",
       "7   [1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...   \n",
       "8   [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "9   [1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "10  [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "11  [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, ...   \n",
       "12  [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "13  [1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "14  [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "15  [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, ...   \n",
       "16  [0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, ...   \n",
       "17  [1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, ...   \n",
       "18  [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, ...   \n",
       "19  [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...   \n",
       "20  [0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, ...   \n",
       "21  [1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, ...   \n",
       "22  [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, ...   \n",
       "23  [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...   \n",
       "\n",
       "                                                preds  \\\n",
       "0   [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...   \n",
       "1   [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...   \n",
       "2   [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "3   [1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...   \n",
       "4   [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, ...   \n",
       "5   [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, ...   \n",
       "6   [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...   \n",
       "7   [1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...   \n",
       "8   [1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, ...   \n",
       "9   [1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, ...   \n",
       "10  [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, ...   \n",
       "11  [0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, ...   \n",
       "12  [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, ...   \n",
       "13  [1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "14  [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "15  [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, ...   \n",
       "16  [1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "17  [1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, ...   \n",
       "18  [0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, ...   \n",
       "19  [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...   \n",
       "20  [1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, ...   \n",
       "21  [1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, ...   \n",
       "22  [0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, ...   \n",
       "23  [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, ...   \n",
       "\n",
       "                                         model_params  accuracy  f1_micro  \\\n",
       "0   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...      0.74      0.74   \n",
       "1   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...      0.78      0.78   \n",
       "2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...      0.78      0.78   \n",
       "3   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...      0.84      0.84   \n",
       "4   {'objective': 'binary:logistic', 'use_label_en...      0.80      0.80   \n",
       "5   {'objective': 'binary:logistic', 'use_label_en...      0.82      0.82   \n",
       "6   {'objective': 'binary:logistic', 'use_label_en...      0.84      0.84   \n",
       "7   {'objective': 'binary:logistic', 'use_label_en...      0.88      0.88   \n",
       "8   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...      0.76      0.76   \n",
       "9   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...      0.86      0.86   \n",
       "10  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...      0.88      0.88   \n",
       "11  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...      0.90      0.90   \n",
       "12  {'objective': 'binary:logistic', 'use_label_en...      0.80      0.80   \n",
       "13  {'objective': 'binary:logistic', 'use_label_en...      0.88      0.88   \n",
       "14  {'objective': 'binary:logistic', 'use_label_en...      0.96      0.96   \n",
       "15  {'objective': 'binary:logistic', 'use_label_en...      0.96      0.96   \n",
       "16  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...      0.72      0.72   \n",
       "17  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...      0.80      0.80   \n",
       "18  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...      0.84      0.84   \n",
       "19  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...      0.96      0.96   \n",
       "20  {'objective': 'binary:logistic', 'use_label_en...      0.70      0.70   \n",
       "21  {'objective': 'binary:logistic', 'use_label_en...      0.84      0.84   \n",
       "22  {'objective': 'binary:logistic', 'use_label_en...      0.86      0.86   \n",
       "23  {'objective': 'binary:logistic', 'use_label_en...      0.98      0.98   \n",
       "\n",
       "    f1_macro     kappa  seed  \n",
       "0   0.706015  0.418605     1  \n",
       "1   0.772633  0.546952     1  \n",
       "2   0.772633  0.546952     1  \n",
       "3   0.837662  0.675325     1  \n",
       "4   0.777184  0.557522     1  \n",
       "5   0.816401  0.632953     1  \n",
       "6   0.833333  0.668874     1  \n",
       "7   0.876847  0.754098     1  \n",
       "8   0.759615  0.520000     2  \n",
       "9   0.859944  0.720893     2  \n",
       "10  0.880000  0.761526     2  \n",
       "11  0.899960  0.801902     2  \n",
       "12  0.799679  0.600000     2  \n",
       "13  0.879808  0.761146     2  \n",
       "14  0.959742  0.919485     2  \n",
       "15  0.959742  0.919614     2  \n",
       "16  0.720000  0.440895     3  \n",
       "17  0.799679  0.600000     3  \n",
       "18  0.839744  0.679487     3  \n",
       "19  0.959742  0.919485     3  \n",
       "20  0.699880  0.400000     3  \n",
       "21  0.840000  0.680000     3  \n",
       "22  0.859944  0.720000     3  \n",
       "23  0.979798  0.959612     3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "display(df)\n",
    "df.to_csv('AdE_polymers_traditional_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Random Forrest - AdE polymers')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "METRICS = ['accuracy','f1_micro','f1_macro', 'kappa']\n",
    "fig, ax = plt.subplots(len(METRICS), 1, sharex=True, layout = 'constrained')\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, metric in enumerate(METRICS):\n",
    "    ax[i].plot(df['train_size'], df[metric], marker = 'o')\n",
    "    ax[i].set_title(metric)\n",
    "    ax[i].set_ylim(0,1)\n",
    "\n",
    "fig.suptitle('Random Forrest - AdE polymers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JorenML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
