{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional machine learning\n",
    "Feature(s): 'SMILES' column\n",
    "\n",
    "- Copolymer sequence of A and B monomer\n",
    "- Binary encoding\n",
    "\n",
    "Target: y_bin\n",
    "\n",
    "- Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Append the parent directory of your package to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..', '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique smiles: 16000\n",
      "Count of all of the smiles: 16000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "path_to_dataset = 'train_polymers.csv'\n",
    "csv_filename = 'train_polymers.csv'\n",
    "\n",
    "# Open the file, Correct the encoding and sep if necessary\n",
    "if path_to_dataset.endswith('.zip'):\n",
    "    with zipfile.ZipFile(path_to_dataset, 'r') as z:\n",
    "        # Open the CSV file within the ZIP file\n",
    "        with z.open(csv_filename) as f:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(f, sep=',', on_bad_lines='warn', index_col = 0)\n",
    "else:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(path_to_dataset, sep=',', on_bad_lines='warn', index_col = 0)\n",
    "\n",
    "\n",
    "print('Count of unique smiles:', df.SMILES.unique().shape[0])\n",
    "print('Count of all of the smiles:', df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping\n",
    "mapping = {'A': 0, 'B': 1}\n",
    "\n",
    "# Apply mapping and convert sequences to arrays\n",
    "def encode_sequence(sequence):\n",
    "    return np.array([mapping[char] for char in sequence.split()])\n",
    "\n",
    "df['Encoded'] = df['SMILES'].apply(encode_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLPipeline import MLmodel, BinTheTarget\n",
    "\n",
    "Target = ['y_bin']\n",
    "Features = ['Encoded']\n",
    "Feature_types = ['numerical']\n",
    "input = df[:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-12 17:41:52.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mndim y_train: 1\u001b[0m\n",
      "\u001b[32m2024-09-12 17:41:52.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mndim x_train: 2\u001b[0m\n",
      "\u001b[32m2024-09-12 17:41:52.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mshape y_train: (50,)\u001b[0m\n",
      "\u001b[32m2024-09-12 17:41:52.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mshape x_train: (50, 20)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier model trained successfully.\n",
      "Accuracy for RandomForestClassifier: 0.66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLmodel(modelType='RandomForestClassifier',\n",
    "                    df=input,\n",
    "                    target=Target,\n",
    "                    features=Features,\n",
    "                    feature_types=Feature_types)\n",
    "\n",
    "# get the values (input and output) of the model\n",
    "X_train, X_test, y_train, y_test = model.getValues()\n",
    "\n",
    "model.train()\n",
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "def objective(trial, model_instance):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to minimize.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters to tune\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [None, 10, 20, 30, 40]),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 6),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "\n",
    "    # Clone the model to ensure a fresh instance each trial\n",
    "    model_clone = clone(model_instance.model)\n",
    "    model_clone.set_params(**params)\n",
    "    \n",
    "    # Define the score metric\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(model_clone, model_instance.X_train, model_instance.y_train, cv=model_instance.cv, scoring=scoring)\n",
    "\n",
    "    # Return the average score across all folds\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-12 17:41:53.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mndim y_train: 1\u001b[0m\n",
      "\u001b[32m2024-09-12 17:41:53.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mndim x_train: 2\u001b[0m\n",
      "\u001b[32m2024-09-12 17:41:53.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mshape y_train: (50,)\u001b[0m\n",
      "\u001b[32m2024-09-12 17:41:53.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMLPipeline\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mshape x_train: (50, 20)\u001b[0m\n",
      "[I 2024-09-12 17:41:53,028] A new study created in memory with name: no-name-7a3dc1a8-35b9-4e5c-aef1-7b8a39019015\n",
      "[I 2024-09-12 17:41:54,114] Trial 0 finished with value: 0.82 and parameters: {'n_estimators': 217, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.82.\n",
      "[I 2024-09-12 17:41:54,565] Trial 1 finished with value: 0.8 and parameters: {'n_estimators': 126, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.82.\n",
      "[I 2024-09-12 17:41:54,905] Trial 2 finished with value: 0.78 and parameters: {'n_estimators': 93, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.82.\n",
      "[I 2024-09-12 17:41:55,543] Trial 3 finished with value: 0.8 and parameters: {'n_estimators': 128, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 0 with value: 0.82.\n",
      "[I 2024-09-12 17:41:55,784] Trial 4 finished with value: 0.8400000000000001 and parameters: {'n_estimators': 66, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:41:56,465] Trial 5 finished with value: 0.8 and parameters: {'n_estimators': 136, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:41:57,883] Trial 6 finished with value: 0.8400000000000001 and parameters: {'n_estimators': 286, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:41:58,166] Trial 7 finished with value: 0.8 and parameters: {'n_estimators': 56, 'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:41:58,906] Trial 8 finished with value: 0.76 and parameters: {'n_estimators': 148, 'max_depth': None, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:41:59,234] Trial 9 finished with value: 0.7799999999999999 and parameters: {'n_estimators': 65, 'max_depth': 20, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:41:59,966] Trial 10 finished with value: 0.76 and parameters: {'n_estimators': 203, 'max_depth': 30, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:01,025] Trial 11 finished with value: 0.78 and parameters: {'n_estimators': 297, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:02,056] Trial 12 finished with value: 0.7799999999999999 and parameters: {'n_estimators': 288, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:02,951] Trial 13 finished with value: 0.7799999999999999 and parameters: {'n_estimators': 252, 'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:03,890] Trial 14 finished with value: 0.8 and parameters: {'n_estimators': 186, 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:04,759] Trial 15 finished with value: 0.76 and parameters: {'n_estimators': 244, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:05,107] Trial 16 finished with value: 0.8400000000000001 and parameters: {'n_estimators': 93, 'max_depth': 30, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:05,939] Trial 17 finished with value: 0.8 and parameters: {'n_estimators': 166, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:07,153] Trial 18 finished with value: 0.8 and parameters: {'n_estimators': 245, 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:07,511] Trial 19 finished with value: 0.78 and parameters: {'n_estimators': 96, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:08,479] Trial 20 finished with value: 0.7799999999999999 and parameters: {'n_estimators': 271, 'max_depth': None, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:08,784] Trial 21 finished with value: 0.8 and parameters: {'n_estimators': 81, 'max_depth': 30, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:09,184] Trial 22 finished with value: 0.72 and parameters: {'n_estimators': 109, 'max_depth': 30, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:09,385] Trial 23 finished with value: 0.72 and parameters: {'n_estimators': 51, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:09,679] Trial 24 finished with value: 0.76 and parameters: {'n_estimators': 75, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:10,261] Trial 25 finished with value: 0.76 and parameters: {'n_estimators': 159, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:10,832] Trial 26 finished with value: 0.8 and parameters: {'n_estimators': 113, 'max_depth': 30, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:11,629] Trial 27 finished with value: 0.8 and parameters: {'n_estimators': 224, 'max_depth': 30, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:12,104] Trial 28 finished with value: 0.8 and parameters: {'n_estimators': 92, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:13,049] Trial 29 finished with value: 0.7799999999999999 and parameters: {'n_estimators': 181, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:13,906] Trial 30 finished with value: 0.76 and parameters: {'n_estimators': 226, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:14,938] Trial 31 finished with value: 0.7799999999999999 and parameters: {'n_estimators': 202, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:16,309] Trial 32 finished with value: 0.78 and parameters: {'n_estimators': 271, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:16,908] Trial 33 finished with value: 0.82 and parameters: {'n_estimators': 114, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:18,017] Trial 34 finished with value: 0.78 and parameters: {'n_estimators': 220, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:18,675] Trial 35 finished with value: 0.8 and parameters: {'n_estimators': 129, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:19,196] Trial 36 finished with value: 0.74 and parameters: {'n_estimators': 140, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:19,544] Trial 37 finished with value: 0.8400000000000001 and parameters: {'n_estimators': 65, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:19,957] Trial 38 finished with value: 0.8 and parameters: {'n_estimators': 78, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:20,294] Trial 39 finished with value: 0.8 and parameters: {'n_estimators': 63, 'max_depth': 20, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:20,629] Trial 40 finished with value: 0.74 and parameters: {'n_estimators': 88, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:20,977] Trial 41 finished with value: 0.8 and parameters: {'n_estimators': 65, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:21,511] Trial 42 finished with value: 0.82 and parameters: {'n_estimators': 103, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:21,785] Trial 43 finished with value: 0.82 and parameters: {'n_estimators': 50, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:22,771] Trial 44 finished with value: 0.7799999999999999 and parameters: {'n_estimators': 196, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:24,193] Trial 45 finished with value: 0.7799999999999999 and parameters: {'n_estimators': 272, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:24,469] Trial 46 finished with value: 0.78 and parameters: {'n_estimators': 71, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:25,887] Trial 47 finished with value: 0.78 and parameters: {'n_estimators': 285, 'max_depth': 40, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:26,450] Trial 48 finished with value: 0.8 and parameters: {'n_estimators': 151, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 0.8400000000000001.\n",
      "[I 2024-09-12 17:42:27,314] Trial 49 finished with value: 0.76 and parameters: {'n_estimators': 171, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 0.8400000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForestClassifier model trained successfully with hyperparameter tuning using Optuna.\n",
      "Best hyperparameters: {'n_estimators': 66, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'bootstrap': False}\n",
      "RandomForestClassifier model trained successfully.\n",
      "Accuracy for RandomForestClassifier: 0.76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLmodel(modelType='RandomForestClassifier', df=df, target=Target, \n",
    "                features=Features, hyperparameter_tuning=True,\n",
    "                feature_types=Feature_types,\n",
    "                optimization_method='optuna', objective=lambda trial: objective(trial, model))\n",
    "\n",
    "model.train()\n",
    "predictions = model.predict()\n",
    "model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JorenML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
